{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bcff2ff-78ac-4225-8542-2f6ebaaad5e8",
   "metadata": {},
   "source": [
    "# HW4\n",
    "member:\n",
    "1. 統計112 劉恩兆 B14081027\n",
    "2. 統計112 宋穎恩 B14081032"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a143b1e5-95c5-416c-8ca5-8b501543a4c2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 載套件、讀資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4786b984-3bd1-4259-9ffd-e6bb90b39520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "080d9baf-ea18-4046-8ed7-477f22589128",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c918918-e809-47f4-a7ef-f9702aefc7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>551</td>\n",
       "      <td>15806307</td>\n",
       "      <td>Trevisano</td>\n",
       "      <td>720</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>114051.97</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>107577.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6897</td>\n",
       "      <td>15709621</td>\n",
       "      <td>Martin</td>\n",
       "      <td>682</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>62397.41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113088.60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4588</td>\n",
       "      <td>15619340</td>\n",
       "      <td>Palmer</td>\n",
       "      <td>672</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>119903.67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>132925.17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>291</td>\n",
       "      <td>15620746</td>\n",
       "      <td>Napolitani</td>\n",
       "      <td>592</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>104257.86</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110857.33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1673</td>\n",
       "      <td>15646372</td>\n",
       "      <td>Yao</td>\n",
       "      <td>753</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>120387.73</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>126378.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>5345</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Yu</td>\n",
       "      <td>568</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>121079.60</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>124890.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>5837</td>\n",
       "      <td>15606641</td>\n",
       "      <td>Liao</td>\n",
       "      <td>602</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>145846.07</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>99276.02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>7335</td>\n",
       "      <td>15739692</td>\n",
       "      <td>Ferri</td>\n",
       "      <td>679</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>5</td>\n",
       "      <td>132810.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130780.85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>9552</td>\n",
       "      <td>15791373</td>\n",
       "      <td>Worsnop</td>\n",
       "      <td>715</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>118729.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95484.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>178</td>\n",
       "      <td>15739931</td>\n",
       "      <td>Ibekwe</td>\n",
       "      <td>600</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>62397.41</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66315.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId     Surname  CreditScore Geography  Gender  Age  \\\n",
       "0           551    15806307   Trevisano          720     Spain    Male   38   \n",
       "1          6897    15709621      Martin          682    France  Female   54   \n",
       "2          4588    15619340      Palmer          672    France  Female   31   \n",
       "3           291    15620746  Napolitani          592     Spain  Female   40   \n",
       "4          1673    15646372         Yao          753     Spain    Male   42   \n",
       "...         ...         ...         ...          ...       ...     ...  ...   \n",
       "7995       5345    15584532          Yu          568    France  Female   35   \n",
       "7996       5837    15606641        Liao          602   Germany  Female   45   \n",
       "7997       7335    15739692       Ferri          679     Spain  Female   43   \n",
       "7998       9552    15791373     Worsnop          715    France    Male   38   \n",
       "7999        178    15739931      Ibekwe          600    France  Female   42   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0          5  114051.97              2          0               1   \n",
       "1          4   62397.41              1          1               0   \n",
       "2          5  119903.67              1          1               1   \n",
       "3          4  104257.86              1          1               0   \n",
       "4          5  120387.73              1          0               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "7995       6  121079.60              2          1               1   \n",
       "7996       7  145846.07              1          1               0   \n",
       "7997       5  132810.01              1          1               0   \n",
       "7998       4  118729.45              1          0               0   \n",
       "7999       5   62397.41              1          0               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           107577.29       0  \n",
       "1           113088.60       1  \n",
       "2           132925.17       0  \n",
       "3           110857.33       0  \n",
       "4           126378.57       0  \n",
       "...               ...     ...  \n",
       "7995        124890.50       1  \n",
       "7996         99276.02       0  \n",
       "7997        130780.85       1  \n",
       "7998         95484.52       0  \n",
       "7999         66315.00       0  \n",
       "\n",
       "[8000 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "900fdbb6-50a8-44f0-890a-fb2510708437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2209</td>\n",
       "      <td>15623595</td>\n",
       "      <td>Scott</td>\n",
       "      <td>726</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>62397.41</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>106139.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9924</td>\n",
       "      <td>15740283</td>\n",
       "      <td>Yegorova</td>\n",
       "      <td>661</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>130339.64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125776.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4617</td>\n",
       "      <td>15802368</td>\n",
       "      <td>Tan</td>\n",
       "      <td>545</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>62397.41</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>78372.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6077</td>\n",
       "      <td>15615322</td>\n",
       "      <td>Anayochukwu</td>\n",
       "      <td>731</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>86717.08</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>136026.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9240</td>\n",
       "      <td>15766374</td>\n",
       "      <td>Glover</td>\n",
       "      <td>533</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>62397.41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>135205.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>7872</td>\n",
       "      <td>15617348</td>\n",
       "      <td>Taylor</td>\n",
       "      <td>628</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>62397.41</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>96201.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>4257</td>\n",
       "      <td>15642785</td>\n",
       "      <td>Tokareva</td>\n",
       "      <td>639</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>98154.30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>109531.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>2273</td>\n",
       "      <td>15766575</td>\n",
       "      <td>Trevisan</td>\n",
       "      <td>548</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>119078.34</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>116725.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>315</td>\n",
       "      <td>15610271</td>\n",
       "      <td>Dickson</td>\n",
       "      <td>602</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>62397.41</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>128135.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>3628</td>\n",
       "      <td>15763895</td>\n",
       "      <td>He</td>\n",
       "      <td>615</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>105570.37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>104140.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId      Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          2209    15623595        Scott          726    France  Female   39   \n",
       "1          9924    15740283     Yegorova          661    France    Male   42   \n",
       "2          4617    15802368          Tan          545    France    Male   34   \n",
       "3          6077    15615322  Anayochukwu          731     Spain  Female   42   \n",
       "4          9240    15766374       Glover          533    France  Female   50   \n",
       "...         ...         ...          ...          ...       ...     ...  ...   \n",
       "1995       7872    15617348       Taylor          628    France    Male   35   \n",
       "1996       4257    15642785     Tokareva          639   Germany    Male   41   \n",
       "1997       2273    15766575     Trevisan          548    France  Female   46   \n",
       "1998        315    15610271      Dickson          602     Spain  Female   44   \n",
       "1999       3628    15763895           He          615   Germany  Female   32   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0          3   62397.41              1          0               0   \n",
       "1          3  130339.64              1          1               0   \n",
       "2          6   62397.41              2          1               1   \n",
       "3          3   86717.08              1          1               0   \n",
       "4          6   62397.41              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "1995       6   62397.41              2          1               1   \n",
       "1996       5   98154.30              2          1               0   \n",
       "1997       3  119078.34              2          1               1   \n",
       "1998       7   62397.41              2          1               1   \n",
       "1999       5  105570.37              1          1               0   \n",
       "\n",
       "      EstimatedSalary  \n",
       "0           106139.31  \n",
       "1           125776.38  \n",
       "2            78372.28  \n",
       "3           136026.27  \n",
       "4           135205.58  \n",
       "...               ...  \n",
       "1995         96201.09  \n",
       "1996        109531.64  \n",
       "1997        116725.67  \n",
       "1998        128135.95  \n",
       "1999        104140.30  \n",
       "\n",
       "[2000 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02220fa4-a490-42b2-9956-488bc9fbbb56",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 資料前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37628a34-e5e2-42dd-bead-1e6bc76cf946",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['RowNumber', 'CustomerId', 'Surname'], axis = 1, inplace = True)\n",
    "RowNumber = test['RowNumber']\n",
    "test.drop(['RowNumber', 'CustomerId', 'Surname'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff96b0ee-8527-4a5a-b0e1-eef0074d8999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88a8e4e6-6795-4f80-9838-ec4e37b5efba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c346161c-3388-4447-b736-384154eabace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography_1</th>\n",
       "      <th>Geography_2</th>\n",
       "      <th>Geography_3</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.509906</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>0.428978</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.304927</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.866637</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.214512</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.529787</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.697356</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>0.615161</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.339115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.656894</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>0.117359</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.438752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.068534</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>0.630562</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.072015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>-1.063169</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>0.652575</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.011302</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>-0.487612</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>1.440568</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.033763</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>0.815853</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>5</td>\n",
       "      <td>1.025801</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.251627</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>1.425266</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>0.577801</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.188456</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>-0.521469</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.214512</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.378566</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Geography_1  Geography_2  Geography_3  Gender  Age  Tenure  \\\n",
       "0        1.509906            1            0            0       1   38       5   \n",
       "1        0.866637            0            1            0       0   54       4   \n",
       "2        0.697356            0            1            0       0   31       5   \n",
       "3       -0.656894            1            0            0       0   40       4   \n",
       "4        2.068534            1            0            0       1   42       5   \n",
       "...           ...          ...          ...          ...     ...  ...     ...   \n",
       "7995    -1.063169            0            1            0       0   35       6   \n",
       "7996    -0.487612            0            0            1       0   45       7   \n",
       "7997     0.815853            1            0            0       0   43       5   \n",
       "7998     1.425266            0            1            0       1   38       4   \n",
       "7999    -0.521469            0            1            0       0   42       5   \n",
       "\n",
       "       Balance  NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \\\n",
       "0     0.428978              2          0               1         0.304927   \n",
       "1    -1.214512              1          1               0         0.529787   \n",
       "2     0.615161              1          1               1         1.339115   \n",
       "3     0.117359              1          1               0         0.438752   \n",
       "4     0.630562              1          0               1         1.072015   \n",
       "...        ...            ...        ...             ...              ...   \n",
       "7995  0.652575              2          1               1         1.011302   \n",
       "7996  1.440568              1          1               0        -0.033763   \n",
       "7997  1.025801              1          1               0         1.251627   \n",
       "7998  0.577801              1          0               0        -0.188456   \n",
       "7999 -1.214512              1          0               0        -1.378566   \n",
       "\n",
       "      Exited  \n",
       "0          0  \n",
       "1          1  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "...      ...  \n",
       "7995       1  \n",
       "7996       0  \n",
       "7997       1  \n",
       "7998       0  \n",
       "7999       0  \n",
       "\n",
       "[8000 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#【train】\n",
    "#Standard Scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "col_to_scale = ['CreditScore', 'Balance', 'EstimatedSalary']\n",
    "scaler = StandardScaler().fit(train[col_to_scale])\n",
    "train_scaled = scaler.transform(train[col_to_scale])\n",
    "train[col_to_scale] = train_scaled\n",
    "#One-hot encoding\n",
    "import category_encoders as ce\n",
    "encoder = ce.OneHotEncoder(cols=['Geography'])\n",
    "train = encoder.fit_transform(train)\n",
    "#Gender map\n",
    "train['Gender'] = train['Gender'].map({'Female':0, 'Male':1})\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0c2ebe5-1dbd-41a0-89aa-13cdbd7541fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography_1</th>\n",
       "      <th>Geography_2</th>\n",
       "      <th>Geography_3</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.609183</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.272730</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.263584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.528128</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>0.915085</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.077935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.401138</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>-1.272730</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.887917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.692341</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.489610</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.502999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.600717</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>-1.272730</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.468965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>-0.020715</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>-1.272730</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.148555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.162233</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.121318</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.404264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>-1.351243</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>0.552459</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.702602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>-0.453136</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>-1.272730</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.175787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>-0.236926</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>0.117487</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.180685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Geography_1  Geography_2  Geography_3  Gender  Age  Tenure  \\\n",
       "0        1.609183            1            0            0       0   39       3   \n",
       "1        0.528128            1            0            0       1   42       3   \n",
       "2       -1.401138            1            0            0       1   34       6   \n",
       "3        1.692341            0            1            0       0   42       3   \n",
       "4       -1.600717            1            0            0       0   50       6   \n",
       "...           ...          ...          ...          ...     ...  ...     ...   \n",
       "1995    -0.020715            1            0            0       1   35       6   \n",
       "1996     0.162233            0            0            1       1   41       5   \n",
       "1997    -1.351243            1            0            0       0   46       3   \n",
       "1998    -0.453136            0            1            0       0   44       7   \n",
       "1999    -0.236926            0            0            1       0   32       5   \n",
       "\n",
       "       Balance  NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0    -1.272730              1          0               0         0.263584  \n",
       "1     0.915085              1          1               0         1.077935  \n",
       "2    -1.272730              2          1               1        -0.887917  \n",
       "3    -0.489610              1          1               0         1.502999  \n",
       "4    -1.272730              1          1               1         1.468965  \n",
       "...        ...            ...        ...             ...              ...  \n",
       "1995 -1.272730              2          1               1        -0.148555  \n",
       "1996 -0.121318              2          1               0         0.404264  \n",
       "1997  0.552459              2          1               1         0.702602  \n",
       "1998 -1.272730              2          1               1         1.175787  \n",
       "1999  0.117487              1          1               0         0.180685  \n",
       "\n",
       "[2000 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#【test】\n",
    "#Standard Scaler \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "col_to_scale = ['CreditScore', 'Balance', 'EstimatedSalary']\n",
    "scaler = StandardScaler().fit(test[col_to_scale])\n",
    "test_scaled = scaler.transform(test[col_to_scale])\n",
    "test[col_to_scale] = test_scaled\n",
    "#One-hot encoding\n",
    "encoder = ce.OneHotEncoder(cols=['Geography'])\n",
    "test = encoder.fit_transform(test)\n",
    "#Gender map\n",
    "test['Gender'] = test['Gender'].map({'Female':0, 'Male':1})\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af340d21-20fb-438c-b8a8-501b1085eeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train.drop(['Exited'], axis=1)\n",
    "train_Y = train['Exited']\n",
    "test_X = test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db869a78-14ca-47c0-9891-eaedcdf28961",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 跑模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58a83de-f435-41e3-8c22-16e3d410722a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## LogisticRegression (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bebc9aa2-3cac-4b33-ab5c-8671fd0eb6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 建立Logistic模型\n",
    "logisticModel = LogisticRegression(random_state=0, max_iter=1000, verbose=1)\n",
    "# 使用訓練資料訓練模型\n",
    "logisticModel.fit(train_X, train_Y.astype(int))\n",
    "# 使用訓練資料預測分類\n",
    "ypred = logisticModel.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc1f606e-7d77-446e-b136-390488994c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2209</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9924</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4617</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9240</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>7872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>4257</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>2273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>3628</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  Exited\n",
       "0          2209       0\n",
       "1          9924       0\n",
       "2          4617       0\n",
       "3          6077       0\n",
       "4          9240       0\n",
       "...         ...     ...\n",
       "1995       7872       0\n",
       "1996       4257       0\n",
       "1997       2273       0\n",
       "1998        315       0\n",
       "1999       3628       0\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload_1 = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload_1.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2d323ca-c086-4d77-9565-8c09b412d81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_1.to_csv('upload_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b7b974-59c1-4777-b6f9-9fb4043ce551",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## SVM (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "234851f2-4450-4c7d-90e2-68eddb26fab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC(max_iter=1000, C=1)\n",
    "model.fit(train_X, train_Y.astype(int))\n",
    "ypred = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "25dac374-3f9b-419e-8f07-c4d024752f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2209</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9924</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4617</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6077</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9240</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>7872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>4257</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>2273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>315</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>3628</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  Exited\n",
       "0          2209       1\n",
       "1          9924       1\n",
       "2          4617       0\n",
       "3          6077       1\n",
       "4          9240       1\n",
       "...         ...     ...\n",
       "1995       7872       0\n",
       "1996       4257       1\n",
       "1997       2273       1\n",
       "1998        315       1\n",
       "1999       3628       0\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload_2 = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload_2.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbf7716d-8981-4109-be84-39d9f5c1de88",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_2.to_csv('upload_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c067d939-6da5-4835-8d60-59d901f9e5d9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MLP (3、59-66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92fb54ff-3738-4fab-9413-6fe54e2745ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(activation= 'tanh', alpha= 0.0005, hidden_layer_sizes= (20, 15), learning_rate= 'constant', max_iter= 2000, solver= 'adam')\n",
    "clf.fit(train_X, train_Y.astype(int))\n",
    "ypred=clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6534af9-5707-4290-a997-8e2971e1faea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2209</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9924</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4617</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9240</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>7872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>4257</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>2273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>3628</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  Exited\n",
       "0          2209       0\n",
       "1          9924       0\n",
       "2          4617       0\n",
       "3          6077       0\n",
       "4          9240       0\n",
       "...         ...     ...\n",
       "1995       7872       0\n",
       "1996       4257       0\n",
       "1997       2273       0\n",
       "1998        315       0\n",
       "1999       3628       0\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload_3 = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload_3.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bfda27dd-4ce0-4cd5-b8d4-9a91a0f89242",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_3.to_csv('upload_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49d1baad-55a7-4dcb-8551-7557f962f0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(activation= 'tanh', alpha= 0.0005, hidden_layer_sizes= (20, 15), learning_rate='constant', max_iter= 1000, solver= 'adam',learning_rate_init=0.005)\n",
    "clf.fit(train_X, train_Y.astype(int))\n",
    "ypred=clf.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload\n",
    "upload.to_csv('upload66.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0b0f09c-48ea-4d62-b1b5-639097eb1a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(activation= 'relu', alpha= 0.0005, hidden_layer_sizes= (20, 15), learning_rate='constant', max_iter= 1000, solver= 'adam',learning_rate_init=0.005)\n",
    "clf.fit(train_X, train_Y.astype(int))\n",
    "ypred=clf.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload\n",
    "upload.to_csv('upload59.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "792de514-14f4-4043-b46e-25c23e437d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(activation= 'relu', alpha= 0.0005, hidden_layer_sizes= (20, 15), learning_rate='constant', max_iter= 1000, solver= 'adam',learning_rate_init=0.01)\n",
    "clf.fit(train_X, train_Y.astype(int))\n",
    "ypred=clf.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload\n",
    "upload.to_csv('upload60.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b70cc75f-324e-4ab2-a232-34c3a1d3f112",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(activation= 'relu', alpha= 0.0005, hidden_layer_sizes= (40, 20, 15), learning_rate='constant', max_iter= 1000, solver= 'adam',learning_rate_init=0.01)\n",
    "clf.fit(train_X, train_Y.astype(int))\n",
    "ypred=clf.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload\n",
    "upload.to_csv('upload61.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4690dc61-1e22-4e89-b0fb-0183c3b440fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(activation= 'relu', alpha= 0.0005, hidden_layer_sizes= (40, 20, 15), learning_rate='constant', max_iter= 2000, solver= 'adam',learning_rate_init=0.005)\n",
    "clf.fit(train_X, train_Y.astype(int))\n",
    "ypred=clf.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload\n",
    "upload.to_csv('upload62.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ab6c7b3-3858-453f-b3a7-3f30f1234f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(activation= 'relu', alpha= 0.0005, hidden_layer_sizes= (60, 40, 20), learning_rate='constant', max_iter= 1000, solver= 'adam',learning_rate_init=0.01)\n",
    "clf.fit(train_X, train_Y.astype(int))\n",
    "ypred=clf.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload\n",
    "upload.to_csv('upload63.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d0e12d3-b2b2-423a-af40-82735d7e4705",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(activation= 'relu', alpha= 0.0005, hidden_layer_sizes= (60, 40, 20), learning_rate='constant', max_iter= 1000, solver= 'adam',learning_rate_init=0.01)\n",
    "clf.fit(train_X, train_Y.astype(int))\n",
    "ypred=clf.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload\n",
    "upload.to_csv('upload63.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8924a8f-bc93-488f-90ea-2d731e193909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(activation= 'tanh', alpha= 0.0005, hidden_layer_sizes= (40, 20, 15), learning_rate='constant', max_iter= 1000, solver= 'adam',learning_rate_init=0.01)\n",
    "clf.fit(train_X, train_Y.astype(int))\n",
    "ypred=clf.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload\n",
    "upload.to_csv('upload64.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7a0112f-aa53-460b-963c-31ca23861a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(activation= 'relu', alpha= 0.0005, hidden_layer_sizes= (40, 20, 15), learning_rate='adaptive', max_iter= 1000, solver= 'adam',learning_rate_init=0.01)\n",
    "clf.fit(train_X, train_Y.astype(int))\n",
    "ypred=clf.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload\n",
    "upload.to_csv('upload65.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b7bc63-ba6d-476f-9843-44fabfeec28f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Decision Tree (4、5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "99898925-0adf-4065-a8e8-c757e9b678c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(train_X, train_Y.astype(int))\n",
    "ypred = dt.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a2375163-bd7f-41f0-8c67-dd023a04c61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2209</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9924</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4617</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9240</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>7872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>4257</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>2273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>3628</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  Exited\n",
       "0          2209       1\n",
       "1          9924       0\n",
       "2          4617       0\n",
       "3          6077       0\n",
       "4          9240       0\n",
       "...         ...     ...\n",
       "1995       7872       0\n",
       "1996       4257       0\n",
       "1997       2273       0\n",
       "1998        315       0\n",
       "1999       3628       0\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload_4 = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload_4.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f4314d1d-5e16-41af-b749-a89b71ec688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_4.to_csv('upload_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b86284c2-f18d-4372-8e26-e463be72cc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth = 6, min_samples_leaf=4, min_samples_split=20)\n",
    "dt.fit(train_X, train_Y.astype(int))\n",
    "ypred = dt.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "700c57d4-fd9f-4fe8-b501-2256d5a60809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2209</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9924</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4617</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9240</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>7872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>4257</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>2273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>3628</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  Exited\n",
       "0          2209       0\n",
       "1          9924       0\n",
       "2          4617       0\n",
       "3          6077       0\n",
       "4          9240       0\n",
       "...         ...     ...\n",
       "1995       7872       0\n",
       "1996       4257       0\n",
       "1997       2273       0\n",
       "1998        315       0\n",
       "1999       3628       0\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload_5 = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload_5.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5caabfea-ed24-4441-9a12-42a0be1fdd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_5.to_csv('upload_5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51f0155-58b3-4e07-98de-7cdfc280c4d8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## KNN (6、7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc3d0e61-8c1a-489a-983c-4436206e14ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn = knn.fit(train_X, train_Y.astype(int))\n",
    "ypred = knn.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "77babbdb-432b-4f3e-b46e-b937ddf8bc0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2209</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9924</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4617</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9240</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>7872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>4257</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>2273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>3628</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  Exited\n",
       "0          2209       0\n",
       "1          9924       0\n",
       "2          4617       0\n",
       "3          6077       0\n",
       "4          9240       1\n",
       "...         ...     ...\n",
       "1995       7872       0\n",
       "1996       4257       0\n",
       "1997       2273       0\n",
       "1998        315       0\n",
       "1999       3628       0\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload_6 = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload_6.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "df4aac75-9fe7-43d0-84e2-31b39048d808",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_6.to_csv('upload_6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c3150021-ff50-4083-bbbf-6368a1f44e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(algorithm='ball_tree', n_neighbors=50, p=1)\n",
    "knn = knn.fit(train_X, train_Y.astype(int))\n",
    "ypred = knn.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ba1c371b-5809-4dae-96b5-d7c2b574bc0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2209</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9924</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4617</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9240</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>7872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>4257</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>2273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>3628</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  Exited\n",
       "0          2209       0\n",
       "1          9924       0\n",
       "2          4617       0\n",
       "3          6077       0\n",
       "4          9240       0\n",
       "...         ...     ...\n",
       "1995       7872       0\n",
       "1996       4257       0\n",
       "1997       2273       0\n",
       "1998        315       0\n",
       "1999       3628       0\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload_7 = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload_7.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "afab3306-29b9-402e-b5fc-e2b94577313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_7.to_csv('upload_7.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020af04b-421b-429c-839d-f39837ca2489",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Random Forest (8、9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "73834e95-6226-469d-acf8-50a34045707b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(train_X, train_Y.astype(int))\n",
    "ypred = rf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "491d8aca-a855-4d74-b5c7-7ace26a98701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2209</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9924</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4617</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9240</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>7872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>4257</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>2273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>3628</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  Exited\n",
       "0          2209       0\n",
       "1          9924       0\n",
       "2          4617       0\n",
       "3          6077       0\n",
       "4          9240       0\n",
       "...         ...     ...\n",
       "1995       7872       0\n",
       "1996       4257       0\n",
       "1997       2273       0\n",
       "1998        315       0\n",
       "1999       3628       0\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload_8 = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload_8.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9417714c-ea73-49f0-8b81-3b2680ca39b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_8.to_csv('upload_8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1acf58bb-2dac-4119-b1b1-9c8ddea7dfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(max_depth = 6, min_samples_leaf=4, min_samples_split=20)\n",
    "rf.fit(train_X, train_Y.astype(int))\n",
    "ypred = rf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8e11fede-0cc1-4b7c-936f-a9b8cb1b89ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2209</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9924</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4617</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9240</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>7872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>4257</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>2273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>3628</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  Exited\n",
       "0          2209       0\n",
       "1          9924       0\n",
       "2          4617       0\n",
       "3          6077       0\n",
       "4          9240       0\n",
       "...         ...     ...\n",
       "1995       7872       0\n",
       "1996       4257       0\n",
       "1997       2273       0\n",
       "1998        315       0\n",
       "1999       3628       0\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload_8 = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload_8.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "10115e54-de6d-46e6-b8dd-4296eacdea2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_9.to_csv('upload_9.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdf2810-56b6-47b1-b6c0-b9cb7704c1bf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Gradient Boost (10、14-35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a1c3bde3-1900-4efa-bcfe-3c001049969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(train_X, train_Y.astype(int))\n",
    "ypred = gb.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9b1b07ee-88e8-410e-b439-e69813c15147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2209</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9924</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4617</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9240</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>7872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>4257</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>2273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>3628</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  Exited\n",
       "0          2209       0\n",
       "1          9924       0\n",
       "2          4617       0\n",
       "3          6077       0\n",
       "4          9240       1\n",
       "...         ...     ...\n",
       "1995       7872       0\n",
       "1996       4257       0\n",
       "1997       2273       0\n",
       "1998        315       0\n",
       "1999       3628       0\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload_10 = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload_10.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3f04b52f-dbb9-4a9f-9675-bb22cea2fd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_10.to_csv('upload_10.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a40956-da82-4764-9615-8b2dec6fa46d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 最佳化參數"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba26c4e9-8aa8-426b-aaec-203dfaa3a1a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af5c0e81-98ce-4b07-bc7a-bf6e17265551",
   "metadata": {},
   "outputs": [],
   "source": [
    "#14 lr=0.001\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb = GradientBoostingClassifier(learning_rate=0.001)\n",
    "gb.fit(train_X, train_Y.astype(int))\n",
    "ypred = gb.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_14.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a002f19-5e99-43cf-bafb-fd1881e5a885",
   "metadata": {},
   "outputs": [],
   "source": [
    "#15 lr=0.01\n",
    "gb = GradientBoostingClassifier(learning_rate=0.01)\n",
    "gb.fit(train_X, train_Y.astype(int))\n",
    "ypred = gb.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_15.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52242ef2-6d74-4c69-966a-20c195160b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#16 lr=0.05\n",
    "gb = GradientBoostingClassifier(learning_rate=0.05)\n",
    "gb.fit(train_X, train_Y.astype(int))\n",
    "ypred = gb.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_16.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b1ba1d9-e4d6-4b70-9a9f-eda666e0a149",
   "metadata": {},
   "outputs": [],
   "source": [
    "#17 lr=0.1\n",
    "gb = GradientBoostingClassifier(learning_rate=0.1)\n",
    "gb.fit(train_X, train_Y.astype(int))\n",
    "ypred = gb.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_17.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2554f1d-9d1d-4a42-a0b3-20c7e01acb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#18 lr=0.25\n",
    "gb = GradientBoostingClassifier(learning_rate=0.25)\n",
    "gb.fit(train_X, train_Y.astype(int))\n",
    "ypred = gb.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_18.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f43dcb2-546d-405a-a538-0a99f2e0a8f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e61653d0-c57e-4e67-b0a6-9cb87aaf8a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#20 lr=0.25, n_estimators=10\n",
    "gb = GradientBoostingClassifier(learning_rate=0.25,n_estimators=10)\n",
    "gb.fit(train_X, train_Y.astype(int))\n",
    "ypred = gb.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0795f3d4-e53a-42ba-b5d4-21cdb984441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#21 lr=0.25, n_estimators=100\n",
    "gb = GradientBoostingClassifier(learning_rate=0.25,n_estimators=100)\n",
    "gb.fit(train_X, train_Y.astype(int))\n",
    "ypred = gb.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_21.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "347dcdd1-e8dd-447d-ab63-943df6817d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#22 lr=0.25, n_estimators=500\n",
    "gb = GradientBoostingClassifier(learning_rate=0.25,n_estimators=500)\n",
    "gb.fit(train_X, train_Y.astype(int))\n",
    "ypred = gb.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_22.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38068354-2314-48e7-8d41-cf8518ee3adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#23 lr=0.25, n_estimators=1000\n",
    "gb = GradientBoostingClassifier(learning_rate=0.25,n_estimators=1000)\n",
    "gb.fit(train_X, train_Y.astype(int))\n",
    "ypred = gb.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_23.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce831d53-7738-47ce-9349-a35bdd39bb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#24 lr=0.25, n_estimators=5000\n",
    "gb = GradientBoostingClassifier(learning_rate=0.25,n_estimators=5000)\n",
    "gb.fit(train_X, train_Y.astype(int))\n",
    "ypred = gb.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_24.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e97a8841-bf73-4016-9cbf-a750472ee0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#25 lr=0.25, n_estimators=50\n",
    "gb = GradientBoostingClassifier(learning_rate=0.25,n_estimators=10)\n",
    "gb.fit(train_X, train_Y.astype(int))\n",
    "ypred = gb.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_25.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af61200a-a45b-4063-802d-d37c887c7f5f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24a1d571-b0a9-471a-825c-06a22158b579",
   "metadata": {},
   "outputs": [],
   "source": [
    "#26 lr=0.25, n_estimators=100, min_samples_leaf=30\n",
    "gb = GradientBoostingClassifier(learning_rate=0.25,n_estimators=100, min_samples_leaf=30)\n",
    "gb.fit(train_X, train_Y.astype(int))\n",
    "ypred = gb.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_26.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "898f556c-1139-4d76-a655-2f27ea1d858e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#27 lr=0.25, n_estimators=100, min_samples_leaf=40\n",
    "gb = GradientBoostingClassifier(learning_rate=0.25,n_estimators=100, min_samples_leaf=40)\n",
    "gb.fit(train_X, train_Y.astype(int))\n",
    "ypred = gb.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_27.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0fda2399-7b0d-4259-a76e-9608e31a69dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#28 lr=0.25, n_estimators=100, min_samples_leaf=50\n",
    "gb = GradientBoostingClassifier(learning_rate=0.25,n_estimators=100, min_samples_leaf=50)\n",
    "gb.fit(train_X, train_Y.astype(int))\n",
    "ypred = gb.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_28.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38521727-1f8b-42c6-afa3-0d5b6b5cafcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#29 lr=0.25, n_estimators=100, min_samples_leaf=60\n",
    "gb = GradientBoostingClassifier(learning_rate=0.25,n_estimators=100, min_samples_leaf=30)\n",
    "gb.fit(train_X, train_Y.astype(int))\n",
    "ypred = gb.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_29.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fb42f09-8fba-45c6-af01-a57e681ba089",
   "metadata": {},
   "outputs": [],
   "source": [
    "#30 lr=0.25, n_estimators=100, min_samples_leaf=70\n",
    "gb = GradientBoostingClassifier(learning_rate=0.25,n_estimators=100, min_samples_leaf=70)\n",
    "gb.fit(train_X, train_Y.astype(int))\n",
    "ypred = gb.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_30.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c0690b-dfdf-4042-ae00-2ec303f66927",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b25dc291-5466-42e6-8f94-b3dc280101b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#31 lr=0.25, n_estimators=100, max_depth=1\n",
    "gb = GradientBoostingClassifier(learning_rate=0.25,n_estimators=100,max_depth=1)\n",
    "gb.fit(train_X, train_Y.astype(int))\n",
    "ypred = gb.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_31.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "350312ea-fd58-4969-a852-c69d1c3c6c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#32 lr=0.25, n_estimators=100, max_depth=3\n",
    "gb = GradientBoostingClassifier(learning_rate=0.25,n_estimators=100,max_depth=3)\n",
    "gb.fit(train_X, train_Y.astype(int))\n",
    "ypred = gb.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_32.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "430d86ac-970b-4e42-a9c4-f594a04f634d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#33 lr=0.25, n_estimators=100, max_depth=5\n",
    "gb = GradientBoostingClassifier(learning_rate=0.25,n_estimators=100,max_depth=5)\n",
    "gb.fit(train_X, train_Y.astype(int))\n",
    "ypred = gb.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_33.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41dd3fd2-c78f-477e-b43a-19c8bd86018f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#34 lr=0.25, n_estimators=100, max_depth=7\n",
    "gb = GradientBoostingClassifier(learning_rate=0.25,n_estimators=100,max_depth=7)\n",
    "gb.fit(train_X, train_Y.astype(int))\n",
    "ypred = gb.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_34.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d351df8c-b48f-4842-a58d-c6c86efca383",
   "metadata": {},
   "outputs": [],
   "source": [
    "#35 lr=0.25, n_estimators=100, max_depth=9\n",
    "gb = GradientBoostingClassifier(learning_rate=0.25,n_estimators=100,max_depth=9)\n",
    "gb.fit(train_X, train_Y.astype(int))\n",
    "ypred = gb.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_35.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421df6b6-9753-4f1b-ae60-2bdb9455e8d8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## XGBoost (11、67-71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c58f240a-0840-4ba6-855a-4277065a5151",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import  XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(train_X, train_Y.astype(int))\n",
    "ypred = xgb.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "609d9ddc-fa54-4fcc-8633-de5509d00c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2209</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9924</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4617</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9240</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>7872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>4257</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>2273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>3628</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  Exited\n",
       "0          2209       0\n",
       "1          9924       0\n",
       "2          4617       0\n",
       "3          6077       0\n",
       "4          9240       1\n",
       "...         ...     ...\n",
       "1995       7872       0\n",
       "1996       4257       0\n",
       "1997       2273       1\n",
       "1998        315       0\n",
       "1999       3628       0\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload_11 = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload_11.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f882c949-0398-4673-b708-185856f5e4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_11.to_csv('upload_11.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff0b3000-a5d5-4b45-a923-482cd2e6205e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import  XGBClassifier\n",
    "xgb = XGBClassifier(learning_rate = 0.01, n_estimators=1000, gamma=0.1)\n",
    "xgb.fit(train_X, train_Y.astype(int))\n",
    "ypred = xgb.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload\n",
    "upload.to_csv('upload_67.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c341ae6-3393-4fe4-a097-3fd5672074d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import  XGBClassifier\n",
    "xgb = XGBClassifier(learning_rate = 0.05, n_estimators=1000, gamma=0.1)\n",
    "xgb.fit(train_X, train_Y.astype(int))\n",
    "ypred = xgb.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload\n",
    "upload.to_csv('upload_68.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b10e66a-0d2b-4e30-a7ff-69b352e0bb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import  XGBClassifier\n",
    "xgb = XGBClassifier(learning_rate = 0.01, n_estimators=1000, gamma=0.3)\n",
    "xgb.fit(train_X, train_Y.astype(int))\n",
    "ypred = xgb.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload\n",
    "upload.to_csv('upload_69.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d68c20cf-7b31-437b-8756-bd81aa35d463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import  XGBClassifier\n",
    "xgb = XGBClassifier(learning_rate = 0.01, n_estimators=1000, gamma=0.1, max_depth=9)\n",
    "xgb.fit(train_X, train_Y.astype(int))\n",
    "ypred = xgb.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload\n",
    "upload.to_csv('upload_70.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9df545f9-43d2-480f-85b4-ccbb5ec8184f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import  XGBClassifier\n",
    "xgb = XGBClassifier(learning_rate = 0.01, n_estimators=1000, gamma=0.1, max_depth=13)\n",
    "xgb.fit(train_X, train_Y.astype(int))\n",
    "ypred = xgb.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload\n",
    "upload.to_csv('upload_71.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b474d8-d840-4c2b-b8ff-71cf8c5f57c4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## LGBM (12、45-58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "14ed9fce-2430-48d1-b538-ccc40bbcfc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "classifier = lgb.LGBMClassifier(objective = 'binary', random_state=0) \n",
    "# learning_rate = 0.05, \n",
    "# n_estimators = 100\n",
    "classifier.fit(train_X, train_Y.astype(int))\n",
    "ypred = classifier.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a2051465-c87a-44c1-a66e-b7e2e48a4156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2209</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9924</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4617</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9240</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>7872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>4257</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>2273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>3628</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  Exited\n",
       "0          2209       0\n",
       "1          9924       0\n",
       "2          4617       0\n",
       "3          6077       0\n",
       "4          9240       0\n",
       "...         ...     ...\n",
       "1995       7872       0\n",
       "1996       4257       0\n",
       "1997       2273       0\n",
       "1998        315       0\n",
       "1999       3628       0\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload_12 = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload_12.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a326b280-df53-4117-8e6f-53f8a3d9ff03",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_12.to_csv('upload_12.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6616db09-da63-4241-a6fc-8a92c7df9d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "classifier = lgb.LGBMClassifier(objective = 'binary', random_state=0,n_estimators = 1000,learning_rate = 0.05) \n",
    "# learning_rate = 0.05, \n",
    "# n_estimators = 100\n",
    "classifier.fit(train_X, train_Y.astype(int))\n",
    "ypred = classifier.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload\n",
    "upload.to_csv('upload_45.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5abc48ef-0eea-4d9c-93f1-356820204ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "classifier = lgb.LGBMClassifier(objective = 'binary', random_state=0,n_estimators = 1000,learning_rate = 0.1) \n",
    "# learning_rate = 0.05, \n",
    "# n_estimators = 100\n",
    "classifier.fit(train_X, train_Y.astype(int))\n",
    "ypred = classifier.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload\n",
    "upload.to_csv('upload_46.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06a45a40-62da-4a33-bb13-8f3a8b6ec465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "classifier = lgb.LGBMClassifier(objective = 'binary', random_state=0,n_estimators = 1000,learning_rate = 0.01) \n",
    "# learning_rate = 0.05, \n",
    "# n_estimators = 100\n",
    "classifier.fit(train_X, train_Y.astype(int))\n",
    "ypred = classifier.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload\n",
    "upload.to_csv('upload_47.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df1e4930-957c-4530-8903-0c5fc2ec9d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "classifier = lgb.LGBMClassifier(objective = 'binary', random_state=0,n_estimators = 1000,learning_rate = 0.005) \n",
    "# learning_rate = 0.05, \n",
    "# n_estimators = 100\n",
    "classifier.fit(train_X, train_Y.astype(int))\n",
    "ypred = classifier.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload\n",
    "upload.to_csv('upload_48.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7fe07259-e19a-4900-a53e-6ee19aac6627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "classifier = lgb.LGBMClassifier(objective = 'binary', random_state=0,n_estimators = 1000,learning_rate = 0.001) \n",
    "# learning_rate = 0.05, \n",
    "# n_estimators = 100\n",
    "classifier.fit(train_X, train_Y.astype(int))\n",
    "ypred = classifier.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload\n",
    "upload.to_csv('upload_49.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "922b1add-0ef2-4b6b-81af-ee383b836493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "classifier = lgb.LGBMClassifier(objective = 'binary', random_state=0,n_estimators = 1000,learning_rate = 0.0005) \n",
    "# learning_rate = 0.05, \n",
    "# n_estimators = 100\n",
    "classifier.fit(train_X, train_Y.astype(int))\n",
    "ypred = classifier.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload\n",
    "upload.to_csv('upload_50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a12e1f42-e6e9-49a2-9290-c54537d925cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "classifier = lgb.LGBMClassifier(objective = 'binary', random_state=0,n_estimators = 300,learning_rate = 0.001) \n",
    "# learning_rate = 0.05, \n",
    "# n_estimators = 100\n",
    "classifier.fit(train_X, train_Y.astype(int))\n",
    "ypred = classifier.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload\n",
    "upload.to_csv('upload_51.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd67584e-58ae-4193-8d8f-9d2325c00d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "classifier = lgb.LGBMClassifier(objective = 'binary', random_state=0,n_estimators = 300,learning_rate = 0.005) \n",
    "# learning_rate = 0.05, \n",
    "# n_estimators = 100\n",
    "classifier.fit(train_X, train_Y.astype(int))\n",
    "ypred = classifier.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload\n",
    "upload.to_csv('upload_52.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "08a94b17-5348-4622-8a09-a245236eb19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n",
      "768\n",
      "995\n",
      "1374\n",
      "1398\n",
      "1831\n",
      "1858\n"
     ]
    }
   ],
   "source": [
    "upload_50 = pd.read_csv('upload_50.csv')\n",
    "upload_48 = pd.read_csv('upload_48.csv')\n",
    "for i in range(len(upload_48)):\n",
    "    if upload_50['Exited'][i] == 1:\n",
    "        print(i)\n",
    "        upload_48['Exited'][i] = 1\n",
    "upload_48.to_csv('upload_53.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f38bd5ec-a8ae-4bf7-bf9c-ff015b97ad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "classifier = lgb.LGBMClassifier(objective = 'binary', random_state=0,n_estimators = 300,learning_rate = 0.005, max_bin=255) \n",
    "# learning_rate = 0.05, \n",
    "# n_estimators = 100\n",
    "classifier.fit(train_X, train_Y.astype(int))\n",
    "ypred = classifier.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload\n",
    "upload.to_csv('upload_54.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ff73409-3fff-4a6f-947b-2b569071cf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "classifier = lgb.LGBMClassifier(objective = 'binary', random_state=0,n_estimators = 300,learning_rate = 0.005, max_bin=255, max_depth=4) \n",
    "# learning_rate = 0.05, \n",
    "# n_estimators = 100\n",
    "classifier.fit(train_X, train_Y.astype(int))\n",
    "ypred = classifier.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload\n",
    "upload.to_csv('upload_55.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fa0544a-bc1a-4192-893b-06007ba58c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "classifier = lgb.LGBMClassifier(objective = 'binary', random_state=0,n_estimators = 300,learning_rate = 0.005, max_bin=255, max_depth=6) \n",
    "# learning_rate = 0.05, \n",
    "# n_estimators = 100\n",
    "classifier.fit(train_X, train_Y.astype(int))\n",
    "ypred = classifier.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload\n",
    "upload.to_csv('upload_56.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cad71623-bba5-4014-87eb-f953fb1f54e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "classifier = lgb.LGBMClassifier(objective = 'binary', random_state=0,n_estimators = 1500,learning_rate = 0.005) \n",
    "# learning_rate = 0.05, \n",
    "# n_estimators = 100\n",
    "classifier.fit(train_X, train_Y.astype(int))\n",
    "ypred = classifier.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload\n",
    "upload.to_csv('upload_57.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "715679ee-9417-4c6d-b84c-e1f4e9e89217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "classifier = lgb.LGBMClassifier(objective = 'binary', random_state=0,n_estimators = 800,learning_rate = 0.005) \n",
    "# learning_rate = 0.05, \n",
    "# n_estimators = 100\n",
    "classifier.fit(train_X, train_Y.astype(int))\n",
    "ypred = classifier.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload\n",
    "upload.to_csv('upload_58.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bf97b7-7d6c-43a8-9a49-4253b6010b66",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## CatBoost (13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "92c30ddf-01a2-40c9-8597-6a855b594abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "clf = CatBoostClassifier()\n",
    "\n",
    "# iterations=5, \n",
    "# learning_rate=0.1, \n",
    "#loss_function='CrossEntropy'\n",
    "\n",
    "clf.fit(train_X, train_Y.astype(int), verbose=False)\n",
    "# cat_features=cat_features, \n",
    "# eval_set=(X_val, y_val), \n",
    "\n",
    "ypred = clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4d143bd0-9609-4f3b-9a54-84ae12ed3daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2209</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9924</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4617</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9240</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>7872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>4257</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>2273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>3628</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  Exited\n",
       "0          2209       0\n",
       "1          9924       0\n",
       "2          4617       0\n",
       "3          6077       0\n",
       "4          9240       1\n",
       "...         ...     ...\n",
       "1995       7872       0\n",
       "1996       4257       0\n",
       "1997       2273       0\n",
       "1998        315       0\n",
       "1999       3628       0\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload_13 = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload_13.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload_13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9466d39a-2c6c-43a3-9705-ad68f0a54a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_13.to_csv('upload_13.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ee127c-49fe-4c68-a2b8-217b540814bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Neural Network (36-130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee2d0656-a427-498c-8205-a1b5c49b2f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_13 (Dense)            (None, 128)               1664      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,977\n",
      "Trainable params: 10,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    " \n",
    "model = Sequential() \n",
    "model.add(Dense(128, activation='relu', input_dim=12))\n",
    "model.add(Dense(64, activation='relu')) \n",
    "model.add(Dense(16, activation='relu')) \n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64d53214-1243-466e-8a53-fd035ec5c586",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "80/80 [==============================] - 2s 5ms/step - loss: 0.7331 - accuracy: 0.7579\n",
      "Epoch 2/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.5190 - accuracy: 0.7960\n",
      "Epoch 3/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4962 - accuracy: 0.7960\n",
      "Epoch 4/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.7986\n",
      "Epoch 5/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.7989\n",
      "Epoch 6/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.8014\n",
      "Epoch 7/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.8061\n",
      "Epoch 8/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.8037\n",
      "Epoch 9/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.8061\n",
      "Epoch 10/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.8076\n",
      "Epoch 11/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.8095\n",
      "Epoch 12/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.8089\n",
      "Epoch 13/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.8060\n",
      "Epoch 14/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.8094\n",
      "Epoch 15/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.8123\n",
      "Epoch 16/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.8144\n",
      "Epoch 17/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.8140\n",
      "Epoch 18/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.8146\n",
      "Epoch 19/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.8163\n",
      "Epoch 20/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.8145\n",
      "Epoch 21/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.8188\n",
      "Epoch 22/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.8171\n",
      "Epoch 23/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.8180\n",
      "Epoch 24/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4170 - accuracy: 0.8177\n",
      "Epoch 25/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4154 - accuracy: 0.8196\n",
      "Epoch 26/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4161 - accuracy: 0.8174\n",
      "Epoch 27/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.8210\n",
      "Epoch 28/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.4057 - accuracy: 0.8220\n",
      "Epoch 29/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.4058 - accuracy: 0.8250\n",
      "Epoch 30/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3997 - accuracy: 0.8280\n",
      "Epoch 31/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4058 - accuracy: 0.8209\n",
      "Epoch 32/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3968 - accuracy: 0.8273\n",
      "Epoch 33/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3987 - accuracy: 0.8276\n",
      "Epoch 34/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3965 - accuracy: 0.8296\n",
      "Epoch 35/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3975 - accuracy: 0.8266\n",
      "Epoch 36/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3925 - accuracy: 0.8303\n",
      "Epoch 37/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3857 - accuracy: 0.8332\n",
      "Epoch 38/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3887 - accuracy: 0.8284\n",
      "Epoch 39/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3858 - accuracy: 0.8365\n",
      "Epoch 40/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3907 - accuracy: 0.8316\n",
      "Epoch 41/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3809 - accuracy: 0.8391\n",
      "Epoch 42/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3785 - accuracy: 0.8403\n",
      "Epoch 43/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3816 - accuracy: 0.8381\n",
      "Epoch 44/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3762 - accuracy: 0.8370\n",
      "Epoch 45/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3718 - accuracy: 0.8420\n",
      "Epoch 46/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3655 - accuracy: 0.8440\n",
      "Epoch 47/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3646 - accuracy: 0.8430\n",
      "Epoch 48/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3696 - accuracy: 0.8424\n",
      "Epoch 49/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3669 - accuracy: 0.8416\n",
      "Epoch 50/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3586 - accuracy: 0.8487\n",
      "Epoch 51/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3559 - accuracy: 0.8515\n",
      "Epoch 52/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3554 - accuracy: 0.8497\n",
      "Epoch 53/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3526 - accuracy: 0.8499\n",
      "Epoch 54/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3552 - accuracy: 0.8514\n",
      "Epoch 55/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3525 - accuracy: 0.8516\n",
      "Epoch 56/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3546 - accuracy: 0.8495\n",
      "Epoch 57/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3506 - accuracy: 0.8525\n",
      "Epoch 58/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3513 - accuracy: 0.8487\n",
      "Epoch 59/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3519 - accuracy: 0.8496\n",
      "Epoch 60/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3514 - accuracy: 0.8505\n",
      "Epoch 61/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3508 - accuracy: 0.8534\n",
      "Epoch 62/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3484 - accuracy: 0.8521\n",
      "Epoch 63/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3449 - accuracy: 0.8546\n",
      "Epoch 64/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3500 - accuracy: 0.8518\n",
      "Epoch 65/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3486 - accuracy: 0.8525\n",
      "Epoch 66/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3461 - accuracy: 0.8550\n",
      "Epoch 67/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3476 - accuracy: 0.8516\n",
      "Epoch 68/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3431 - accuracy: 0.8529\n",
      "Epoch 69/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3411 - accuracy: 0.8544\n",
      "Epoch 70/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3431 - accuracy: 0.8549\n",
      "Epoch 71/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3450 - accuracy: 0.8543\n",
      "Epoch 72/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3433 - accuracy: 0.8553\n",
      "Epoch 73/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3430 - accuracy: 0.8554\n",
      "Epoch 74/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3430 - accuracy: 0.8534\n",
      "Epoch 75/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3468 - accuracy: 0.8544\n",
      "Epoch 76/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3427 - accuracy: 0.8586\n",
      "Epoch 77/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3452 - accuracy: 0.8543\n",
      "Epoch 78/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3465 - accuracy: 0.8550\n",
      "Epoch 79/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3399 - accuracy: 0.8569\n",
      "Epoch 80/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3382 - accuracy: 0.8575\n",
      "Epoch 81/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3386 - accuracy: 0.8550\n",
      "Epoch 82/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3410 - accuracy: 0.8558\n",
      "Epoch 83/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3404 - accuracy: 0.8600\n",
      "Epoch 84/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3407 - accuracy: 0.8556\n",
      "Epoch 85/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3410 - accuracy: 0.8579\n",
      "Epoch 86/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3406 - accuracy: 0.8571\n",
      "Epoch 87/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3393 - accuracy: 0.8593\n",
      "Epoch 88/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3394 - accuracy: 0.8566\n",
      "Epoch 89/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3410 - accuracy: 0.8562\n",
      "Epoch 90/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3414 - accuracy: 0.8549\n",
      "Epoch 91/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3411 - accuracy: 0.8544\n",
      "Epoch 92/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3366 - accuracy: 0.8572\n",
      "Epoch 93/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3360 - accuracy: 0.8583\n",
      "Epoch 94/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3411 - accuracy: 0.8568\n",
      "Epoch 95/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3392 - accuracy: 0.8575\n",
      "Epoch 96/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3347 - accuracy: 0.8611\n",
      "Epoch 97/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3342 - accuracy: 0.8608\n",
      "Epoch 98/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3371 - accuracy: 0.8589\n",
      "Epoch 99/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3374 - accuracy: 0.8546\n",
      "Epoch 100/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3376 - accuracy: 0.8566\n",
      "Epoch 101/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3354 - accuracy: 0.8595\n",
      "Epoch 102/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3315 - accuracy: 0.8611\n",
      "Epoch 103/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3348 - accuracy: 0.8595\n",
      "Epoch 104/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3330 - accuracy: 0.8591\n",
      "Epoch 105/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3311 - accuracy: 0.8600\n",
      "Epoch 106/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3337 - accuracy: 0.8587\n",
      "Epoch 107/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3372 - accuracy: 0.8575\n",
      "Epoch 108/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3318 - accuracy: 0.8616\n",
      "Epoch 109/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3319 - accuracy: 0.8591\n",
      "Epoch 110/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3292 - accuracy: 0.8608\n",
      "Epoch 111/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3334 - accuracy: 0.8602\n",
      "Epoch 112/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3329 - accuracy: 0.8602\n",
      "Epoch 113/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3301 - accuracy: 0.8635\n",
      "Epoch 114/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3302 - accuracy: 0.8597\n",
      "Epoch 115/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3346 - accuracy: 0.8589\n",
      "Epoch 116/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3296 - accuracy: 0.8620\n",
      "Epoch 117/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3272 - accuracy: 0.8602\n",
      "Epoch 118/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3295 - accuracy: 0.8625\n",
      "Epoch 119/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3339 - accuracy: 0.8595\n",
      "Epoch 120/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3317 - accuracy: 0.8629\n",
      "Epoch 121/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3283 - accuracy: 0.8614\n",
      "Epoch 122/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3323 - accuracy: 0.8594\n",
      "Epoch 123/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3276 - accuracy: 0.8615\n",
      "Epoch 124/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3293 - accuracy: 0.8610\n",
      "Epoch 125/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3276 - accuracy: 0.8620\n",
      "Epoch 126/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3253 - accuracy: 0.8630\n",
      "Epoch 127/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3286 - accuracy: 0.8627\n",
      "Epoch 128/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3255 - accuracy: 0.8627\n",
      "Epoch 129/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3293 - accuracy: 0.8631\n",
      "Epoch 130/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3256 - accuracy: 0.8645\n",
      "Epoch 131/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3245 - accuracy: 0.8629\n",
      "Epoch 132/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3247 - accuracy: 0.8640\n",
      "Epoch 133/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3231 - accuracy: 0.8654\n",
      "Epoch 134/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3262 - accuracy: 0.8656\n",
      "Epoch 135/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3263 - accuracy: 0.8629\n",
      "Epoch 136/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3274 - accuracy: 0.8634\n",
      "Epoch 137/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3256 - accuracy: 0.8641\n",
      "Epoch 138/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3215 - accuracy: 0.8648\n",
      "Epoch 139/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3229 - accuracy: 0.8668\n",
      "Epoch 140/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3224 - accuracy: 0.8652\n",
      "Epoch 141/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3221 - accuracy: 0.8625\n",
      "Epoch 142/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3230 - accuracy: 0.8651\n",
      "Epoch 143/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3251 - accuracy: 0.8619\n",
      "Epoch 144/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3207 - accuracy: 0.8640\n",
      "Epoch 145/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3227 - accuracy: 0.8648\n",
      "Epoch 146/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3205 - accuracy: 0.8685\n",
      "Epoch 147/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3191 - accuracy: 0.8645\n",
      "Epoch 148/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3177 - accuracy: 0.8666\n",
      "Epoch 149/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3194 - accuracy: 0.8673\n",
      "Epoch 150/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3199 - accuracy: 0.8674\n",
      "Epoch 151/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3201 - accuracy: 0.8661\n",
      "Epoch 152/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3150 - accuracy: 0.8669\n",
      "Epoch 153/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3199 - accuracy: 0.8646\n",
      "Epoch 154/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3147 - accuracy: 0.8698\n",
      "Epoch 155/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3196 - accuracy: 0.8662\n",
      "Epoch 156/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3278 - accuracy: 0.8619\n",
      "Epoch 157/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3167 - accuracy: 0.8676\n",
      "Epoch 158/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3180 - accuracy: 0.8662\n",
      "Epoch 159/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3194 - accuracy: 0.8665\n",
      "Epoch 160/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3182 - accuracy: 0.8676\n",
      "Epoch 161/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3173 - accuracy: 0.8677\n",
      "Epoch 162/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3134 - accuracy: 0.8674\n",
      "Epoch 163/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3136 - accuracy: 0.8700\n",
      "Epoch 164/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3145 - accuracy: 0.8675\n",
      "Epoch 165/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3112 - accuracy: 0.8704\n",
      "Epoch 166/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3181 - accuracy: 0.8658\n",
      "Epoch 167/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3125 - accuracy: 0.8692\n",
      "Epoch 168/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3120 - accuracy: 0.8689\n",
      "Epoch 169/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3138 - accuracy: 0.8689\n",
      "Epoch 170/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3122 - accuracy: 0.8714\n",
      "Epoch 171/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3131 - accuracy: 0.8696\n",
      "Epoch 172/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3099 - accuracy: 0.8708\n",
      "Epoch 173/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3118 - accuracy: 0.8689\n",
      "Epoch 174/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3107 - accuracy: 0.8699\n",
      "Epoch 175/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3106 - accuracy: 0.8702\n",
      "Epoch 176/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3122 - accuracy: 0.8711\n",
      "Epoch 177/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3115 - accuracy: 0.8675\n",
      "Epoch 178/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3142 - accuracy: 0.8671\n",
      "Epoch 179/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3078 - accuracy: 0.8717\n",
      "Epoch 180/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3100 - accuracy: 0.8726\n",
      "Epoch 181/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3108 - accuracy: 0.8698\n",
      "Epoch 182/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3059 - accuracy: 0.8730\n",
      "Epoch 183/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3070 - accuracy: 0.8721\n",
      "Epoch 184/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3067 - accuracy: 0.8720\n",
      "Epoch 185/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3082 - accuracy: 0.8719\n",
      "Epoch 186/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3134 - accuracy: 0.8666\n",
      "Epoch 187/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3071 - accuracy: 0.8711\n",
      "Epoch 188/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3089 - accuracy: 0.8696\n",
      "Epoch 189/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3073 - accuracy: 0.8696\n",
      "Epoch 190/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3034 - accuracy: 0.8716\n",
      "Epoch 191/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3055 - accuracy: 0.8721\n",
      "Epoch 192/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3059 - accuracy: 0.8717\n",
      "Epoch 193/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3018 - accuracy: 0.8734\n",
      "Epoch 194/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3009 - accuracy: 0.8758\n",
      "Epoch 195/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3035 - accuracy: 0.8735\n",
      "Epoch 196/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3027 - accuracy: 0.8740\n",
      "Epoch 197/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3034 - accuracy: 0.8720\n",
      "Epoch 198/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3010 - accuracy: 0.8750\n",
      "Epoch 199/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2994 - accuracy: 0.8735\n",
      "Epoch 200/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3015 - accuracy: 0.8731\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ae1fbc5670>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_Y.astype(int), epochs=200, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c3a5fee-8d37-40f7-93f6-c00914550f5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.round(model.predict(test_X),0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_36.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78b32c8a-ae1a-424f-8398-dad05a63115f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model.predict(test_X)>0.5,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_37.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "716be24e-683d-4f75-8b0a-886ecd74efdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model.predict(test_X)>0.58,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_43.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a19fff34-84b7-42df-87b6-6e62248aa91b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "80/80 [==============================] - 1s 2ms/step - loss: 0.5130 - accuracy: 0.7908\n",
      "Epoch 2/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7976\n",
      "Epoch 3/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.8019\n",
      "Epoch 4/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7989\n",
      "Epoch 5/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.8069\n",
      "Epoch 6/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.8073\n",
      "Epoch 7/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.8066\n",
      "Epoch 8/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.8076\n",
      "Epoch 9/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.8120\n",
      "Epoch 10/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.8129\n",
      "Epoch 11/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.8125\n",
      "Epoch 12/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.8151\n",
      "Epoch 13/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.8141\n",
      "Epoch 14/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.8176\n",
      "Epoch 15/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4170 - accuracy: 0.8184\n",
      "Epoch 16/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.8236\n",
      "Epoch 17/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4153 - accuracy: 0.8220\n",
      "Epoch 18/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8224\n",
      "Epoch 19/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4015 - accuracy: 0.8259\n",
      "Epoch 20/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3934 - accuracy: 0.8316\n",
      "Epoch 21/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3896 - accuracy: 0.8328\n",
      "Epoch 22/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3867 - accuracy: 0.8324\n",
      "Epoch 23/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3795 - accuracy: 0.8360\n",
      "Epoch 24/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3822 - accuracy: 0.8379\n",
      "Epoch 25/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3801 - accuracy: 0.8344\n",
      "Epoch 26/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3758 - accuracy: 0.8361\n",
      "Epoch 27/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3748 - accuracy: 0.8391\n",
      "Epoch 28/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3685 - accuracy: 0.8456\n",
      "Epoch 29/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3659 - accuracy: 0.8435\n",
      "Epoch 30/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3672 - accuracy: 0.8419\n",
      "Epoch 31/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3676 - accuracy: 0.8416\n",
      "Epoch 32/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3609 - accuracy: 0.8470\n",
      "Epoch 33/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3615 - accuracy: 0.8471\n",
      "Epoch 34/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3584 - accuracy: 0.8480\n",
      "Epoch 35/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3575 - accuracy: 0.8459\n",
      "Epoch 36/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3680 - accuracy: 0.8441\n",
      "Epoch 37/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3578 - accuracy: 0.8515\n",
      "Epoch 38/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3638 - accuracy: 0.8443\n",
      "Epoch 39/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3595 - accuracy: 0.8484\n",
      "Epoch 40/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3542 - accuracy: 0.8497\n",
      "Epoch 41/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3529 - accuracy: 0.8493\n",
      "Epoch 42/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3534 - accuracy: 0.8501\n",
      "Epoch 43/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3564 - accuracy: 0.8505\n",
      "Epoch 44/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3535 - accuracy: 0.8495\n",
      "Epoch 45/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3545 - accuracy: 0.8497\n",
      "Epoch 46/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3536 - accuracy: 0.8489\n",
      "Epoch 47/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8475\n",
      "Epoch 48/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3518 - accuracy: 0.8516\n",
      "Epoch 49/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3510 - accuracy: 0.8519\n",
      "Epoch 50/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3541 - accuracy: 0.8503\n",
      "Epoch 51/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3501 - accuracy: 0.8562\n",
      "Epoch 52/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3493 - accuracy: 0.8544\n",
      "Epoch 53/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3476 - accuracy: 0.8510\n",
      "Epoch 54/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3548 - accuracy: 0.8494\n",
      "Epoch 55/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3481 - accuracy: 0.8518\n",
      "Epoch 56/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3482 - accuracy: 0.8536\n",
      "Epoch 57/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3478 - accuracy: 0.8514\n",
      "Epoch 58/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3466 - accuracy: 0.8536\n",
      "Epoch 59/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3434 - accuracy: 0.8537\n",
      "Epoch 60/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3437 - accuracy: 0.8545\n",
      "Epoch 61/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3451 - accuracy: 0.8545\n",
      "Epoch 62/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3449 - accuracy: 0.8533\n",
      "Epoch 63/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3431 - accuracy: 0.8560\n",
      "Epoch 64/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3438 - accuracy: 0.8547\n",
      "Epoch 65/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3449 - accuracy: 0.8528\n",
      "Epoch 66/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3466 - accuracy: 0.8549\n",
      "Epoch 67/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3402 - accuracy: 0.8556\n",
      "Epoch 68/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3454 - accuracy: 0.8537\n",
      "Epoch 69/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3391 - accuracy: 0.8583\n",
      "Epoch 70/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3467 - accuracy: 0.8512\n",
      "Epoch 71/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3403 - accuracy: 0.8583\n",
      "Epoch 72/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3400 - accuracy: 0.8554\n",
      "Epoch 73/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3383 - accuracy: 0.8560\n",
      "Epoch 74/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3375 - accuracy: 0.8615\n",
      "Epoch 75/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3336 - accuracy: 0.8581\n",
      "Epoch 76/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3357 - accuracy: 0.8576\n",
      "Epoch 77/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3360 - accuracy: 0.8600\n",
      "Epoch 78/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3357 - accuracy: 0.8577\n",
      "Epoch 79/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8579\n",
      "Epoch 80/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3362 - accuracy: 0.8589\n",
      "Epoch 81/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3365 - accuracy: 0.8581\n",
      "Epoch 82/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8600\n",
      "Epoch 83/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3363 - accuracy: 0.8602\n",
      "Epoch 84/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3345 - accuracy: 0.8591\n",
      "Epoch 85/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3345 - accuracy: 0.8575\n",
      "Epoch 86/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3317 - accuracy: 0.8600\n",
      "Epoch 87/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3316 - accuracy: 0.8605\n",
      "Epoch 88/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3316 - accuracy: 0.8597\n",
      "Epoch 89/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3292 - accuracy: 0.8621\n",
      "Epoch 90/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3303 - accuracy: 0.8602\n",
      "Epoch 91/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3307 - accuracy: 0.8637\n",
      "Epoch 92/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3297 - accuracy: 0.8606\n",
      "Epoch 93/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3308 - accuracy: 0.8621\n",
      "Epoch 94/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3356 - accuracy: 0.8591\n",
      "Epoch 95/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3283 - accuracy: 0.8651\n",
      "Epoch 96/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3290 - accuracy: 0.8634\n",
      "Epoch 97/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3255 - accuracy: 0.8665\n",
      "Epoch 98/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3262 - accuracy: 0.8650\n",
      "Epoch 99/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3272 - accuracy: 0.8636\n",
      "Epoch 100/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3256 - accuracy: 0.8645\n",
      "Epoch 101/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3262 - accuracy: 0.8656\n",
      "Epoch 102/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3218 - accuracy: 0.8644\n",
      "Epoch 103/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3250 - accuracy: 0.8651\n",
      "Epoch 104/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3233 - accuracy: 0.8660\n",
      "Epoch 105/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3237 - accuracy: 0.8651\n",
      "Epoch 106/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3211 - accuracy: 0.8669\n",
      "Epoch 107/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 0.8652\n",
      "Epoch 108/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3199 - accuracy: 0.8669\n",
      "Epoch 109/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3272 - accuracy: 0.8652\n",
      "Epoch 110/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3200 - accuracy: 0.8687\n",
      "Epoch 111/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3279 - accuracy: 0.8660\n",
      "Epoch 112/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3258 - accuracy: 0.8618\n",
      "Epoch 113/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3182 - accuracy: 0.8680\n",
      "Epoch 114/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3220 - accuracy: 0.8665\n",
      "Epoch 115/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3219 - accuracy: 0.8655\n",
      "Epoch 116/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3215 - accuracy: 0.8635\n",
      "Epoch 117/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3200 - accuracy: 0.8687\n",
      "Epoch 118/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3171 - accuracy: 0.8674\n",
      "Epoch 119/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.8651\n",
      "Epoch 120/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3193 - accuracy: 0.8695\n",
      "Epoch 121/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3178 - accuracy: 0.8709\n",
      "Epoch 122/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3192 - accuracy: 0.8654\n",
      "Epoch 123/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3210 - accuracy: 0.8695\n",
      "Epoch 124/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3208 - accuracy: 0.8655\n",
      "Epoch 125/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3149 - accuracy: 0.8665\n",
      "Epoch 126/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3165 - accuracy: 0.8668\n",
      "Epoch 127/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3161 - accuracy: 0.8691\n",
      "Epoch 128/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3151 - accuracy: 0.8717\n",
      "Epoch 129/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3145 - accuracy: 0.8687\n",
      "Epoch 130/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3162 - accuracy: 0.8683\n",
      "Epoch 131/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3158 - accuracy: 0.8702\n",
      "Epoch 132/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3136 - accuracy: 0.8701\n",
      "Epoch 133/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3139 - accuracy: 0.8711\n",
      "Epoch 134/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3139 - accuracy: 0.8705\n",
      "Epoch 135/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3168 - accuracy: 0.8659\n",
      "Epoch 136/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3149 - accuracy: 0.8714\n",
      "Epoch 137/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3099 - accuracy: 0.8729\n",
      "Epoch 138/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3165 - accuracy: 0.8664\n",
      "Epoch 139/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3145 - accuracy: 0.8684\n",
      "Epoch 140/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3127 - accuracy: 0.8696\n",
      "Epoch 141/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3131 - accuracy: 0.8698\n",
      "Epoch 142/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3148 - accuracy: 0.8677\n",
      "Epoch 143/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3121 - accuracy: 0.8694\n",
      "Epoch 144/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3139 - accuracy: 0.8701\n",
      "Epoch 145/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3086 - accuracy: 0.8716\n",
      "Epoch 146/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3093 - accuracy: 0.8709\n",
      "Epoch 147/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3106 - accuracy: 0.8712\n",
      "Epoch 148/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3108 - accuracy: 0.8705\n",
      "Epoch 149/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3116 - accuracy: 0.8705\n",
      "Epoch 150/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3082 - accuracy: 0.8723\n",
      "Epoch 151/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3097 - accuracy: 0.8699\n",
      "Epoch 152/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3085 - accuracy: 0.8734\n",
      "Epoch 153/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3080 - accuracy: 0.8730\n",
      "Epoch 154/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3166 - accuracy: 0.8710\n",
      "Epoch 155/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3054 - accuracy: 0.8709\n",
      "Epoch 156/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3057 - accuracy: 0.8685\n",
      "Epoch 157/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3024 - accuracy: 0.8685\n",
      "Epoch 158/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3069 - accuracy: 0.8721\n",
      "Epoch 159/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3113 - accuracy: 0.8702\n",
      "Epoch 160/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3050 - accuracy: 0.8742\n",
      "Epoch 161/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3071 - accuracy: 0.8719\n",
      "Epoch 162/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3014 - accuracy: 0.8755\n",
      "Epoch 163/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3025 - accuracy: 0.8748\n",
      "Epoch 164/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3060 - accuracy: 0.8710\n",
      "Epoch 165/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3050 - accuracy: 0.8729\n",
      "Epoch 166/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3026 - accuracy: 0.8741\n",
      "Epoch 167/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3021 - accuracy: 0.8740\n",
      "Epoch 168/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3001 - accuracy: 0.8752\n",
      "Epoch 169/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3022 - accuracy: 0.8759\n",
      "Epoch 170/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3022 - accuracy: 0.8752\n",
      "Epoch 171/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3009 - accuracy: 0.8724\n",
      "Epoch 172/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3053 - accuracy: 0.8725\n",
      "Epoch 173/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3010 - accuracy: 0.8739\n",
      "Epoch 174/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2982 - accuracy: 0.8758\n",
      "Epoch 175/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2981 - accuracy: 0.8761\n",
      "Epoch 176/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2961 - accuracy: 0.8751\n",
      "Epoch 177/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2992 - accuracy: 0.8739\n",
      "Epoch 178/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2983 - accuracy: 0.8763\n",
      "Epoch 179/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2999 - accuracy: 0.8739\n",
      "Epoch 180/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2997 - accuracy: 0.8751\n",
      "Epoch 181/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2966 - accuracy: 0.8748\n",
      "Epoch 182/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2962 - accuracy: 0.8721\n",
      "Epoch 183/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2953 - accuracy: 0.8770\n",
      "Epoch 184/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2954 - accuracy: 0.8759\n",
      "Epoch 185/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2951 - accuracy: 0.8752\n",
      "Epoch 186/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2946 - accuracy: 0.8773\n",
      "Epoch 187/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2930 - accuracy: 0.8765\n",
      "Epoch 188/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2982 - accuracy: 0.8761\n",
      "Epoch 189/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2930 - accuracy: 0.8776\n",
      "Epoch 190/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2938 - accuracy: 0.8780\n",
      "Epoch 191/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2935 - accuracy: 0.8771\n",
      "Epoch 192/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2901 - accuracy: 0.8781\n",
      "Epoch 193/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2897 - accuracy: 0.8777\n",
      "Epoch 194/200\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2926 - accuracy: 0.8789\n",
      "Epoch 195/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2946 - accuracy: 0.8761\n",
      "Epoch 196/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2940 - accuracy: 0.8750\n",
      "Epoch 197/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2941 - accuracy: 0.8777\n",
      "Epoch 198/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2892 - accuracy: 0.8742\n",
      "Epoch 199/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2889 - accuracy: 0.8802\n",
      "Epoch 200/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2913 - accuracy: 0.8756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2bc4278caf0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_Y.astype(int), epochs=200, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "076d3c1f-0152-433d-868a-feeb904e2759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model.predict(test_X)>0.5,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_39.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c265dd9f-ff99-43ad-a0bb-89a3e7feae98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               1664      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,545\n",
      "Trainable params: 12,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    " \n",
    "model = Sequential() \n",
    "model.add(Dense(128, activation='relu', input_dim=12))\n",
    "model.add(Dense(64, activation='relu')) \n",
    "model.add(Dense(32, activation='relu')) \n",
    "model.add(Dense(16, activation='relu')) \n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "093da9ba-46f1-475d-8e8d-5abf2ed3e178",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "80/80 [==============================] - 2s 4ms/step - loss: 0.5181 - accuracy: 0.7958\n",
      "Epoch 2/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.4820 - accuracy: 0.7962\n",
      "Epoch 3/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.7996\n",
      "Epoch 4/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.4549 - accuracy: 0.8039\n",
      "Epoch 5/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.8059\n",
      "Epoch 6/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.8036\n",
      "Epoch 7/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.8079\n",
      "Epoch 8/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.8065\n",
      "Epoch 9/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.8096\n",
      "Epoch 10/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8119\n",
      "Epoch 11/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.8173\n",
      "Epoch 12/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.4099 - accuracy: 0.8199\n",
      "Epoch 13/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.4120 - accuracy: 0.8238\n",
      "Epoch 14/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.4026 - accuracy: 0.8227\n",
      "Epoch 15/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3922 - accuracy: 0.8267\n",
      "Epoch 16/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3871 - accuracy: 0.8322\n",
      "Epoch 17/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3801 - accuracy: 0.8364\n",
      "Epoch 18/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3820 - accuracy: 0.8372\n",
      "Epoch 19/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3795 - accuracy: 0.8335\n",
      "Epoch 20/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3705 - accuracy: 0.8405\n",
      "Epoch 21/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3701 - accuracy: 0.8400\n",
      "Epoch 22/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3673 - accuracy: 0.8420\n",
      "Epoch 23/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3761 - accuracy: 0.8378\n",
      "Epoch 24/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3660 - accuracy: 0.8395\n",
      "Epoch 25/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3755 - accuracy: 0.8367\n",
      "Epoch 26/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3677 - accuracy: 0.8416\n",
      "Epoch 27/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3626 - accuracy: 0.8455\n",
      "Epoch 28/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3640 - accuracy: 0.8418\n",
      "Epoch 29/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3645 - accuracy: 0.8426\n",
      "Epoch 30/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3606 - accuracy: 0.8428\n",
      "Epoch 31/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3639 - accuracy: 0.8453\n",
      "Epoch 32/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3593 - accuracy: 0.8469\n",
      "Epoch 33/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3584 - accuracy: 0.8475\n",
      "Epoch 34/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3636 - accuracy: 0.8454\n",
      "Epoch 35/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3596 - accuracy: 0.8528\n",
      "Epoch 36/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3536 - accuracy: 0.8500\n",
      "Epoch 37/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3546 - accuracy: 0.8519\n",
      "Epoch 38/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3555 - accuracy: 0.8505\n",
      "Epoch 39/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3529 - accuracy: 0.8516\n",
      "Epoch 40/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3548 - accuracy: 0.8511\n",
      "Epoch 41/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3554 - accuracy: 0.8484\n",
      "Epoch 42/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3533 - accuracy: 0.8534\n",
      "Epoch 43/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3536 - accuracy: 0.8520\n",
      "Epoch 44/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3502 - accuracy: 0.8510\n",
      "Epoch 45/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3556 - accuracy: 0.8503\n",
      "Epoch 46/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3483 - accuracy: 0.8525\n",
      "Epoch 47/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3460 - accuracy: 0.8543\n",
      "Epoch 48/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3462 - accuracy: 0.8541\n",
      "Epoch 49/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3474 - accuracy: 0.8540\n",
      "Epoch 50/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3470 - accuracy: 0.8531\n",
      "Epoch 51/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3472 - accuracy: 0.8541\n",
      "Epoch 52/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3540 - accuracy: 0.8524\n",
      "Epoch 53/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3419 - accuracy: 0.8572\n",
      "Epoch 54/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3453 - accuracy: 0.8551\n",
      "Epoch 55/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3452 - accuracy: 0.8568\n",
      "Epoch 56/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3472 - accuracy: 0.8583\n",
      "Epoch 57/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3438 - accuracy: 0.8544\n",
      "Epoch 58/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3412 - accuracy: 0.8571\n",
      "Epoch 59/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3426 - accuracy: 0.8558\n",
      "Epoch 60/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3401 - accuracy: 0.8569\n",
      "Epoch 61/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3428 - accuracy: 0.8576\n",
      "Epoch 62/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3428 - accuracy: 0.8602\n",
      "Epoch 63/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3426 - accuracy: 0.8577\n",
      "Epoch 64/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3392 - accuracy: 0.8571\n",
      "Epoch 65/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3378 - accuracy: 0.8589\n",
      "Epoch 66/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3399 - accuracy: 0.8593\n",
      "Epoch 67/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3358 - accuracy: 0.8616\n",
      "Epoch 68/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3361 - accuracy: 0.8611\n",
      "Epoch 69/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3343 - accuracy: 0.8612\n",
      "Epoch 70/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3374 - accuracy: 0.8615\n",
      "Epoch 71/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3324 - accuracy: 0.8622\n",
      "Epoch 72/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3375 - accuracy: 0.8572\n",
      "Epoch 73/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3331 - accuracy: 0.8618\n",
      "Epoch 74/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3343 - accuracy: 0.8621\n",
      "Epoch 75/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3344 - accuracy: 0.8581\n",
      "Epoch 76/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3413 - accuracy: 0.8562\n",
      "Epoch 77/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3366 - accuracy: 0.8605\n",
      "Epoch 78/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3341 - accuracy: 0.8619\n",
      "Epoch 79/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3302 - accuracy: 0.8631\n",
      "Epoch 80/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3428 - accuracy: 0.8575\n",
      "Epoch 81/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3329 - accuracy: 0.8610\n",
      "Epoch 82/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3334 - accuracy: 0.8593\n",
      "Epoch 83/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3330 - accuracy: 0.8612\n",
      "Epoch 84/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3302 - accuracy: 0.8616\n",
      "Epoch 85/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3304 - accuracy: 0.8633\n",
      "Epoch 86/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3296 - accuracy: 0.8636\n",
      "Epoch 87/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3268 - accuracy: 0.8646\n",
      "Epoch 88/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3300 - accuracy: 0.8631\n",
      "Epoch 89/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3263 - accuracy: 0.8645\n",
      "Epoch 90/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3290 - accuracy: 0.8619\n",
      "Epoch 91/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3270 - accuracy: 0.8644\n",
      "Epoch 92/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3265 - accuracy: 0.8644\n",
      "Epoch 93/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3258 - accuracy: 0.8649\n",
      "Epoch 94/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3277 - accuracy: 0.8633\n",
      "Epoch 95/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3273 - accuracy: 0.8656\n",
      "Epoch 96/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3315 - accuracy: 0.8640\n",
      "Epoch 97/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3322 - accuracy: 0.8622\n",
      "Epoch 98/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3254 - accuracy: 0.8650\n",
      "Epoch 99/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3269 - accuracy: 0.8624\n",
      "Epoch 100/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3244 - accuracy: 0.8664\n",
      "Epoch 101/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3230 - accuracy: 0.8665\n",
      "Epoch 102/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3244 - accuracy: 0.8661\n",
      "Epoch 103/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3255 - accuracy: 0.8637\n",
      "Epoch 104/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3275 - accuracy: 0.8640\n",
      "Epoch 105/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3230 - accuracy: 0.8646\n",
      "Epoch 106/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3245 - accuracy: 0.8658\n",
      "Epoch 107/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3223 - accuracy: 0.8662\n",
      "Epoch 108/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3207 - accuracy: 0.8655\n",
      "Epoch 109/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3203 - accuracy: 0.8655\n",
      "Epoch 110/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3222 - accuracy: 0.8652\n",
      "Epoch 111/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3250 - accuracy: 0.8674\n",
      "Epoch 112/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3254 - accuracy: 0.8651\n",
      "Epoch 113/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3182 - accuracy: 0.8662\n",
      "Epoch 114/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3228 - accuracy: 0.8675\n",
      "Epoch 115/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3213 - accuracy: 0.8656\n",
      "Epoch 116/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3227 - accuracy: 0.8660\n",
      "Epoch 117/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3195 - accuracy: 0.8675\n",
      "Epoch 118/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3180 - accuracy: 0.8669\n",
      "Epoch 119/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3165 - accuracy: 0.8681\n",
      "Epoch 120/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3158 - accuracy: 0.8680\n",
      "Epoch 121/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3171 - accuracy: 0.8665\n",
      "Epoch 122/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3189 - accuracy: 0.8675\n",
      "Epoch 123/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3145 - accuracy: 0.8673\n",
      "Epoch 124/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3183 - accuracy: 0.8674\n",
      "Epoch 125/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3156 - accuracy: 0.8675\n",
      "Epoch 126/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3151 - accuracy: 0.8675\n",
      "Epoch 127/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3165 - accuracy: 0.8662\n",
      "Epoch 128/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3147 - accuracy: 0.8666\n",
      "Epoch 129/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3139 - accuracy: 0.8701\n",
      "Epoch 130/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3138 - accuracy: 0.8692\n",
      "Epoch 131/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3115 - accuracy: 0.8681\n",
      "Epoch 132/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3114 - accuracy: 0.8677\n",
      "Epoch 133/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3120 - accuracy: 0.8675\n",
      "Epoch 134/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3094 - accuracy: 0.8696\n",
      "Epoch 135/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3122 - accuracy: 0.8679\n",
      "Epoch 136/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3109 - accuracy: 0.8687\n",
      "Epoch 137/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3072 - accuracy: 0.8716\n",
      "Epoch 138/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3088 - accuracy: 0.8700\n",
      "Epoch 139/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3098 - accuracy: 0.8695\n",
      "Epoch 140/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3053 - accuracy: 0.8708\n",
      "Epoch 141/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3078 - accuracy: 0.8712\n",
      "Epoch 142/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3091 - accuracy: 0.8702\n",
      "Epoch 143/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3113 - accuracy: 0.8702\n",
      "Epoch 144/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3052 - accuracy: 0.8708\n",
      "Epoch 145/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3077 - accuracy: 0.8661\n",
      "Epoch 146/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3061 - accuracy: 0.8708\n",
      "Epoch 147/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3051 - accuracy: 0.8710\n",
      "Epoch 148/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3073 - accuracy: 0.8696\n",
      "Epoch 149/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3110 - accuracy: 0.8677\n",
      "Epoch 150/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3063 - accuracy: 0.8711\n",
      "Epoch 151/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3020 - accuracy: 0.8717\n",
      "Epoch 152/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3022 - accuracy: 0.8701\n",
      "Epoch 153/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3032 - accuracy: 0.8706\n",
      "Epoch 154/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2990 - accuracy: 0.8721\n",
      "Epoch 155/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2991 - accuracy: 0.8734\n",
      "Epoch 156/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3026 - accuracy: 0.8696\n",
      "Epoch 157/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3054 - accuracy: 0.8700\n",
      "Epoch 158/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2984 - accuracy: 0.8714\n",
      "Epoch 159/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2978 - accuracy: 0.8731\n",
      "Epoch 160/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2982 - accuracy: 0.8726\n",
      "Epoch 161/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2989 - accuracy: 0.8705\n",
      "Epoch 162/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3044 - accuracy: 0.8711\n",
      "Epoch 163/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2967 - accuracy: 0.8698\n",
      "Epoch 164/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2971 - accuracy: 0.8727\n",
      "Epoch 165/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2967 - accuracy: 0.8734\n",
      "Epoch 166/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2966 - accuracy: 0.8742\n",
      "Epoch 167/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2920 - accuracy: 0.8752\n",
      "Epoch 168/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2966 - accuracy: 0.8723\n",
      "Epoch 169/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2898 - accuracy: 0.8741\n",
      "Epoch 170/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2906 - accuracy: 0.8750\n",
      "Epoch 171/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2926 - accuracy: 0.8737\n",
      "Epoch 172/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2954 - accuracy: 0.8754\n",
      "Epoch 173/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2929 - accuracy: 0.8759\n",
      "Epoch 174/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2930 - accuracy: 0.8721\n",
      "Epoch 175/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2877 - accuracy: 0.8746\n",
      "Epoch 176/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2860 - accuracy: 0.8791\n",
      "Epoch 177/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2927 - accuracy: 0.8720\n",
      "Epoch 178/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2851 - accuracy: 0.8785\n",
      "Epoch 179/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2904 - accuracy: 0.8771\n",
      "Epoch 180/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2889 - accuracy: 0.8756\n",
      "Epoch 181/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2832 - accuracy: 0.8785\n",
      "Epoch 182/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2885 - accuracy: 0.8754\n",
      "Epoch 183/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2866 - accuracy: 0.8775\n",
      "Epoch 184/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2844 - accuracy: 0.8780\n",
      "Epoch 185/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2812 - accuracy: 0.8805\n",
      "Epoch 186/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2897 - accuracy: 0.8748\n",
      "Epoch 187/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2827 - accuracy: 0.8775\n",
      "Epoch 188/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2801 - accuracy: 0.8777\n",
      "Epoch 189/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2777 - accuracy: 0.8796\n",
      "Epoch 190/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2799 - accuracy: 0.8805\n",
      "Epoch 191/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2833 - accuracy: 0.8795\n",
      "Epoch 192/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2792 - accuracy: 0.8767\n",
      "Epoch 193/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2843 - accuracy: 0.8752\n",
      "Epoch 194/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2780 - accuracy: 0.8774\n",
      "Epoch 195/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2797 - accuracy: 0.8785\n",
      "Epoch 196/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2780 - accuracy: 0.8792\n",
      "Epoch 197/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2744 - accuracy: 0.8825\n",
      "Epoch 198/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2743 - accuracy: 0.8804\n",
      "Epoch 199/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2753 - accuracy: 0.8784\n",
      "Epoch 200/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2739 - accuracy: 0.8770\n",
      "Epoch 201/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2739 - accuracy: 0.8815\n",
      "Epoch 202/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2751 - accuracy: 0.8811\n",
      "Epoch 203/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2724 - accuracy: 0.8789\n",
      "Epoch 204/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2720 - accuracy: 0.8832\n",
      "Epoch 205/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2668 - accuracy: 0.8851\n",
      "Epoch 206/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2703 - accuracy: 0.8826\n",
      "Epoch 207/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2673 - accuracy: 0.8814\n",
      "Epoch 208/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2722 - accuracy: 0.8826\n",
      "Epoch 209/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2700 - accuracy: 0.8824\n",
      "Epoch 210/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2832 - accuracy: 0.8767\n",
      "Epoch 211/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2735 - accuracy: 0.8829\n",
      "Epoch 212/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2656 - accuracy: 0.8831\n",
      "Epoch 213/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2707 - accuracy: 0.8809\n",
      "Epoch 214/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2681 - accuracy: 0.8814\n",
      "Epoch 215/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2681 - accuracy: 0.8825\n",
      "Epoch 216/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2693 - accuracy: 0.8832\n",
      "Epoch 217/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2647 - accuracy: 0.8829\n",
      "Epoch 218/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2584 - accuracy: 0.8866\n",
      "Epoch 219/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2590 - accuracy: 0.8886\n",
      "Epoch 220/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2626 - accuracy: 0.8844\n",
      "Epoch 221/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2616 - accuracy: 0.8838\n",
      "Epoch 222/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2646 - accuracy: 0.8839\n",
      "Epoch 223/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2588 - accuracy: 0.8863\n",
      "Epoch 224/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2556 - accuracy: 0.8900\n",
      "Epoch 225/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2562 - accuracy: 0.8861\n",
      "Epoch 226/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2540 - accuracy: 0.8903\n",
      "Epoch 227/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2573 - accuracy: 0.8859\n",
      "Epoch 228/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2547 - accuracy: 0.8867\n",
      "Epoch 229/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2583 - accuracy: 0.8879\n",
      "Epoch 230/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2517 - accuracy: 0.8903\n",
      "Epoch 231/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2531 - accuracy: 0.8900\n",
      "Epoch 232/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2625 - accuracy: 0.8886\n",
      "Epoch 233/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2513 - accuracy: 0.8911\n",
      "Epoch 234/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2504 - accuracy: 0.8901\n",
      "Epoch 235/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2482 - accuracy: 0.8882\n",
      "Epoch 236/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2584 - accuracy: 0.8855\n",
      "Epoch 237/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2468 - accuracy: 0.8936\n",
      "Epoch 238/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2480 - accuracy: 0.8878\n",
      "Epoch 239/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2519 - accuracy: 0.8889\n",
      "Epoch 240/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2509 - accuracy: 0.8921\n",
      "Epoch 241/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2471 - accuracy: 0.8917\n",
      "Epoch 242/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2500 - accuracy: 0.8884\n",
      "Epoch 243/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.8914\n",
      "Epoch 244/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2563 - accuracy: 0.8861\n",
      "Epoch 245/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2456 - accuracy: 0.8909\n",
      "Epoch 246/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2438 - accuracy: 0.8941\n",
      "Epoch 247/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2428 - accuracy: 0.8929\n",
      "Epoch 248/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2401 - accuracy: 0.8929\n",
      "Epoch 249/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2402 - accuracy: 0.8934\n",
      "Epoch 250/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2517 - accuracy: 0.8882\n",
      "Epoch 251/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2515 - accuracy: 0.8891\n",
      "Epoch 252/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2449 - accuracy: 0.8921\n",
      "Epoch 253/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2418 - accuracy: 0.8909\n",
      "Epoch 254/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2375 - accuracy: 0.8950\n",
      "Epoch 255/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2397 - accuracy: 0.8919\n",
      "Epoch 256/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2406 - accuracy: 0.8929\n",
      "Epoch 257/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2387 - accuracy: 0.8939\n",
      "Epoch 258/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2359 - accuracy: 0.8972\n",
      "Epoch 259/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2339 - accuracy: 0.8940\n",
      "Epoch 260/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2316 - accuracy: 0.8966\n",
      "Epoch 261/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2324 - accuracy: 0.8969\n",
      "Epoch 262/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2336 - accuracy: 0.8953\n",
      "Epoch 263/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2386 - accuracy: 0.8940\n",
      "Epoch 264/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2379 - accuracy: 0.8915\n",
      "Epoch 265/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2290 - accuracy: 0.8972\n",
      "Epoch 266/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2335 - accuracy: 0.8934\n",
      "Epoch 267/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2323 - accuracy: 0.8978\n",
      "Epoch 268/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2341 - accuracy: 0.8925\n",
      "Epoch 269/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2366 - accuracy: 0.8929\n",
      "Epoch 270/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2268 - accuracy: 0.8986\n",
      "Epoch 271/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2350 - accuracy: 0.8957\n",
      "Epoch 272/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2309 - accuracy: 0.8960\n",
      "Epoch 273/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2279 - accuracy: 0.8972\n",
      "Epoch 274/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2284 - accuracy: 0.8971\n",
      "Epoch 275/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2356 - accuracy: 0.8938\n",
      "Epoch 276/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2217 - accuracy: 0.9007\n",
      "Epoch 277/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2247 - accuracy: 0.8988\n",
      "Epoch 278/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2274 - accuracy: 0.8955\n",
      "Epoch 279/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2200 - accuracy: 0.9018\n",
      "Epoch 280/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2219 - accuracy: 0.9013\n",
      "Epoch 281/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2216 - accuracy: 0.8985\n",
      "Epoch 282/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2316 - accuracy: 0.8942\n",
      "Epoch 283/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2289 - accuracy: 0.8955\n",
      "Epoch 284/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2338 - accuracy: 0.8970\n",
      "Epoch 285/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2283 - accuracy: 0.8953\n",
      "Epoch 286/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2312 - accuracy: 0.8971\n",
      "Epoch 287/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2205 - accuracy: 0.8999\n",
      "Epoch 288/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2226 - accuracy: 0.8986\n",
      "Epoch 289/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2172 - accuracy: 0.9013\n",
      "Epoch 290/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2158 - accuracy: 0.9043\n",
      "Epoch 291/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2173 - accuracy: 0.9022\n",
      "Epoch 292/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2211 - accuracy: 0.9005\n",
      "Epoch 293/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2214 - accuracy: 0.9015\n",
      "Epoch 294/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2155 - accuracy: 0.9010\n",
      "Epoch 295/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2219 - accuracy: 0.9009\n",
      "Epoch 296/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2127 - accuracy: 0.9034\n",
      "Epoch 297/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2126 - accuracy: 0.9016\n",
      "Epoch 298/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2104 - accuracy: 0.9055\n",
      "Epoch 299/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2266 - accuracy: 0.8970\n",
      "Epoch 300/300\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2144 - accuracy: 0.9035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ae1a2d5a90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_Y.astype(int), epochs=300, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af7969b9-f669-420d-82e5-d0008d8909ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model.predict(test_X)>0.5,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_40.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ed7bb55-306f-4f1a-86a5-51d38b1ca628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 128)               1664      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,545\n",
      "Trainable params: 12,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    " \n",
    "model = Sequential() \n",
    "model.add(Dense(128, activation='relu', input_dim=12))\n",
    "model.add(Dense(64, activation='relu')) \n",
    "model.add(Dense(32, activation='relu')) \n",
    "model.add(Dense(16, activation='relu')) \n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d2af27d-a02d-4994-9067-129efcf9f3b5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.4557 - accuracy: 0.8034\n",
      "Epoch 2/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.4508 - accuracy: 0.8052\n",
      "Epoch 3/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.4427 - accuracy: 0.8111\n",
      "Epoch 4/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.4380 - accuracy: 0.8110\n",
      "Epoch 5/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.4308 - accuracy: 0.8125\n",
      "Epoch 6/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.4238 - accuracy: 0.8144\n",
      "Epoch 7/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.4051 - accuracy: 0.8204\n",
      "Epoch 8/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3963 - accuracy: 0.8284\n",
      "Epoch 9/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3876 - accuracy: 0.8317\n",
      "Epoch 10/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3765 - accuracy: 0.8401\n",
      "Epoch 11/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3772 - accuracy: 0.8399\n",
      "Epoch 12/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3694 - accuracy: 0.8450\n",
      "Epoch 13/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3635 - accuracy: 0.8432\n",
      "Epoch 14/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3604 - accuracy: 0.8505\n",
      "Epoch 15/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3574 - accuracy: 0.8516\n",
      "Epoch 16/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3575 - accuracy: 0.8512\n",
      "Epoch 17/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3541 - accuracy: 0.8497\n",
      "Epoch 18/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3533 - accuracy: 0.8511\n",
      "Epoch 19/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3523 - accuracy: 0.8541\n",
      "Epoch 20/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3485 - accuracy: 0.8536\n",
      "Epoch 21/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3498 - accuracy: 0.8533\n",
      "Epoch 22/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3500 - accuracy: 0.8550\n",
      "Epoch 23/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3420 - accuracy: 0.8593\n",
      "Epoch 24/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3427 - accuracy: 0.8581\n",
      "Epoch 25/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3460 - accuracy: 0.8570\n",
      "Epoch 26/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3410 - accuracy: 0.8593\n",
      "Epoch 27/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3404 - accuracy: 0.8584\n",
      "Epoch 28/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3399 - accuracy: 0.8612\n",
      "Epoch 29/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3375 - accuracy: 0.8583\n",
      "Epoch 30/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3348 - accuracy: 0.8604\n",
      "Epoch 31/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3344 - accuracy: 0.8620\n",
      "Epoch 32/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3342 - accuracy: 0.8635\n",
      "Epoch 33/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3363 - accuracy: 0.8621\n",
      "Epoch 34/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3303 - accuracy: 0.8627\n",
      "Epoch 35/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3326 - accuracy: 0.8609\n",
      "Epoch 36/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3307 - accuracy: 0.8639\n",
      "Epoch 37/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3299 - accuracy: 0.8626\n",
      "Epoch 38/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3285 - accuracy: 0.8625\n",
      "Epoch 39/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3273 - accuracy: 0.8619\n",
      "Epoch 40/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3267 - accuracy: 0.8616\n",
      "Epoch 41/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3273 - accuracy: 0.8629\n",
      "Epoch 42/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3250 - accuracy: 0.8643\n",
      "Epoch 43/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3246 - accuracy: 0.8640\n",
      "Epoch 44/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3217 - accuracy: 0.8668\n",
      "Epoch 45/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3191 - accuracy: 0.8683\n",
      "Epoch 46/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3184 - accuracy: 0.8639\n",
      "Epoch 47/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3163 - accuracy: 0.8680\n",
      "Epoch 48/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3165 - accuracy: 0.8659\n",
      "Epoch 49/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3144 - accuracy: 0.8680\n",
      "Epoch 50/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3130 - accuracy: 0.8673\n",
      "Epoch 51/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3137 - accuracy: 0.8660\n",
      "Epoch 52/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3100 - accuracy: 0.8691\n",
      "Epoch 53/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3117 - accuracy: 0.8702\n",
      "Epoch 54/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3114 - accuracy: 0.8675\n",
      "Epoch 55/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3114 - accuracy: 0.8694\n",
      "Epoch 56/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3061 - accuracy: 0.8696\n",
      "Epoch 57/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3056 - accuracy: 0.8687\n",
      "Epoch 58/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3060 - accuracy: 0.8685\n",
      "Epoch 59/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3042 - accuracy: 0.8686\n",
      "Epoch 60/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3012 - accuracy: 0.8711\n",
      "Epoch 61/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.3033 - accuracy: 0.8725\n",
      "Epoch 62/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2981 - accuracy: 0.8727\n",
      "Epoch 63/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2982 - accuracy: 0.8712\n",
      "Epoch 64/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2950 - accuracy: 0.8723\n",
      "Epoch 65/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2960 - accuracy: 0.8727\n",
      "Epoch 66/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2965 - accuracy: 0.8726\n",
      "Epoch 67/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2914 - accuracy: 0.8734\n",
      "Epoch 68/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2956 - accuracy: 0.8730\n",
      "Epoch 69/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2878 - accuracy: 0.8780\n",
      "Epoch 70/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2918 - accuracy: 0.8733\n",
      "Epoch 71/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2874 - accuracy: 0.8763\n",
      "Epoch 72/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2850 - accuracy: 0.8786\n",
      "Epoch 73/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2846 - accuracy: 0.8767\n",
      "Epoch 74/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2850 - accuracy: 0.8786\n",
      "Epoch 75/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2842 - accuracy: 0.8784\n",
      "Epoch 76/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2818 - accuracy: 0.8783\n",
      "Epoch 77/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2865 - accuracy: 0.8755\n",
      "Epoch 78/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2806 - accuracy: 0.8798\n",
      "Epoch 79/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2815 - accuracy: 0.8780\n",
      "Epoch 80/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2765 - accuracy: 0.8831\n",
      "Epoch 81/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2799 - accuracy: 0.8796\n",
      "Epoch 82/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2777 - accuracy: 0.8790\n",
      "Epoch 83/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2714 - accuracy: 0.8845\n",
      "Epoch 84/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2759 - accuracy: 0.8809\n",
      "Epoch 85/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2698 - accuracy: 0.8839\n",
      "Epoch 86/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2704 - accuracy: 0.8838\n",
      "Epoch 87/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2718 - accuracy: 0.8848\n",
      "Epoch 88/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2710 - accuracy: 0.8852\n",
      "Epoch 89/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2686 - accuracy: 0.8825\n",
      "Epoch 90/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2635 - accuracy: 0.8826\n",
      "Epoch 91/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2668 - accuracy: 0.8860\n",
      "Epoch 92/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2661 - accuracy: 0.8808\n",
      "Epoch 93/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2626 - accuracy: 0.8844\n",
      "Epoch 94/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2675 - accuracy: 0.8855\n",
      "Epoch 95/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2611 - accuracy: 0.8863\n",
      "Epoch 96/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2623 - accuracy: 0.8906\n",
      "Epoch 97/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2626 - accuracy: 0.8854\n",
      "Epoch 98/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2648 - accuracy: 0.8852\n",
      "Epoch 99/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2557 - accuracy: 0.8896\n",
      "Epoch 100/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2585 - accuracy: 0.8856\n",
      "Epoch 101/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2607 - accuracy: 0.8854\n",
      "Epoch 102/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2528 - accuracy: 0.8896\n",
      "Epoch 103/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2521 - accuracy: 0.8886\n",
      "Epoch 104/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2517 - accuracy: 0.8898\n",
      "Epoch 105/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2568 - accuracy: 0.8885\n",
      "Epoch 106/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2532 - accuracy: 0.8889\n",
      "Epoch 107/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2472 - accuracy: 0.8920\n",
      "Epoch 108/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2481 - accuracy: 0.8901\n",
      "Epoch 109/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2471 - accuracy: 0.8909\n",
      "Epoch 110/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2480 - accuracy: 0.8934\n",
      "Epoch 111/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2475 - accuracy: 0.8917\n",
      "Epoch 112/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2456 - accuracy: 0.8931\n",
      "Epoch 113/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2421 - accuracy: 0.8964\n",
      "Epoch 114/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2406 - accuracy: 0.8956\n",
      "Epoch 115/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2464 - accuracy: 0.8923\n",
      "Epoch 116/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2461 - accuracy: 0.8913\n",
      "Epoch 117/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2345 - accuracy: 0.8976\n",
      "Epoch 118/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2439 - accuracy: 0.8954\n",
      "Epoch 119/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2335 - accuracy: 0.8990\n",
      "Epoch 120/300\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.2454 - accuracy: 0.8938\n",
      "Epoch 121/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2361 - accuracy: 0.8949\n",
      "Epoch 122/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2353 - accuracy: 0.8979\n",
      "Epoch 123/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2362 - accuracy: 0.8955\n",
      "Epoch 124/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2365 - accuracy: 0.8949\n",
      "Epoch 125/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2393 - accuracy: 0.8956\n",
      "Epoch 126/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2279 - accuracy: 0.9011\n",
      "Epoch 127/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2354 - accuracy: 0.8986\n",
      "Epoch 128/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2276 - accuracy: 0.9006\n",
      "Epoch 129/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2346 - accuracy: 0.8939\n",
      "Epoch 130/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2249 - accuracy: 0.9038\n",
      "Epoch 131/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2315 - accuracy: 0.9018\n",
      "Epoch 132/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2319 - accuracy: 0.9003\n",
      "Epoch 133/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2269 - accuracy: 0.9015\n",
      "Epoch 134/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2205 - accuracy: 0.9014\n",
      "Epoch 135/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2227 - accuracy: 0.9036\n",
      "Epoch 136/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2166 - accuracy: 0.9084\n",
      "Epoch 137/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2250 - accuracy: 0.9021\n",
      "Epoch 138/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2208 - accuracy: 0.9060\n",
      "Epoch 139/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2234 - accuracy: 0.8995\n",
      "Epoch 140/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2217 - accuracy: 0.9031\n",
      "Epoch 141/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2170 - accuracy: 0.9061\n",
      "Epoch 142/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2180 - accuracy: 0.9025\n",
      "Epoch 143/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2207 - accuracy: 0.9040\n",
      "Epoch 144/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2178 - accuracy: 0.9044\n",
      "Epoch 145/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2148 - accuracy: 0.9062\n",
      "Epoch 146/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2079 - accuracy: 0.9101\n",
      "Epoch 147/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2205 - accuracy: 0.9022\n",
      "Epoch 148/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2066 - accuracy: 0.9111\n",
      "Epoch 149/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2143 - accuracy: 0.9049\n",
      "Epoch 150/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2079 - accuracy: 0.9107\n",
      "Epoch 151/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2110 - accuracy: 0.9076\n",
      "Epoch 152/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2097 - accuracy: 0.9086\n",
      "Epoch 153/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2063 - accuracy: 0.9109\n",
      "Epoch 154/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2033 - accuracy: 0.9131\n",
      "Epoch 155/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2029 - accuracy: 0.9140\n",
      "Epoch 156/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2090 - accuracy: 0.9078\n",
      "Epoch 157/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2072 - accuracy: 0.9093\n",
      "Epoch 158/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1999 - accuracy: 0.9143\n",
      "Epoch 159/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1996 - accuracy: 0.9122\n",
      "Epoch 160/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1966 - accuracy: 0.9151\n",
      "Epoch 161/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2055 - accuracy: 0.9069\n",
      "Epoch 162/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1988 - accuracy: 0.9141\n",
      "Epoch 163/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2003 - accuracy: 0.9131\n",
      "Epoch 164/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1962 - accuracy: 0.9139\n",
      "Epoch 165/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1982 - accuracy: 0.9146\n",
      "Epoch 166/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1939 - accuracy: 0.9161\n",
      "Epoch 167/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1975 - accuracy: 0.9133\n",
      "Epoch 168/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2016 - accuracy: 0.9126\n",
      "Epoch 169/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.2021 - accuracy: 0.9129\n",
      "Epoch 170/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1869 - accuracy: 0.9186\n",
      "Epoch 171/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1909 - accuracy: 0.9161\n",
      "Epoch 172/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1934 - accuracy: 0.9180\n",
      "Epoch 173/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1933 - accuracy: 0.9146\n",
      "Epoch 174/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1858 - accuracy: 0.9210\n",
      "Epoch 175/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1905 - accuracy: 0.9125\n",
      "Epoch 176/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1978 - accuracy: 0.9128\n",
      "Epoch 177/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1849 - accuracy: 0.9201\n",
      "Epoch 178/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1916 - accuracy: 0.9170\n",
      "Epoch 179/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1910 - accuracy: 0.9180\n",
      "Epoch 180/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1845 - accuracy: 0.9190\n",
      "Epoch 181/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1871 - accuracy: 0.9175\n",
      "Epoch 182/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1904 - accuracy: 0.9149\n",
      "Epoch 183/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1850 - accuracy: 0.9202\n",
      "Epoch 184/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1753 - accuracy: 0.9212\n",
      "Epoch 185/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1811 - accuracy: 0.9212\n",
      "Epoch 186/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1852 - accuracy: 0.9189\n",
      "Epoch 187/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1802 - accuracy: 0.9199\n",
      "Epoch 188/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1836 - accuracy: 0.9214\n",
      "Epoch 189/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1751 - accuracy: 0.9230\n",
      "Epoch 190/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1900 - accuracy: 0.9178\n",
      "Epoch 191/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1743 - accuracy: 0.9275\n",
      "Epoch 192/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1845 - accuracy: 0.9195\n",
      "Epoch 193/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1812 - accuracy: 0.9225\n",
      "Epoch 194/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1760 - accuracy: 0.9241\n",
      "Epoch 195/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1758 - accuracy: 0.9224\n",
      "Epoch 196/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1775 - accuracy: 0.9241\n",
      "Epoch 197/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1678 - accuracy: 0.9271\n",
      "Epoch 198/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1675 - accuracy: 0.9270\n",
      "Epoch 199/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1744 - accuracy: 0.9226\n",
      "Epoch 200/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1734 - accuracy: 0.9256\n",
      "Epoch 201/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1747 - accuracy: 0.9230\n",
      "Epoch 202/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1672 - accuracy: 0.9255\n",
      "Epoch 203/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1680 - accuracy: 0.9287\n",
      "Epoch 204/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1764 - accuracy: 0.9218\n",
      "Epoch 205/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1663 - accuracy: 0.9294\n",
      "Epoch 206/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1784 - accuracy: 0.9235\n",
      "Epoch 207/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1649 - accuracy: 0.9300\n",
      "Epoch 208/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1717 - accuracy: 0.9245\n",
      "Epoch 209/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1756 - accuracy: 0.9227\n",
      "Epoch 210/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1644 - accuracy: 0.9276\n",
      "Epoch 211/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1766 - accuracy: 0.9261\n",
      "Epoch 212/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1608 - accuracy: 0.9310\n",
      "Epoch 213/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1590 - accuracy: 0.9302\n",
      "Epoch 214/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1586 - accuracy: 0.9324\n",
      "Epoch 215/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1735 - accuracy: 0.9241\n",
      "Epoch 216/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1562 - accuracy: 0.9341\n",
      "Epoch 217/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1684 - accuracy: 0.9264\n",
      "Epoch 218/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1737 - accuracy: 0.9256\n",
      "Epoch 219/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1561 - accuracy: 0.9301\n",
      "Epoch 220/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1605 - accuracy: 0.9340\n",
      "Epoch 221/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1581 - accuracy: 0.9295\n",
      "Epoch 222/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1689 - accuracy: 0.9294\n",
      "Epoch 223/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1566 - accuracy: 0.9339\n",
      "Epoch 224/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1521 - accuracy: 0.9336\n",
      "Epoch 225/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1606 - accuracy: 0.9309\n",
      "Epoch 226/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1535 - accuracy: 0.9335\n",
      "Epoch 227/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1616 - accuracy: 0.9308\n",
      "Epoch 228/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1474 - accuracy: 0.9352\n",
      "Epoch 229/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1589 - accuracy: 0.9311\n",
      "Epoch 230/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1495 - accuracy: 0.9358\n",
      "Epoch 231/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1558 - accuracy: 0.9330\n",
      "Epoch 232/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1633 - accuracy: 0.9321\n",
      "Epoch 233/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1802 - accuracy: 0.9285\n",
      "Epoch 234/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1431 - accuracy: 0.9375\n",
      "Epoch 235/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1437 - accuracy: 0.9383\n",
      "Epoch 236/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1539 - accuracy: 0.9352\n",
      "Epoch 237/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1664 - accuracy: 0.9287\n",
      "Epoch 238/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1597 - accuracy: 0.9298\n",
      "Epoch 239/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1537 - accuracy: 0.9327\n",
      "Epoch 240/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1488 - accuracy: 0.9350\n",
      "Epoch 241/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1485 - accuracy: 0.9351\n",
      "Epoch 242/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1700 - accuracy: 0.9294\n",
      "Epoch 243/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1401 - accuracy: 0.9421\n",
      "Epoch 244/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1432 - accuracy: 0.9415\n",
      "Epoch 245/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1585 - accuracy: 0.9348\n",
      "Epoch 246/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1437 - accuracy: 0.9358\n",
      "Epoch 247/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1509 - accuracy: 0.9377\n",
      "Epoch 248/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1429 - accuracy: 0.9389\n",
      "Epoch 249/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1582 - accuracy: 0.9323\n",
      "Epoch 250/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1517 - accuracy: 0.9336\n",
      "Epoch 251/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1438 - accuracy: 0.9406\n",
      "Epoch 252/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1456 - accuracy: 0.9391\n",
      "Epoch 253/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1417 - accuracy: 0.9408\n",
      "Epoch 254/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1449 - accuracy: 0.9364\n",
      "Epoch 255/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1427 - accuracy: 0.9375\n",
      "Epoch 256/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1433 - accuracy: 0.9383\n",
      "Epoch 257/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1456 - accuracy: 0.9390\n",
      "Epoch 258/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1484 - accuracy: 0.9369\n",
      "Epoch 259/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1433 - accuracy: 0.9375\n",
      "Epoch 260/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1481 - accuracy: 0.9370\n",
      "Epoch 261/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1472 - accuracy: 0.9386\n",
      "Epoch 262/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1368 - accuracy: 0.9438\n",
      "Epoch 263/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1389 - accuracy: 0.9405\n",
      "Epoch 264/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1342 - accuracy: 0.9448\n",
      "Epoch 265/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1406 - accuracy: 0.9414\n",
      "Epoch 266/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1347 - accuracy: 0.9419\n",
      "Epoch 267/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1295 - accuracy: 0.9451\n",
      "Epoch 268/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1501 - accuracy: 0.9377\n",
      "Epoch 269/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1398 - accuracy: 0.9438\n",
      "Epoch 270/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1284 - accuracy: 0.9438\n",
      "Epoch 271/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1381 - accuracy: 0.9411\n",
      "Epoch 272/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1540 - accuracy: 0.9351\n",
      "Epoch 273/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1355 - accuracy: 0.9430\n",
      "Epoch 274/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1321 - accuracy: 0.9467\n",
      "Epoch 275/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1371 - accuracy: 0.9413\n",
      "Epoch 276/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1413 - accuracy: 0.9401\n",
      "Epoch 277/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1350 - accuracy: 0.9435\n",
      "Epoch 278/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1241 - accuracy: 0.9479\n",
      "Epoch 279/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1364 - accuracy: 0.9423\n",
      "Epoch 280/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1401 - accuracy: 0.9420\n",
      "Epoch 281/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1209 - accuracy: 0.9464\n",
      "Epoch 282/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1391 - accuracy: 0.9429\n",
      "Epoch 283/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1360 - accuracy: 0.9446\n",
      "Epoch 284/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1451 - accuracy: 0.9399\n",
      "Epoch 285/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1255 - accuracy: 0.9466\n",
      "Epoch 286/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1327 - accuracy: 0.9429\n",
      "Epoch 287/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1294 - accuracy: 0.9473\n",
      "Epoch 288/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1343 - accuracy: 0.9417\n",
      "Epoch 289/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1432 - accuracy: 0.9402\n",
      "Epoch 290/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1383 - accuracy: 0.9420\n",
      "Epoch 291/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1375 - accuracy: 0.9436\n",
      "Epoch 292/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1307 - accuracy: 0.9442\n",
      "Epoch 293/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1333 - accuracy: 0.9440\n",
      "Epoch 294/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1372 - accuracy: 0.9415\n",
      "Epoch 295/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1207 - accuracy: 0.9489\n",
      "Epoch 296/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1455 - accuracy: 0.9394\n",
      "Epoch 297/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1337 - accuracy: 0.9450\n",
      "Epoch 298/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1198 - accuracy: 0.9492\n",
      "Epoch 299/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1305 - accuracy: 0.9451\n",
      "Epoch 300/300\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.1275 - accuracy: 0.9463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ae1e9fc5b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_Y.astype(int), epochs=300, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41c8c203-b2f8-4b8b-b8aa-763de152f0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model.predict(test_X)>0.5,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_41.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "877d6cc4-0401-4b1c-b144-4d41eeb2c8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 64)                832       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,889\n",
      "Trainable params: 1,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    " \n",
    "model = Sequential() \n",
    "model.add(Dense(64, activation='relu', input_dim=12))\n",
    "model.add(Dense(16, activation='relu')) \n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa5544e9-0989-41fc-86f3-bd27d1e1fee7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.8095\n",
      "Epoch 2/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.8061\n",
      "Epoch 3/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.8089\n",
      "Epoch 4/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.8040\n",
      "Epoch 5/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.8061\n",
      "Epoch 6/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.8119\n",
      "Epoch 7/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.8120\n",
      "Epoch 8/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.8094\n",
      "Epoch 9/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.8102\n",
      "Epoch 10/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.8121\n",
      "Epoch 11/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.8116\n",
      "Epoch 12/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.8111\n",
      "Epoch 13/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.8091\n",
      "Epoch 14/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.8131\n",
      "Epoch 15/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.8091\n",
      "Epoch 16/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.8111\n",
      "Epoch 17/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.8129\n",
      "Epoch 18/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.8145\n",
      "Epoch 19/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.8120\n",
      "Epoch 20/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.8138\n",
      "Epoch 21/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.8119\n",
      "Epoch 22/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.8098\n",
      "Epoch 23/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.8152\n",
      "Epoch 24/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.8091\n",
      "Epoch 25/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.8148\n",
      "Epoch 26/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4243 - accuracy: 0.8146\n",
      "Epoch 27/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.8094\n",
      "Epoch 28/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.8160\n",
      "Epoch 29/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4160 - accuracy: 0.8146\n",
      "Epoch 30/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4103 - accuracy: 0.8234\n",
      "Epoch 31/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4086 - accuracy: 0.8217\n",
      "Epoch 32/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.8264\n",
      "Epoch 33/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4061 - accuracy: 0.8245\n",
      "Epoch 34/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3980 - accuracy: 0.8275\n",
      "Epoch 35/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.4032 - accuracy: 0.8279\n",
      "Epoch 36/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3985 - accuracy: 0.8299\n",
      "Epoch 37/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3937 - accuracy: 0.8307\n",
      "Epoch 38/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3910 - accuracy: 0.8321\n",
      "Epoch 39/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3888 - accuracy: 0.8329\n",
      "Epoch 40/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3863 - accuracy: 0.8314\n",
      "Epoch 41/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3836 - accuracy: 0.8321\n",
      "Epoch 42/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3832 - accuracy: 0.8370\n",
      "Epoch 43/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3847 - accuracy: 0.8341\n",
      "Epoch 44/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3804 - accuracy: 0.8339\n",
      "Epoch 45/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3846 - accuracy: 0.8330\n",
      "Epoch 46/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3792 - accuracy: 0.8344\n",
      "Epoch 47/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3802 - accuracy: 0.8367\n",
      "Epoch 48/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3787 - accuracy: 0.8396\n",
      "Epoch 49/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3760 - accuracy: 0.8365\n",
      "Epoch 50/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3759 - accuracy: 0.8403\n",
      "Epoch 51/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3779 - accuracy: 0.8359\n",
      "Epoch 52/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3759 - accuracy: 0.8370\n",
      "Epoch 53/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3788 - accuracy: 0.8378\n",
      "Epoch 54/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3751 - accuracy: 0.8393\n",
      "Epoch 55/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3729 - accuracy: 0.8396\n",
      "Epoch 56/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.8374\n",
      "Epoch 57/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3720 - accuracy: 0.8407\n",
      "Epoch 58/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3739 - accuracy: 0.8388\n",
      "Epoch 59/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3734 - accuracy: 0.8409\n",
      "Epoch 60/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3729 - accuracy: 0.8382\n",
      "Epoch 61/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3691 - accuracy: 0.8396\n",
      "Epoch 62/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3696 - accuracy: 0.8409\n",
      "Epoch 63/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3724 - accuracy: 0.8409\n",
      "Epoch 64/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3698 - accuracy: 0.8425\n",
      "Epoch 65/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3722 - accuracy: 0.8389\n",
      "Epoch 66/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3691 - accuracy: 0.8429\n",
      "Epoch 67/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3683 - accuracy: 0.8415\n",
      "Epoch 68/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3662 - accuracy: 0.8430\n",
      "Epoch 69/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3655 - accuracy: 0.8426\n",
      "Epoch 70/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3647 - accuracy: 0.8469\n",
      "Epoch 71/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3697 - accuracy: 0.8406\n",
      "Epoch 72/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8435\n",
      "Epoch 73/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8447\n",
      "Epoch 74/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3647 - accuracy: 0.8415\n",
      "Epoch 75/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3678 - accuracy: 0.8416\n",
      "Epoch 76/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3626 - accuracy: 0.8466\n",
      "Epoch 77/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3612 - accuracy: 0.8460\n",
      "Epoch 78/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3641 - accuracy: 0.8451\n",
      "Epoch 79/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3630 - accuracy: 0.8481\n",
      "Epoch 80/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3664 - accuracy: 0.8454\n",
      "Epoch 81/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3614 - accuracy: 0.8459\n",
      "Epoch 82/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3625 - accuracy: 0.8456\n",
      "Epoch 83/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3587 - accuracy: 0.8499\n",
      "Epoch 84/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3582 - accuracy: 0.8476\n",
      "Epoch 85/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3585 - accuracy: 0.8481\n",
      "Epoch 86/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3584 - accuracy: 0.8499\n",
      "Epoch 87/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3564 - accuracy: 0.8508\n",
      "Epoch 88/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3574 - accuracy: 0.8514\n",
      "Epoch 89/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3583 - accuracy: 0.8471\n",
      "Epoch 90/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3561 - accuracy: 0.8515\n",
      "Epoch 91/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3567 - accuracy: 0.8521\n",
      "Epoch 92/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.8485\n",
      "Epoch 93/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3625 - accuracy: 0.8493\n",
      "Epoch 94/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3603 - accuracy: 0.8504\n",
      "Epoch 95/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3518 - accuracy: 0.8530\n",
      "Epoch 96/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 0.8499\n",
      "Epoch 97/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3551 - accuracy: 0.8509\n",
      "Epoch 98/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3519 - accuracy: 0.8515\n",
      "Epoch 99/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3517 - accuracy: 0.8530\n",
      "Epoch 100/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3525 - accuracy: 0.8540\n",
      "Epoch 101/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3569 - accuracy: 0.8505\n",
      "Epoch 102/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3535 - accuracy: 0.8518\n",
      "Epoch 103/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3514 - accuracy: 0.8535\n",
      "Epoch 104/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3496 - accuracy: 0.8536\n",
      "Epoch 105/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3493 - accuracy: 0.8528\n",
      "Epoch 106/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3519 - accuracy: 0.8526\n",
      "Epoch 107/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3491 - accuracy: 0.8550\n",
      "Epoch 108/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3478 - accuracy: 0.8554\n",
      "Epoch 109/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3515 - accuracy: 0.8529\n",
      "Epoch 110/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3461 - accuracy: 0.8553\n",
      "Epoch 111/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3473 - accuracy: 0.8562\n",
      "Epoch 112/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3474 - accuracy: 0.8568\n",
      "Epoch 113/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3466 - accuracy: 0.8569\n",
      "Epoch 114/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3457 - accuracy: 0.8553\n",
      "Epoch 115/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3481 - accuracy: 0.8525\n",
      "Epoch 116/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3491 - accuracy: 0.8554\n",
      "Epoch 117/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3427 - accuracy: 0.8585\n",
      "Epoch 118/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3474 - accuracy: 0.8530\n",
      "Epoch 119/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3444 - accuracy: 0.8561\n",
      "Epoch 120/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3477 - accuracy: 0.8553\n",
      "Epoch 121/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3439 - accuracy: 0.8562\n",
      "Epoch 122/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3469 - accuracy: 0.8544\n",
      "Epoch 123/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3460 - accuracy: 0.8554\n",
      "Epoch 124/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3434 - accuracy: 0.8572\n",
      "Epoch 125/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3440 - accuracy: 0.8580\n",
      "Epoch 126/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3432 - accuracy: 0.8574\n",
      "Epoch 127/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3455 - accuracy: 0.8540\n",
      "Epoch 128/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3420 - accuracy: 0.8584\n",
      "Epoch 129/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3421 - accuracy: 0.8570\n",
      "Epoch 130/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3468 - accuracy: 0.8545\n",
      "Epoch 131/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3436 - accuracy: 0.8558\n",
      "Epoch 132/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3391 - accuracy: 0.8571\n",
      "Epoch 133/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3408 - accuracy: 0.8590\n",
      "Epoch 134/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3394 - accuracy: 0.8581\n",
      "Epoch 135/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3416 - accuracy: 0.8583\n",
      "Epoch 136/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3403 - accuracy: 0.8583\n",
      "Epoch 137/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3405 - accuracy: 0.8558\n",
      "Epoch 138/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3392 - accuracy: 0.8599\n",
      "Epoch 139/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3373 - accuracy: 0.8591\n",
      "Epoch 140/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3412 - accuracy: 0.8601\n",
      "Epoch 141/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3432 - accuracy: 0.8562\n",
      "Epoch 142/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3351 - accuracy: 0.8604\n",
      "Epoch 143/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8596\n",
      "Epoch 144/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3364 - accuracy: 0.8585\n",
      "Epoch 145/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3367 - accuracy: 0.8610\n",
      "Epoch 146/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3382 - accuracy: 0.8602\n",
      "Epoch 147/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3361 - accuracy: 0.8610\n",
      "Epoch 148/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.8620\n",
      "Epoch 149/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3332 - accuracy: 0.8639\n",
      "Epoch 150/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3380 - accuracy: 0.8618\n",
      "Epoch 151/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3434 - accuracy: 0.8584\n",
      "Epoch 152/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3331 - accuracy: 0.8612\n",
      "Epoch 153/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3342 - accuracy: 0.8606\n",
      "Epoch 154/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3344 - accuracy: 0.8624\n",
      "Epoch 155/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3338 - accuracy: 0.8627\n",
      "Epoch 156/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3344 - accuracy: 0.8611\n",
      "Epoch 157/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3326 - accuracy: 0.8625\n",
      "Epoch 158/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8627\n",
      "Epoch 159/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3302 - accuracy: 0.8659\n",
      "Epoch 160/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3332 - accuracy: 0.8620\n",
      "Epoch 161/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3309 - accuracy: 0.8618\n",
      "Epoch 162/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3322 - accuracy: 0.8621\n",
      "Epoch 163/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3363 - accuracy: 0.8615\n",
      "Epoch 164/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3327 - accuracy: 0.8606\n",
      "Epoch 165/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3303 - accuracy: 0.8643\n",
      "Epoch 166/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8624\n",
      "Epoch 167/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3429 - accuracy: 0.8550\n",
      "Epoch 168/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3287 - accuracy: 0.8650\n",
      "Epoch 169/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3324 - accuracy: 0.8636\n",
      "Epoch 170/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3294 - accuracy: 0.8643\n",
      "Epoch 171/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3294 - accuracy: 0.8626\n",
      "Epoch 172/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8664\n",
      "Epoch 173/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3290 - accuracy: 0.8651\n",
      "Epoch 174/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3286 - accuracy: 0.8651\n",
      "Epoch 175/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3321 - accuracy: 0.8616\n",
      "Epoch 176/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3346 - accuracy: 0.8630\n",
      "Epoch 177/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3278 - accuracy: 0.8637\n",
      "Epoch 178/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8631\n",
      "Epoch 179/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3305 - accuracy: 0.8635\n",
      "Epoch 180/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3302 - accuracy: 0.8634\n",
      "Epoch 181/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3295 - accuracy: 0.8631\n",
      "Epoch 182/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3328 - accuracy: 0.8633\n",
      "Epoch 183/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8666\n",
      "Epoch 184/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3286 - accuracy: 0.8639\n",
      "Epoch 185/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3282 - accuracy: 0.8640\n",
      "Epoch 186/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8648\n",
      "Epoch 187/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3276 - accuracy: 0.8640\n",
      "Epoch 188/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8648\n",
      "Epoch 189/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3263 - accuracy: 0.8684\n",
      "Epoch 190/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8641\n",
      "Epoch 191/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3284 - accuracy: 0.8631\n",
      "Epoch 192/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3277 - accuracy: 0.8633\n",
      "Epoch 193/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3267 - accuracy: 0.8631\n",
      "Epoch 194/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3249 - accuracy: 0.8651\n",
      "Epoch 195/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3263 - accuracy: 0.8633\n",
      "Epoch 196/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8671\n",
      "Epoch 197/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3257 - accuracy: 0.8658\n",
      "Epoch 198/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3285 - accuracy: 0.8608\n",
      "Epoch 199/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3249 - accuracy: 0.8677\n",
      "Epoch 200/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3285 - accuracy: 0.8644\n",
      "Epoch 201/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3248 - accuracy: 0.8648\n",
      "Epoch 202/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8656\n",
      "Epoch 203/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3244 - accuracy: 0.8676\n",
      "Epoch 204/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3280 - accuracy: 0.8636\n",
      "Epoch 205/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3259 - accuracy: 0.8650\n",
      "Epoch 206/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3236 - accuracy: 0.8652\n",
      "Epoch 207/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3254 - accuracy: 0.8660\n",
      "Epoch 208/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3309 - accuracy: 0.8643\n",
      "Epoch 209/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3240 - accuracy: 0.8665\n",
      "Epoch 210/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8630\n",
      "Epoch 211/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3254 - accuracy: 0.8636\n",
      "Epoch 212/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3250 - accuracy: 0.8669\n",
      "Epoch 213/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8671\n",
      "Epoch 214/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8636\n",
      "Epoch 215/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3255 - accuracy: 0.8689\n",
      "Epoch 216/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8631\n",
      "Epoch 217/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3244 - accuracy: 0.8660\n",
      "Epoch 218/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3225 - accuracy: 0.8684\n",
      "Epoch 219/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3258 - accuracy: 0.8650\n",
      "Epoch 220/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3226 - accuracy: 0.8676\n",
      "Epoch 221/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3226 - accuracy: 0.8670\n",
      "Epoch 222/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3286 - accuracy: 0.8639\n",
      "Epoch 223/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3229 - accuracy: 0.8671\n",
      "Epoch 224/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.8677\n",
      "Epoch 225/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3211 - accuracy: 0.8651\n",
      "Epoch 226/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8649\n",
      "Epoch 227/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3215 - accuracy: 0.8670\n",
      "Epoch 228/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3238 - accuracy: 0.8637\n",
      "Epoch 229/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8660\n",
      "Epoch 230/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3221 - accuracy: 0.8666\n",
      "Epoch 231/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3296 - accuracy: 0.8609\n",
      "Epoch 232/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3241 - accuracy: 0.8650\n",
      "Epoch 233/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3221 - accuracy: 0.8669\n",
      "Epoch 234/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3213 - accuracy: 0.8655\n",
      "Epoch 235/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8666\n",
      "Epoch 236/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3219 - accuracy: 0.8675\n",
      "Epoch 237/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3239 - accuracy: 0.8673\n",
      "Epoch 238/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3201 - accuracy: 0.8691\n",
      "Epoch 239/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3184 - accuracy: 0.8696\n",
      "Epoch 240/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3227 - accuracy: 0.8659\n",
      "Epoch 241/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8670\n",
      "Epoch 242/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3259 - accuracy: 0.8643\n",
      "Epoch 243/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3226 - accuracy: 0.8676\n",
      "Epoch 244/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3220 - accuracy: 0.8654\n",
      "Epoch 245/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3213 - accuracy: 0.8677\n",
      "Epoch 246/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8646\n",
      "Epoch 247/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3196 - accuracy: 0.8683\n",
      "Epoch 248/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8652\n",
      "Epoch 249/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.8670\n",
      "Epoch 250/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8620\n",
      "Epoch 251/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3191 - accuracy: 0.8673\n",
      "Epoch 252/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3209 - accuracy: 0.8656\n",
      "Epoch 253/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3207 - accuracy: 0.8668\n",
      "Epoch 254/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3216 - accuracy: 0.8664\n",
      "Epoch 255/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3194 - accuracy: 0.8689\n",
      "Epoch 256/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3205 - accuracy: 0.8684\n",
      "Epoch 257/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3186 - accuracy: 0.8679\n",
      "Epoch 258/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3207 - accuracy: 0.8676\n",
      "Epoch 259/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3172 - accuracy: 0.8691\n",
      "Epoch 260/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3249 - accuracy: 0.8660\n",
      "Epoch 261/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3193 - accuracy: 0.8652\n",
      "Epoch 262/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3197 - accuracy: 0.8664\n",
      "Epoch 263/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3171 - accuracy: 0.8677\n",
      "Epoch 264/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3210 - accuracy: 0.8685\n",
      "Epoch 265/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3183 - accuracy: 0.8669\n",
      "Epoch 266/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3178 - accuracy: 0.8695\n",
      "Epoch 267/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3165 - accuracy: 0.8690\n",
      "Epoch 268/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3189 - accuracy: 0.8670\n",
      "Epoch 269/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3181 - accuracy: 0.8695\n",
      "Epoch 270/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3223 - accuracy: 0.8699\n",
      "Epoch 271/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3219 - accuracy: 0.8681\n",
      "Epoch 272/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3202 - accuracy: 0.8684\n",
      "Epoch 273/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3220 - accuracy: 0.8681\n",
      "Epoch 274/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3213 - accuracy: 0.8669\n",
      "Epoch 275/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3176 - accuracy: 0.8700\n",
      "Epoch 276/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3185 - accuracy: 0.8706\n",
      "Epoch 277/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3194 - accuracy: 0.8662\n",
      "Epoch 278/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3239 - accuracy: 0.8644\n",
      "Epoch 279/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3157 - accuracy: 0.8704\n",
      "Epoch 280/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3199 - accuracy: 0.8684\n",
      "Epoch 281/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3159 - accuracy: 0.8716\n",
      "Epoch 282/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3219 - accuracy: 0.8630\n",
      "Epoch 283/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3191 - accuracy: 0.8673\n",
      "Epoch 284/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3140 - accuracy: 0.8698\n",
      "Epoch 285/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3174 - accuracy: 0.8674\n",
      "Epoch 286/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3154 - accuracy: 0.8690\n",
      "Epoch 287/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3202 - accuracy: 0.8662\n",
      "Epoch 288/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3200 - accuracy: 0.8702\n",
      "Epoch 289/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3155 - accuracy: 0.8691\n",
      "Epoch 290/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3178 - accuracy: 0.8660\n",
      "Epoch 291/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3227 - accuracy: 0.8648\n",
      "Epoch 292/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3193 - accuracy: 0.8646\n",
      "Epoch 293/300\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3164 - accuracy: 0.8685\n",
      "Epoch 294/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3192 - accuracy: 0.8675\n",
      "Epoch 295/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3173 - accuracy: 0.8671\n",
      "Epoch 296/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3168 - accuracy: 0.8674\n",
      "Epoch 297/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3164 - accuracy: 0.8690\n",
      "Epoch 298/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3195 - accuracy: 0.8687\n",
      "Epoch 299/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3152 - accuracy: 0.8699\n",
      "Epoch 300/300\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3170 - accuracy: 0.8658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ae1fb43a30>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_Y.astype(int), epochs=300, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1417062c-91f5-49a8-9718-f42c26f5fcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model.predict(test_X)>0.5,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_42.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e9fb8e6-9649-41e2-ae8b-48ae02716109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_18 (Dense)            (None, 128)               1664      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128)              512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 16)                1040      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,809\n",
      "Trainable params: 11,393\n",
      "Non-trainable params: 416\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "model = Sequential() \n",
    "model.add(Dense(128, activation='relu', input_dim=12))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "072677eb-d0c6-4769-88b7-b8c92bc4f3d9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "80/80 [==============================] - 3s 5ms/step - loss: 0.5951 - accuracy: 0.6977\n",
      "Epoch 2/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.4507 - accuracy: 0.8275\n",
      "Epoch 3/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3857 - accuracy: 0.8490\n",
      "Epoch 4/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3575 - accuracy: 0.8584\n",
      "Epoch 5/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3433 - accuracy: 0.8599\n",
      "Epoch 6/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3410 - accuracy: 0.8624\n",
      "Epoch 7/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3397 - accuracy: 0.8605\n",
      "Epoch 8/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3343 - accuracy: 0.8606\n",
      "Epoch 9/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3317 - accuracy: 0.8625\n",
      "Epoch 10/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3303 - accuracy: 0.8609\n",
      "Epoch 11/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3322 - accuracy: 0.8611\n",
      "Epoch 12/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3308 - accuracy: 0.8611\n",
      "Epoch 13/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3278 - accuracy: 0.8624\n",
      "Epoch 14/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3301 - accuracy: 0.8649\n",
      "Epoch 15/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3247 - accuracy: 0.8649\n",
      "Epoch 16/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3248 - accuracy: 0.8651\n",
      "Epoch 17/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3235 - accuracy: 0.8640\n",
      "Epoch 18/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3254 - accuracy: 0.8664\n",
      "Epoch 19/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3206 - accuracy: 0.8673\n",
      "Epoch 20/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3241 - accuracy: 0.8656\n",
      "Epoch 21/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3212 - accuracy: 0.8685\n",
      "Epoch 22/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3204 - accuracy: 0.8660\n",
      "Epoch 23/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3211 - accuracy: 0.8646\n",
      "Epoch 24/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3200 - accuracy: 0.8658\n",
      "Epoch 25/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3221 - accuracy: 0.8627\n",
      "Epoch 26/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3192 - accuracy: 0.8680\n",
      "Epoch 27/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3166 - accuracy: 0.8668\n",
      "Epoch 28/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3167 - accuracy: 0.8660\n",
      "Epoch 29/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3207 - accuracy: 0.8646\n",
      "Epoch 30/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3188 - accuracy: 0.8670\n",
      "Epoch 31/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3130 - accuracy: 0.8696\n",
      "Epoch 32/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3118 - accuracy: 0.8700\n",
      "Epoch 33/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3110 - accuracy: 0.8717\n",
      "Epoch 34/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3155 - accuracy: 0.8661\n",
      "Epoch 35/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3115 - accuracy: 0.8674\n",
      "Epoch 36/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3119 - accuracy: 0.8702\n",
      "Epoch 37/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3063 - accuracy: 0.8723\n",
      "Epoch 38/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3123 - accuracy: 0.8694\n",
      "Epoch 39/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3108 - accuracy: 0.8698\n",
      "Epoch 40/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3061 - accuracy: 0.8730\n",
      "Epoch 41/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3110 - accuracy: 0.8690\n",
      "Epoch 42/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3099 - accuracy: 0.8706\n",
      "Epoch 43/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3066 - accuracy: 0.8686\n",
      "Epoch 44/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3027 - accuracy: 0.8716\n",
      "Epoch 45/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3011 - accuracy: 0.8756\n",
      "Epoch 46/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3027 - accuracy: 0.8737\n",
      "Epoch 47/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3040 - accuracy: 0.8687\n",
      "Epoch 48/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.3037 - accuracy: 0.8736\n",
      "Epoch 49/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.3049 - accuracy: 0.8699\n",
      "Epoch 50/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.3068 - accuracy: 0.8723\n",
      "Epoch 51/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2983 - accuracy: 0.8749\n",
      "Epoch 52/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2990 - accuracy: 0.8733\n",
      "Epoch 53/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2965 - accuracy: 0.8749\n",
      "Epoch 54/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2980 - accuracy: 0.8759\n",
      "Epoch 55/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2986 - accuracy: 0.8721\n",
      "Epoch 56/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2957 - accuracy: 0.8748\n",
      "Epoch 57/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2964 - accuracy: 0.8783\n",
      "Epoch 58/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2975 - accuracy: 0.8759\n",
      "Epoch 59/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2962 - accuracy: 0.8744\n",
      "Epoch 60/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2917 - accuracy: 0.8758\n",
      "Epoch 61/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2971 - accuracy: 0.8736\n",
      "Epoch 62/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2961 - accuracy: 0.8754\n",
      "Epoch 63/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2952 - accuracy: 0.8765\n",
      "Epoch 64/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2940 - accuracy: 0.8755\n",
      "Epoch 65/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2918 - accuracy: 0.8758\n",
      "Epoch 66/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2911 - accuracy: 0.8767\n",
      "Epoch 67/200\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.2944 - accuracy: 0.8750\n",
      "Epoch 68/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2916 - accuracy: 0.8773\n",
      "Epoch 69/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2907 - accuracy: 0.8765\n",
      "Epoch 70/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2886 - accuracy: 0.8759\n",
      "Epoch 71/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2878 - accuracy: 0.8795\n",
      "Epoch 72/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2890 - accuracy: 0.8764\n",
      "Epoch 73/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2921 - accuracy: 0.8740\n",
      "Epoch 74/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2877 - accuracy: 0.8775\n",
      "Epoch 75/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2856 - accuracy: 0.8761\n",
      "Epoch 76/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2891 - accuracy: 0.8749\n",
      "Epoch 77/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2836 - accuracy: 0.8836\n",
      "Epoch 78/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2875 - accuracy: 0.8742\n",
      "Epoch 79/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2853 - accuracy: 0.8783\n",
      "Epoch 80/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2839 - accuracy: 0.8801\n",
      "Epoch 81/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2872 - accuracy: 0.8784\n",
      "Epoch 82/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2820 - accuracy: 0.8815\n",
      "Epoch 83/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2827 - accuracy: 0.8792\n",
      "Epoch 84/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2867 - accuracy: 0.8744\n",
      "Epoch 85/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2844 - accuracy: 0.8792\n",
      "Epoch 86/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2823 - accuracy: 0.8831\n",
      "Epoch 87/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2803 - accuracy: 0.8794\n",
      "Epoch 88/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2824 - accuracy: 0.8784\n",
      "Epoch 89/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2842 - accuracy: 0.8806\n",
      "Epoch 90/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2792 - accuracy: 0.8844\n",
      "Epoch 91/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2878 - accuracy: 0.8775\n",
      "Epoch 92/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2781 - accuracy: 0.8799\n",
      "Epoch 93/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2804 - accuracy: 0.8811\n",
      "Epoch 94/200\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2777 - accuracy: 0.8826\n",
      "Epoch 95/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2848 - accuracy: 0.8760\n",
      "Epoch 96/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2795 - accuracy: 0.8804\n",
      "Epoch 97/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2812 - accuracy: 0.8783\n",
      "Epoch 98/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2791 - accuracy: 0.8806\n",
      "Epoch 99/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2766 - accuracy: 0.8810\n",
      "Epoch 100/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2799 - accuracy: 0.8826\n",
      "Epoch 101/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2811 - accuracy: 0.8789\n",
      "Epoch 102/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2770 - accuracy: 0.8790\n",
      "Epoch 103/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2728 - accuracy: 0.8821\n",
      "Epoch 104/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2707 - accuracy: 0.8846\n",
      "Epoch 105/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2733 - accuracy: 0.8869\n",
      "Epoch 106/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2755 - accuracy: 0.8819\n",
      "Epoch 107/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2768 - accuracy: 0.8801\n",
      "Epoch 108/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2723 - accuracy: 0.8844\n",
      "Epoch 109/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2753 - accuracy: 0.8804\n",
      "Epoch 110/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2744 - accuracy: 0.8825\n",
      "Epoch 111/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2692 - accuracy: 0.8895\n",
      "Epoch 112/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2738 - accuracy: 0.8850\n",
      "Epoch 113/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2723 - accuracy: 0.8834\n",
      "Epoch 114/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2704 - accuracy: 0.8830\n",
      "Epoch 115/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2709 - accuracy: 0.8849\n",
      "Epoch 116/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2697 - accuracy: 0.8861\n",
      "Epoch 117/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2691 - accuracy: 0.8834\n",
      "Epoch 118/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2695 - accuracy: 0.8813\n",
      "Epoch 119/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2715 - accuracy: 0.8820\n",
      "Epoch 120/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2708 - accuracy: 0.8860\n",
      "Epoch 121/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2731 - accuracy: 0.8836\n",
      "Epoch 122/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2659 - accuracy: 0.8859\n",
      "Epoch 123/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2659 - accuracy: 0.8852\n",
      "Epoch 124/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2677 - accuracy: 0.8840\n",
      "Epoch 125/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2669 - accuracy: 0.8842\n",
      "Epoch 126/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2680 - accuracy: 0.8852\n",
      "Epoch 127/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2659 - accuracy: 0.8855\n",
      "Epoch 128/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2660 - accuracy: 0.8856\n",
      "Epoch 129/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2685 - accuracy: 0.8840\n",
      "Epoch 130/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2651 - accuracy: 0.8856\n",
      "Epoch 131/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2667 - accuracy: 0.8840\n",
      "Epoch 132/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2617 - accuracy: 0.8873\n",
      "Epoch 133/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2647 - accuracy: 0.8845\n",
      "Epoch 134/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2654 - accuracy: 0.8860\n",
      "Epoch 135/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2648 - accuracy: 0.8875\n",
      "Epoch 136/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2657 - accuracy: 0.8854\n",
      "Epoch 137/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2628 - accuracy: 0.8856\n",
      "Epoch 138/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2628 - accuracy: 0.8880\n",
      "Epoch 139/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2662 - accuracy: 0.8881\n",
      "Epoch 140/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2634 - accuracy: 0.8873\n",
      "Epoch 141/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2629 - accuracy: 0.8880\n",
      "Epoch 142/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2666 - accuracy: 0.8836\n",
      "Epoch 143/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2626 - accuracy: 0.8880\n",
      "Epoch 144/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2635 - accuracy: 0.8864\n",
      "Epoch 145/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2686 - accuracy: 0.8842\n",
      "Epoch 146/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2588 - accuracy: 0.8890\n",
      "Epoch 147/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2586 - accuracy: 0.8884\n",
      "Epoch 148/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2574 - accuracy: 0.8916\n",
      "Epoch 149/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2552 - accuracy: 0.8929\n",
      "Epoch 150/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2578 - accuracy: 0.8888\n",
      "Epoch 151/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2569 - accuracy: 0.8924\n",
      "Epoch 152/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2607 - accuracy: 0.8884\n",
      "Epoch 153/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2615 - accuracy: 0.8892\n",
      "Epoch 154/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2553 - accuracy: 0.8906\n",
      "Epoch 155/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2576 - accuracy: 0.8848\n",
      "Epoch 156/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2616 - accuracy: 0.8866\n",
      "Epoch 157/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2580 - accuracy: 0.8892\n",
      "Epoch 158/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2543 - accuracy: 0.8903\n",
      "Epoch 159/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2570 - accuracy: 0.8910\n",
      "Epoch 160/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2532 - accuracy: 0.8906\n",
      "Epoch 161/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2517 - accuracy: 0.8920\n",
      "Epoch 162/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2594 - accuracy: 0.8878\n",
      "Epoch 163/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2594 - accuracy: 0.8890\n",
      "Epoch 164/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2492 - accuracy: 0.8930\n",
      "Epoch 165/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2562 - accuracy: 0.8925\n",
      "Epoch 166/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2540 - accuracy: 0.8913\n",
      "Epoch 167/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2514 - accuracy: 0.8906\n",
      "Epoch 168/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2556 - accuracy: 0.8931\n",
      "Epoch 169/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2533 - accuracy: 0.8930\n",
      "Epoch 170/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2513 - accuracy: 0.8930\n",
      "Epoch 171/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2573 - accuracy: 0.8910\n",
      "Epoch 172/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2480 - accuracy: 0.8907\n",
      "Epoch 173/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2545 - accuracy: 0.8884\n",
      "Epoch 174/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2549 - accuracy: 0.8892\n",
      "Epoch 175/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2531 - accuracy: 0.8907\n",
      "Epoch 176/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2546 - accuracy: 0.8906\n",
      "Epoch 177/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2513 - accuracy: 0.8940\n",
      "Epoch 178/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2526 - accuracy: 0.8931\n",
      "Epoch 179/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2526 - accuracy: 0.8913\n",
      "Epoch 180/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2551 - accuracy: 0.8910\n",
      "Epoch 181/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2466 - accuracy: 0.8974\n",
      "Epoch 182/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2504 - accuracy: 0.8955\n",
      "Epoch 183/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2493 - accuracy: 0.8945\n",
      "Epoch 184/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2493 - accuracy: 0.8936\n",
      "Epoch 185/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2504 - accuracy: 0.8934\n",
      "Epoch 186/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2507 - accuracy: 0.8938\n",
      "Epoch 187/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2506 - accuracy: 0.8972\n",
      "Epoch 188/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2498 - accuracy: 0.8931\n",
      "Epoch 189/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2507 - accuracy: 0.8925\n",
      "Epoch 190/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2509 - accuracy: 0.8905\n",
      "Epoch 191/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2497 - accuracy: 0.8942\n",
      "Epoch 192/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2550 - accuracy: 0.8934\n",
      "Epoch 193/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2464 - accuracy: 0.8954\n",
      "Epoch 194/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2478 - accuracy: 0.8950\n",
      "Epoch 195/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2487 - accuracy: 0.8928\n",
      "Epoch 196/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2449 - accuracy: 0.8941\n",
      "Epoch 197/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2462 - accuracy: 0.8959\n",
      "Epoch 198/200\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 0.2460 - accuracy: 0.8942\n",
      "Epoch 199/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2464 - accuracy: 0.8947\n",
      "Epoch 200/200\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2460 - accuracy: 0.8935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ae21f198e0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_Y.astype(int), epochs=200, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70c87b43-d98d-46f7-991e-a7d4d538d8a1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.round(model.predict(test_X),0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_36.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dab9e0dd-f9c5-4dbe-9d9a-82956d6ec897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model.predict(test_X)>0.5,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_44.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa4bbd7-2733-4f97-890b-6aab687750cc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "727bf570-675b-4927-8246-c721cb8897ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 80 candidates, totalling 800 fits\n",
      "{'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model_xgb=XGBClassifier(n_jobs=-1,random_state=42,eval_metric='logloss')\n",
    "parameters = {'n_estimators':[50,100,200, 300],'max_depth':[3,4,5,6,7],'learning_rate':[0.1,0.01,0.05,0.001]}\n",
    "model_xgb_grid = GridSearchCV(model_xgb, parameters,cv=10,verbose=1).fit(train_X,train_Y)\n",
    "print(model_xgb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "234e27dc-f1a2-4e8a-9186-0da0ed6e054f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb=XGBClassifier(n_jobs=-1,random_state=42,n_estimators=200,max_depth=4,learning_rate=0.1,eval_metric='logloss')\n",
    "model_xgb.fit(train_X,train_Y)\n",
    "ypred = model_xgb.predict(test_X)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload\n",
    "upload.to_csv('upload_72.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a9ea5f-4cb2-4c33-b40d-f07c7aee6cf5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 73-81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3062c899-d005-431d-9d44-22aa784c48a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dnn=tf.keras.Sequential()\n",
    "\n",
    "model_dnn.add(tf.keras.layers.Dense(25,activation='relu',input_dim=12))\n",
    "model_dnn.add(tf.keras.layers.Dropout(0.5))\n",
    "model_dnn.add(tf.keras.layers.Dense(10,activation='relu'))\n",
    "model_dnn.add(tf.keras.layers.Dropout(0.3))\n",
    "model_dnn.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
    "model_dnn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),loss=\"binary_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3d207a3-b6c7-4084-b831-5b8dce04641f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16823ad2400>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dnn.fit(train_X,train_Y,epochs=200,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "138d2bd2-7199-4f37-b27f-d23182f6fe53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 488us/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.5,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_73.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9cb85f1b-4c6c-4ac7-8558-441aec160cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 625us/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.48,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_74.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "691060f3-118f-4779-85bf-05afd0648747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 456us/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.46,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_75.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9bb097c0-3921-4243-88f7-ee1142bd36de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 546us/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.44,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_76.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "055e37d1-606a-4d03-9bb0-ebd3e2241a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 726us/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.45,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_77.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f887cdf-3140-415f-9c0f-e0a528bff8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 756us/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.448,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_78.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46635cd3-fbe8-4db6-96f3-84692e75ed75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 510us/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.446,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_79.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "721385ac-bdbd-4b41-98a8-e6046d684e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 711us/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.452,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_80.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14fa8aaf-6fe6-43f9-b79f-2672fd93c6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 596us/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.454,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_81.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700e885d-428b-4f19-96d2-4307f86db59c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f420b38-4c47-4399-b2c6-a6592bef25cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dnn=tf.keras.Sequential()\n",
    "\n",
    "model_dnn.add(tf.keras.layers.Dense(25,activation='relu',input_dim=12))\n",
    "model_dnn.add(tf.keras.layers.Dropout(0.5))\n",
    "model_dnn.add(tf.keras.layers.Dense(10,activation='relu'))\n",
    "model_dnn.add(tf.keras.layers.Dropout(0.3))\n",
    "model_dnn.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
    "model_dnn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005),loss=\"binary_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "11ee8570-6464-4a94-aa1c-9bdbf11fa4c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16826e51070>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dnn.fit(train_X,train_Y,epochs=200,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2aafdcc-d2a3-4da2-b20f-688d8630f7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.5,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_82.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c0de1f-6c52-4618-9e9b-107773753878",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 83-85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f94dfaca-3146-4740-92e8-51e936b0820b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dnn=tf.keras.Sequential()\n",
    "\n",
    "model_dnn.add(tf.keras.layers.Dense(25,activation='relu',input_dim=12))\n",
    "model_dnn.add(tf.keras.layers.Dropout(0.5))\n",
    "model_dnn.add(tf.keras.layers.Dense(10,activation='relu'))\n",
    "model_dnn.add(tf.keras.layers.Dropout(0.3))\n",
    "model_dnn.add(tf.keras.layers.Dense(3,activation='relu'))\n",
    "model_dnn.add(tf.keras.layers.Dropout(0.3))\n",
    "model_dnn.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
    "model_dnn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),loss=\"binary_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a3bc7af1-1b30-4961-a5a0-d7b0a88ece14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16825cc8f70>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dnn.fit(train_X,train_Y,epochs=200,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9bf79e0e-ccdf-4cbf-afa7-b43b327d0ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.5,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_83.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "610d26e0-9e38-4e63-940f-97b7fd47e65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.45,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_84.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "04c7c817-6613-4cfa-8ccd-b03ab99cf21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.48,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_85.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7bf949-e6c7-45b9-8f67-e1c45e5a5bd8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 86-88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b8ef2b5d-6269-493d-80f4-30abccbb7a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dnn=tf.keras.Sequential()\n",
    "\n",
    "model_dnn.add(tf.keras.layers.Dense(25,activation='relu',input_dim=12))\n",
    "model_dnn.add(tf.keras.layers.Dropout(0.5))\n",
    "model_dnn.add(tf.keras.layers.Dense(12,activation='relu'))\n",
    "model_dnn.add(tf.keras.layers.Dropout(0.3))\n",
    "model_dnn.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
    "model_dnn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),loss=\"binary_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d7c79185-8215-46c2-b6a5-0ee82c2f2850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16827f486d0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dnn.fit(train_X,train_Y,epochs=200,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f33f405e-28d8-4691-a13e-b00adf72f278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.5,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_86.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "86087c47-ad8c-4a3b-8adc-1c7a68d855eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.45,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_87.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "71ca2919-9ef1-4a6a-b42e-7b10d31af0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.48,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_88.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e501ea-6696-4eb5-80dd-96b2f8b94da0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 89-91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1e5b5ae2-095a-4dc7-bf76-6fb37074b722",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dnn=tf.keras.Sequential()\n",
    "\n",
    "model_dnn.add(tf.keras.layers.Dense(25,activation='relu',input_dim=12))\n",
    "model_dnn.add(tf.keras.layers.Dropout(0.4))\n",
    "model_dnn.add(tf.keras.layers.Dense(9,activation='relu'))\n",
    "model_dnn.add(tf.keras.layers.Dropout(0.3))\n",
    "model_dnn.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
    "model_dnn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),loss=\"binary_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "25275c1b-c04b-4cb9-9f8c-81d85ee4fc51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1682e573b50>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dnn.fit(train_X,train_Y,epochs=200,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "953fd3a4-bf3a-4306-a2c1-94d31b90808a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.5,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_89.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3ff5494d-3509-48c8-ac9b-a3a450869d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.45,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_90.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "60636e4c-e5af-4337-b489-b52a6a69ac27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.48,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_91.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b35c491-0a19-44f9-aa53-19b2576f713d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 92-94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0abb5722-3e4b-47fe-ac22-76226ea3dc51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography_1</th>\n",
       "      <th>Geography_2</th>\n",
       "      <th>Geography_3</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.509906</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.663721</td>\n",
       "      <td>5</td>\n",
       "      <td>0.428978</td>\n",
       "      <td>0.799546</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.304927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.866637</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.465241</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.214512</td>\n",
       "      <td>-0.917139</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.529787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.697356</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.595141</td>\n",
       "      <td>5</td>\n",
       "      <td>0.615161</td>\n",
       "      <td>-0.917139</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.339115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.656894</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.397600</td>\n",
       "      <td>4</td>\n",
       "      <td>0.117359</td>\n",
       "      <td>-0.917139</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.438752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.068534</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.131480</td>\n",
       "      <td>5</td>\n",
       "      <td>0.630562</td>\n",
       "      <td>-0.917139</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.072015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>-1.063169</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.062901</td>\n",
       "      <td>6</td>\n",
       "      <td>0.652575</td>\n",
       "      <td>0.799546</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.011302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>-0.487612</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.267700</td>\n",
       "      <td>7</td>\n",
       "      <td>1.440568</td>\n",
       "      <td>-0.917139</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.033763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>0.815853</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>5</td>\n",
       "      <td>1.025801</td>\n",
       "      <td>-0.917139</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.251627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>1.425266</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.663721</td>\n",
       "      <td>4</td>\n",
       "      <td>0.577801</td>\n",
       "      <td>-0.917139</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.188456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>-0.521469</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.131480</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.214512</td>\n",
       "      <td>-0.917139</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.378566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Geography_1  Geography_2  Geography_3  Gender       Age  \\\n",
       "0        1.509906            1            0            0       1 -0.663721   \n",
       "1        0.866637            0            1            0       0  1.465241   \n",
       "2        0.697356            0            1            0       0 -1.595141   \n",
       "3       -0.656894            1            0            0       0 -0.397600   \n",
       "4        2.068534            1            0            0       1 -0.131480   \n",
       "...           ...          ...          ...          ...     ...       ...   \n",
       "7995    -1.063169            0            1            0       0 -1.062901   \n",
       "7996    -0.487612            0            0            1       0  0.267700   \n",
       "7997     0.815853            1            0            0       0  0.001580   \n",
       "7998     1.425266            0            1            0       1 -0.663721   \n",
       "7999    -0.521469            0            1            0       0 -0.131480   \n",
       "\n",
       "      Tenure   Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0          5  0.428978       0.799546          0               1   \n",
       "1          4 -1.214512      -0.917139          1               0   \n",
       "2          5  0.615161      -0.917139          1               1   \n",
       "3          4  0.117359      -0.917139          1               0   \n",
       "4          5  0.630562      -0.917139          0               1   \n",
       "...      ...       ...            ...        ...             ...   \n",
       "7995       6  0.652575       0.799546          1               1   \n",
       "7996       7  1.440568      -0.917139          1               0   \n",
       "7997       5  1.025801      -0.917139          1               0   \n",
       "7998       4  0.577801      -0.917139          0               0   \n",
       "7999       5 -1.214512      -0.917139          0               0   \n",
       "\n",
       "      EstimatedSalary  \n",
       "0            0.304927  \n",
       "1            0.529787  \n",
       "2            1.339115  \n",
       "3            0.438752  \n",
       "4            1.072015  \n",
       "...               ...  \n",
       "7995         1.011302  \n",
       "7996        -0.033763  \n",
       "7997         1.251627  \n",
       "7998        -0.188456  \n",
       "7999        -1.378566  \n",
       "\n",
       "[16000 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_2 = train_X.copy()\n",
    "train_Y_2 = train_Y.copy()\n",
    "train_X_3 = pd.concat([train_X_2, train_X_2], axis = 0)\n",
    "train_Y_3 = pd.concat([train_Y_2, train_Y_2], axis = 0)\n",
    "train_X_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb1bab75-2642-4f47-84ed-ead1686b9e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dnn=tf.keras.Sequential()\n",
    "\n",
    "model_dnn.add(tf.keras.layers.Dense(25,activation='relu',input_dim=12))\n",
    "model_dnn.add(tf.keras.layers.Dropout(0.5))\n",
    "model_dnn.add(tf.keras.layers.Dense(10,activation='relu'))\n",
    "model_dnn.add(tf.keras.layers.Dropout(0.3))\n",
    "model_dnn.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
    "model_dnn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005),loss=\"binary_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df533f80-57fb-4d0f-af86-5c0bed32a816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x201ead55610>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dnn.fit(train_X_3,train_Y_3,epochs=200,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae375655-5493-4bfb-86e8-8aa7fe2bbfe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.5,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_92.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20830177-3d07-4ced-b310-72ab0853a4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.45,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_93.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cf72fe9-0268-42bc-8d72-d1a842329e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.48,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_94.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4944d5-f562-4d79-9a21-3bb770b81c88",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 95-97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0502489b-d32b-4d9f-8339-1eebfd17581c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dnn=tf.keras.Sequential()\n",
    "\n",
    "model_dnn.add(tf.keras.layers.Dense(30,activation='relu',input_dim=12))\n",
    "model_dnn.add(tf.keras.layers.Dropout(0.5))\n",
    "model_dnn.add(tf.keras.layers.Dense(10,activation='relu'))\n",
    "model_dnn.add(tf.keras.layers.Dropout(0.3))\n",
    "model_dnn.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
    "model_dnn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),loss=\"binary_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bcf7dee3-e6b4-465e-a1f4-48d3c97c1c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x201ec19c4c0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dnn.fit(train_X,train_Y,epochs=200,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22a7101d-4b0d-4deb-8a44-fef9945fe38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.5,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_95.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b50ab8f-728e-47bd-9532-9b00d9ace31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.48,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_96.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ed2bc31-fce7-499d-b2d9-aef0d95630e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.46,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_97.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffad844-57ae-42a2-8186-c979c4acf33a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 98-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1302760-bfae-4c4c-b6f6-42f08858bc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dnn=tf.keras.Sequential()\n",
    "\n",
    "model_dnn.add(tf.keras.layers.Dense(20,activation='relu',input_dim=12))\n",
    "model_dnn.add(tf.keras.layers.Dropout(0.5))\n",
    "model_dnn.add(tf.keras.layers.Dense(10,activation='relu'))\n",
    "model_dnn.add(tf.keras.layers.Dropout(0.3))\n",
    "model_dnn.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
    "model_dnn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),loss=\"binary_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f39ae365-9ec8-4580-9bac-7b074ee9c997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x201ee2f0af0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dnn.fit(train_X,train_Y,epochs=200,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95d2ecb6-6b22-4f50-a798-46a9cf600487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.5,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_98.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d867a98-9bb6-42ec-ac37-5a0bc91030b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.48,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_99.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3fb7b8aa-fbce-49fe-8199-4af2e348e1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.46,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_100.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f9a295-7ede-47d6-965c-e573aec072b2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 101-108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4987397e-59b3-41d4-9c50-f1ed5d6e66b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dnn=tf.keras.Sequential()\n",
    "\n",
    "model_dnn.add(tf.keras.layers.Dense(20,activation='relu',input_dim=12))\n",
    "model_dnn.add(tf.keras.layers.Dropout(0.5))\n",
    "model_dnn.add(tf.keras.layers.Dense(10,activation='relu'))\n",
    "model_dnn.add(tf.keras.layers.Dropout(0.3))\n",
    "model_dnn.add(tf.keras.layers.Dense(3,activation='relu'))\n",
    "model_dnn.add(tf.keras.layers.Dropout(0.2))\n",
    "model_dnn.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
    "model_dnn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),loss=\"binary_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f75eb7bf-d07d-4199-ae89-618cfc8fe7bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x201ee438460>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dnn.fit(train_X,train_Y,epochs=200,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5c3b28a-6e2f-41fe-ad68-8c6a9eb15245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.5,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_101.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a995ce8d-d6e3-4d8d-8626-dd136b04104a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.48,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_102.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05baeeb2-fb21-4079-bcd6-46d93470fbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.46,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_103.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f52c7640-31a2-4337-9015-cbeabcdf867b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.42,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_104.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9701245f-8a1b-4c2e-9b30-1bf2d79c5331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.40,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_105.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d03d6ef-85c6-45a8-ae40-830542909989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.385,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_106.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55834d91-3ef6-44d6-adfd-d81efd90ac95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.39,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_107.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1a97b55-c496-4a6b-a790-f09157207ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.395,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_108.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafe5bc3-a122-47fb-b710-b7fa31e81c3f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 109-111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b3f9384-db6c-4d23-b4ff-8f6718f73030",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dnn=tf.keras.Sequential()\n",
    "\n",
    "model_dnn.add(tf.keras.layers.Dense(15,activation='relu',input_dim=12))\n",
    "model_dnn.add(tf.keras.layers.Dropout(0.2))\n",
    "model_dnn.add(tf.keras.layers.Dense(7,activation='relu'))\n",
    "model_dnn.add(tf.keras.layers.Dropout(0.2))\n",
    "model_dnn.add(tf.keras.layers.Dense(7,activation='relu'))\n",
    "model_dnn.add(tf.keras.layers.Dropout(0.2))\n",
    "model_dnn.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
    "model_dnn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),loss=\"binary_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "adcf3e33-1800-4fcc-ac1a-99ec22c2a566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x201f15c31c0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dnn.fit(train_X,train_Y,epochs=200,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f9670fc5-0566-478f-9eb2-79c69415a726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.5,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_109.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2da83f39-95a7-4741-83e1-bf296e9d7727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.48,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_110.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4f65a4db-f11a-4e94-9c34-e1a42ac9a81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.46,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_111.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7fe372-cae6-4d94-956d-cf69e7bb42de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 112-113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18a6cdc5-b0b3-4a08-82d1-92beb385232a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tenure也standardize\n",
    "model_dnn=tf.keras.Sequential()\n",
    "\n",
    "model_dnn.add(tf.keras.layers.Dense(25,activation='relu',input_dim=12))\n",
    "model_dnn.add(tf.keras.layers.Dropout(0.5))\n",
    "model_dnn.add(tf.keras.layers.Dense(10,activation='relu'))\n",
    "model_dnn.add(tf.keras.layers.Dropout(0.3))\n",
    "model_dnn.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
    "model_dnn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),loss=\"binary_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecf95311-31cc-472b-a3ac-27f94ea3b87c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a5de4829a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dnn.fit(train_X,train_Y,epochs=200,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b684443-bc31-44a8-a572-6b9e71df8462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 2s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.5,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_112.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea429cc9-0ff5-41e3-b5c8-e70f20c104cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.46,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_113.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d08cd54-6744-425d-bc11-9fcf826faa9e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 114-115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10d6eb75-9322-4ebe-aaaf-65cf5936fd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tenure也normalize\n",
    "model_dnn=tf.keras.Sequential()\n",
    "\n",
    "model_dnn.add(tf.keras.layers.Dense(25,activation='relu',input_dim=12))\n",
    "model_dnn.add(tf.keras.layers.Dropout(0.5))\n",
    "model_dnn.add(tf.keras.layers.Dense(10,activation='relu'))\n",
    "model_dnn.add(tf.keras.layers.Dropout(0.3))\n",
    "model_dnn.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
    "model_dnn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),loss=\"binary_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07726814-038b-4c33-abf7-d41d0b5d2cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a5e2b46430>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dnn.fit(train_X,train_Y,epochs=200,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d516ae2d-5db0-46a8-b5ca-6b4c47536ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.5,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_114.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "def4d5d2-15e5-4913-af73-9f11122b5482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.46,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_115.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4d2437-f4e8-43c9-b9b7-17f6b19873c7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 116-117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72262f8e-c80c-49b5-b900-a51e632a29a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only normalize 3 col\n",
    "model_dnn=tf.keras.Sequential()\n",
    "\n",
    "model_dnn.add(tf.keras.layers.Dense(25,activation='relu',input_dim=12))\n",
    "model_dnn.add(tf.keras.layers.Dropout(0.5))\n",
    "model_dnn.add(tf.keras.layers.Dense(10,activation='relu'))\n",
    "model_dnn.add(tf.keras.layers.Dropout(0.3))\n",
    "model_dnn.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
    "model_dnn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),loss=\"binary_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58a18631-68f1-45de-a622-fb9cb6e5f954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a5e17d7a60>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dnn.fit(train_X,train_Y,epochs=200,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2751c387-2049-44be-aba2-565e9bd9e2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.5,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_116.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bacadffb-b374-42d0-9f29-b070d761701d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.46,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_117.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da842cb-e89e-4c02-a493-b318789f6c47",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 118-122"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8e960afc-46f1-4816-ae95-67c5e4a09ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only standardize 3 col\n",
    "model_dnn=tf.keras.Sequential()\n",
    "\n",
    "model_dnn.add(tf.keras.layers.Dense(25,activation='relu',input_dim=12))\n",
    "model_dnn.add(tf.keras.layers.Dropout(0.5))\n",
    "model_dnn.add(tf.keras.layers.Dense(10,activation='relu'))\n",
    "model_dnn.add(tf.keras.layers.Dropout(0.3))\n",
    "model_dnn.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
    "model_dnn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),loss=\"binary_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c37212a7-e782-4777-9f50-a37a63bad71e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a5e177a190>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dnn.fit(train_X,train_Y,epochs=200,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aceda9cb-c7c8-4e9d-9e4c-37ad09a06b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.5,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_118.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d7a23409-3152-4e50-82aa-b3e9029f029a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.46,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_119.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a8c06220-566d-4a82-8fa6-a0c844fb128f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.42,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_120.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b3d2ef67-e25c-490d-bc51-d0a5e378d8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.39,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_121.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5fb88d46-cb6e-473b-b1b2-25368a0b5e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.36,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_122.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd0f1b6-d201-44ad-b12b-3bf203647664",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 123-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c2f0e74f-9abc-4edb-a61d-862dd7d8bacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only standardize 4 col\n",
    "model_dnn=tf.keras.Sequential()\n",
    "\n",
    "model_dnn.add(tf.keras.layers.Dense(25,activation='relu',input_dim=12))\n",
    "model_dnn.add(tf.keras.layers.Dropout(0.5))\n",
    "model_dnn.add(tf.keras.layers.Dense(10,activation='relu'))\n",
    "model_dnn.add(tf.keras.layers.Dropout(0.3))\n",
    "model_dnn.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
    "model_dnn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),loss=\"binary_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "04624dab-58c8-4f39-9156-498ca9683e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a5e54f8970>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dnn.fit(train_X,train_Y,epochs=200,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8b079283-06a1-43e6-9192-a97c75e82a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.5,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_123.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2d8fa8a4-b539-474a-a86f-3592c8f62a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.44,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_124.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "25bafd9e-b852-4e5e-a6c5-9a2cc0be372d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.5,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_125.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "720124b9-8dbf-42a7-a6b5-689daf739727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.45,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_126.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "704d8779-5377-4c30-8ddd-a3dc64f170f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.40,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_127.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "85038f74-a438-4598-945b-c8bb128d71f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred = np.where(model_dnn.predict(test_X)>0.35,1,0)\n",
    "RowNumber = pd.DataFrame(RowNumber)\n",
    "Y_pred = pd.DataFrame(ypred)\n",
    "upload = pd.concat([RowNumber,Y_pred], axis=1)\n",
    "upload.rename(columns={0: 'Exited'}, inplace=True)\n",
    "upload.to_csv('upload_128.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1c0908-c686-4a2e-b043-48ba674eb65f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
