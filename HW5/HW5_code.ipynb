{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a4b3f42-66fa-4efd-b009-4cec8819e8db",
   "metadata": {
    "tags": []
   },
   "source": [
    "# HW5 codes\n",
    "members:<br>\n",
    "1. 劉恩兆 B14081027\n",
    "2. 宋穎恩 B14081302"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f3075f-cacf-4f62-879a-8c32267a2475",
   "metadata": {},
   "source": [
    "注意事項：為留下每次上傳的模型參數設定，會出現較多相似的cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5b346d-7777-4452-b0ed-cbc21cd80032",
   "metadata": {},
   "source": [
    "# loading packages & setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfdc5a7-2d48-45e9-b4ce-b0312b17e2a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install spacy\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# !pip install torch\n",
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d9ec773-8628-49a7-af7d-3f7b9e089b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\danny\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\danny\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import regex as re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# import wordcloud\n",
    "# from wordcloud import WordCloud\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from tqdm import tqdm\n",
    "stop_words = stopwords.words('english')\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb0dcd8-6d58-4e7f-8d76-4c2817417e8d",
   "metadata": {},
   "source": [
    "# loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b6ee83b-5295-4661-9f9f-289e7594fe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29a932d4-95e7-4bde-8bdf-bc01cc05e697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14869, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a0709f4-a3e2-4a70-b9dc-003f83f0ae71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9914, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9f4a00aa-e7a6-4776-a68c-41aad001fc44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[9-1-13] 2:50 pm \"son of a bitch ate my mac n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @BryceSerna: Don't be a pussy grab the boot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @ClicquotSuave: bunch of rappers boutta flo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>@michigannews13 wow. Thats great language comi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>and this is why I'm single, I don't fuck with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14864</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @Estellleeee: Lol bitches act hard when the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14865</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @yes_paul: I bitch about unnecessary things...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14866</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @Im_Amy_Bitches: I'm not always a bitch, so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14867</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @dkiswinning: GamePlan: 1. Eat the pussy 2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14868</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @FeeelGreatness: You don't know where your ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14869 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       class                                              tweet\n",
       "0          1  [9-1-13] 2:50 pm \"son of a bitch ate my mac n ...\n",
       "1          1  RT @BryceSerna: Don't be a pussy grab the boot...\n",
       "2          2  RT @ClicquotSuave: bunch of rappers boutta flo...\n",
       "3          2  @michigannews13 wow. Thats great language comi...\n",
       "4          1  and this is why I'm single, I don't fuck with ...\n",
       "...      ...                                                ...\n",
       "14864      1  RT @Estellleeee: Lol bitches act hard when the...\n",
       "14865      1  RT @yes_paul: I bitch about unnecessary things...\n",
       "14866      1  RT @Im_Amy_Bitches: I'm not always a bitch, so...\n",
       "14867      1  RT @dkiswinning: GamePlan: 1. Eat the pussy 2....\n",
       "14868      1  RT @FeeelGreatness: You don't know where your ...\n",
       "\n",
       "[14869 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82c59393-afff-4b65-8c24-1cfce83e4ab2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>!!!!!!\"@__BrighterDays: I can not just sit up ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>!!!!&amp;#8220;@selfiequeenbri: cause I'm tired of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>\" @rhythmixx_ :hobbies include: fighting Maria...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9909</th>\n",
       "      <td>9909</td>\n",
       "      <td>you're all niggers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9910</th>\n",
       "      <td>9910</td>\n",
       "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9911</th>\n",
       "      <td>9911</td>\n",
       "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9912</th>\n",
       "      <td>9912</td>\n",
       "      <td>youu got wild bitches tellin you lies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9913</th>\n",
       "      <td>9913</td>\n",
       "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9914 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              tweet\n",
       "0        0  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...\n",
       "1        1  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...\n",
       "2        2  !!!!!!\"@__BrighterDays: I can not just sit up ...\n",
       "3        3  !!!!&#8220;@selfiequeenbri: cause I'm tired of...\n",
       "4        4  \" @rhythmixx_ :hobbies include: fighting Maria...\n",
       "...    ...                                                ...\n",
       "9909  9909                                 you're all niggers\n",
       "9910  9910  you's a muthaf***in lie &#8220;@LifeAsKing: @2...\n",
       "9911  9911  young buck wanna eat!!.. dat nigguh like I ain...\n",
       "9912  9912              youu got wild bitches tellin you lies\n",
       "9913  9913  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...\n",
       "\n",
       "[9914 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f70b380-3e3a-4b55-8207-d4fd4d7f5ff9",
   "metadata": {},
   "source": [
    "#### 將資料分出 input & label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b043c40-5a15-46d6-ba77-45f5bc6b52ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input為['tweet']\n",
    "train_inputs = train['tweet']\n",
    "test_inputs = test['tweet']\n",
    "# label為train資料的['class']\n",
    "train_labels = train['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddacbbb8-e728-49ec-8099-bbdaaadc9362",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94c873c-6dfa-498b-9841-2994c7acb88d",
   "metadata": {},
   "source": [
    "##### 清除無用無字以及停用詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c74b3d69-5f8c-47e5-a1fc-d67148d5d5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "def clean_text(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub(r\"^(rt)\", \"\", text) #Removing RT in the beginning \n",
    "    \n",
    "    text = re.sub(r\"(@[a-zA-Z0-9_]*[:;, ])\", \"\", text) #Removing @user \n",
    "    \n",
    "    text = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", text) # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "\n",
    "    text = re.sub(r\"http\\S+\", \"\",text) #Removing URLs \n",
    "    #text = re.sub(r\"http\", \"\",text)\n",
    "    \n",
    "    html=re.compile(r'<.*?>') \n",
    "    \n",
    "    text = html.sub(r'',text) #Removing html tags\n",
    "    \n",
    "    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\" + '_'\n",
    "    for p in punctuations:\n",
    "        text = text.replace(p,'') #Removing punctuations\n",
    "        \n",
    "    text = [word.lower() for word in text.split() if word.lower() not in sw]\n",
    "    \n",
    "    text = [lemmatizer.lemmatize(word) for word in text]\n",
    "    \n",
    "    text = \" \".join(text) #removing stopwords\n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text) #Removing emojis\n",
    "    \n",
    "    text = re.sub(r\"^(am)\", \"\",text)\n",
    "    text = re.sub(r\"^(pm)\", \"\",text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55931b1c-463c-48d3-85ee-ac0218b076f9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>son bitch ate mac n cheese http tco ojyz w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>pussy grab booty love booty appreciate booty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>bunch rapper boutta flood internet w trash rem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>wow thats great language coming h coach, sure ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>single, fuck bitch attitude foh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>yea hoe rocking friday last night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>free da real niccas n give snitch da time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>ur fag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>judge appointed obama doesnt see agenda fuckin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>wonder nsa spook following</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>rt love hood bitch god help lmaoooo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>trust bitch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>think flat wrong blame brian cashman yankee snytv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>lil fraudulent bitch nerve call phone talking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>shit pussy joke end like rest show chicken shi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>pussy nigga fuck chick stretch mark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>main nigguh since digital camera selfies http ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>fuckin skyler white bitch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>yes good shapely eurotrash manbooty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>love hoe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>got hoe yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>ill take yo bitch make everybody bitch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>handle liquor bitch handle meeedd chief sosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>thought enough hair ponytail bitch http tco pw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>beat pussy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>cruising go kart walmart selling cupcakes, go ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>bitzy probably popped percocet drink mellie se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>vienna sausage clit http tco yy gj oed suck da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>wyo bitch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>looked like time looked like biker bitch punk ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    class                                              tweet\n",
       "0       1         son bitch ate mac n cheese http tco ojyz w\n",
       "1       1       pussy grab booty love booty appreciate booty\n",
       "2       2  bunch rapper boutta flood internet w trash rem...\n",
       "3       2  wow thats great language coming h coach, sure ...\n",
       "4       1                    single, fuck bitch attitude foh\n",
       "5       1                  yea hoe rocking friday last night\n",
       "6       1          free da real niccas n give snitch da time\n",
       "7       0                                             ur fag\n",
       "8       1  judge appointed obama doesnt see agenda fuckin...\n",
       "9       2                         wonder nsa spook following\n",
       "10      1                rt love hood bitch god help lmaoooo\n",
       "11      1                                        trust bitch\n",
       "12      2  think flat wrong blame brian cashman yankee snytv\n",
       "13      1  lil fraudulent bitch nerve call phone talking ...\n",
       "14      0  shit pussy joke end like rest show chicken shi...\n",
       "15      0                pussy nigga fuck chick stretch mark\n",
       "16      0  main nigguh since digital camera selfies http ...\n",
       "17      1                          fuckin skyler white bitch\n",
       "18      1                yes good shapely eurotrash manbooty\n",
       "19      1                                           love hoe\n",
       "20      1                                        got hoe yet\n",
       "21      1             ill take yo bitch make everybody bitch\n",
       "22      1       handle liquor bitch handle meeedd chief sosa\n",
       "23      1  thought enough hair ponytail bitch http tco pw...\n",
       "24      1                                         beat pussy\n",
       "25      1  cruising go kart walmart selling cupcakes, go ...\n",
       "26      1  bitzy probably popped percocet drink mellie se...\n",
       "27      1  vienna sausage clit http tco yy gj oed suck da...\n",
       "28      1                                          wyo bitch\n",
       "29      1  looked like time looked like biker bitch punk ..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tweet'] = train['tweet'].apply(lambda x: clean_text(x))\n",
    "test['tweet'] = test['tweet'].apply(lambda x: clean_text(x))\n",
    "train.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf79b5c8-5010-4ab1-87d5-190b10a2996f",
   "metadata": {},
   "source": [
    "##### 將文字資料轉為TF-IDF矩陣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3737a31e-0112-4a34-8c83-d1638a21b641",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer() \n",
    "\n",
    "tfidf_train_vectors = tfidf_vectorizer.fit_transform(train_inputs)\n",
    "\n",
    "tfidf_test_vectors = tfidf_vectorizer.transform(test_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73436c7-8518-4374-abc6-779605bd83ac",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35d3f6ce-814d-4e30-ba74-e375bcf593e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier()\n",
    "\n",
    "classifier.fit(tfidf_train_vectors, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a65650f-cd24-4735-ae2c-cc01efe49222",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(tfidf_test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41575450-e1eb-445c-a76d-28edc5b4c623",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9909</th>\n",
       "      <td>9909</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9910</th>\n",
       "      <td>9910</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9911</th>\n",
       "      <td>9911</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9912</th>\n",
       "      <td>9912</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9913</th>\n",
       "      <td>9913</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9914 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  class\n",
       "0        0      1\n",
       "1        1      1\n",
       "2        2      1\n",
       "3        3      1\n",
       "4        4      1\n",
       "...    ...    ...\n",
       "9909  9909      1\n",
       "9910  9910      1\n",
       "9911  9911      1\n",
       "9912  9912      1\n",
       "9913  9913      2\n",
       "\n",
       "[9914 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df = pd.DataFrame(y_pred)\n",
    "id = pd.DataFrame([*range(0,9914)])\n",
    "upload = pd.concat([id, prediction_df], axis=1)\n",
    "upload.columns=['id','class']\n",
    "upload.to_csv('upload_12.csv')\n",
    "upload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95ac891-b30a-4a62-9055-158bd741065c",
   "metadata": {},
   "source": [
    "##### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f377b7c-a8ba-447f-8e20-cbcdb33ec158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "classifier = lgb.LGBMClassifier(n_estimators=200,max_depth=5)\n",
    "classifier.fit(tfidf_train_vectors, train_labels)\n",
    "y_pred = classifier.predict(tfidf_test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "938844b3-56b6-4484-90a3-34e01b7d331e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9909</th>\n",
       "      <td>9909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9910</th>\n",
       "      <td>9910</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9911</th>\n",
       "      <td>9911</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9912</th>\n",
       "      <td>9912</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9913</th>\n",
       "      <td>9913</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9914 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  class\n",
       "0        0      1\n",
       "1        1      2\n",
       "2        2      1\n",
       "3        3      1\n",
       "4        4      1\n",
       "...    ...    ...\n",
       "9909  9909      0\n",
       "9910  9910      2\n",
       "9911  9911      1\n",
       "9912  9912      1\n",
       "9913  9913      2\n",
       "\n",
       "[9914 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df = pd.DataFrame(y_pred)\n",
    "id = pd.DataFrame([*range(0,9914)])\n",
    "upload = pd.concat([id, prediction_df], axis=1)\n",
    "upload.columns=['id','class']\n",
    "upload.to_csv('upload_30.csv')\n",
    "upload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45075799-33a0-4241-926c-b59929235fae",
   "metadata": {},
   "source": [
    "##### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c599188e-fda9-4690-aa9a-21d53bb77d6f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.68004319\n",
      "Iteration 2, loss = 0.58427757\n",
      "Iteration 3, loss = 0.40228923\n",
      "Iteration 4, loss = 0.33145592\n",
      "Iteration 5, loss = 0.28448658\n",
      "Iteration 6, loss = 0.25869075\n",
      "Iteration 7, loss = 0.27971799\n",
      "Iteration 8, loss = 0.31371892\n",
      "Iteration 9, loss = 0.35723937\n",
      "Iteration 10, loss = 0.28098913\n",
      "Iteration 11, loss = 0.17647206\n",
      "Iteration 12, loss = 0.12655612\n",
      "Iteration 13, loss = 0.09796744\n",
      "Iteration 14, loss = 0.63822520\n",
      "Iteration 15, loss = 0.29286453\n",
      "Iteration 16, loss = 0.23689069\n",
      "Iteration 17, loss = 0.40922554\n",
      "Iteration 18, loss = 0.18151037\n",
      "Iteration 19, loss = 0.26444635\n",
      "Iteration 20, loss = 0.20654021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "classifier = MLPClassifier(solver='sgd', activation='relu',alpha=1e-4,hidden_layer_sizes=(50,50), random_state=1,max_iter=20,verbose=10,learning_rate_init=.1)\n",
    "classifier.fit(tfidf_train_vectors, train_labels)\n",
    "y_pred = classifier.predict(tfidf_test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "998dd048-7c81-442c-ae6a-c57294133c0d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9909</th>\n",
       "      <td>9909</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9910</th>\n",
       "      <td>9910</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9911</th>\n",
       "      <td>9911</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9912</th>\n",
       "      <td>9912</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9913</th>\n",
       "      <td>9913</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9914 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  class\n",
       "0        0      1\n",
       "1        1      1\n",
       "2        2      1\n",
       "3        3      1\n",
       "4        4      1\n",
       "...    ...    ...\n",
       "9909  9909      1\n",
       "9910  9910      2\n",
       "9911  9911      1\n",
       "9912  9912      1\n",
       "9913  9913      2\n",
       "\n",
       "[9914 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df = pd.DataFrame(y_pred)\n",
    "id = pd.DataFrame([*range(0,9914)])\n",
    "upload = pd.concat([id, prediction_df], axis=1)\n",
    "upload.columns=['id','class']\n",
    "upload.to_csv('upload_14.csv')\n",
    "upload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0960891-d93d-4815-a1ad-50c3d01a6432",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Bert Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b4f80e-0754-4ad3-9d74-672c1cc9dc8d",
   "metadata": {},
   "source": [
    "### check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bde132d4-4f9d-4934-8237-f30ff494377c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 3070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# If there's a GPU available\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If there's no GPU available\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "# 使用GPU來訓練"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5eb007-0b6f-4714-8097-756158fe39fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dataset settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1bf9017b-25eb-402e-a796-80c4b7fa4a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "labels = {0:0,\n",
    "          1:1,\n",
    "          2:2 }\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.labels = [labels[label] for label in df['class']]\n",
    "        self.texts = [tokenizer(text, \n",
    "                                padding='max_length', \n",
    "                                max_length = 512, \n",
    "                                truncation=True,\n",
    "                                return_tensors=\"pt\") \n",
    "                      for text in df['tweet']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f87720-2bd1-453c-88fa-0b6dfaf30a14",
   "metadata": {},
   "source": [
    "### construct a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c9c6ca-c308-49f2-95fb-849e0c22f242",
   "metadata": {},
   "source": [
    "##### upload 1-5 setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b27f960-7d50-458a-93d8-fc4144b690f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload 1-5 setting\n",
    "from transformers import BertModel\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 3)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5360a2-cb7d-49ba-af07-17d56211ce80",
   "metadata": {},
   "source": [
    "##### upload 7 setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fc8f955-4f92-4fd8-a564-dcb364c2566f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload 7 setting\n",
    "from transformers import BertModel\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, dropout=0.3):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 3)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f23cd8-fc87-4a25-871b-316a19e43850",
   "metadata": {},
   "source": [
    "### training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384cb452-0d31-4157-ad42-834758039fa8",
   "metadata": {},
   "source": [
    "##### upload 1-5 setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7350b04-58ff-487d-b63d-04e594c8cff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "def trainmodel(model, train_data, learning_rate, epochs):\n",
    "  # 通過Dataset類獲取訓練集\n",
    "    train = Dataset(train_data)\n",
    "    # DataLoader根據batch_size獲取數據，訓練時選擇打亂樣本\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
    "  # 判斷是否使用GPU\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    # 定義損失函數和優化器\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "            model = model.cuda()\n",
    "            criterion = criterion.cuda()\n",
    "    # 開始進入訓練循環\n",
    "    for epoch_num in range(epochs):\n",
    "      # 定義兩個變量，用於存儲訓練集的準確率和損失\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "      # 進度條函數tqdm\n",
    "            for train_input, train_label in tqdm(train_dataloader):\n",
    "\n",
    "                train_label = train_label.to(device)\n",
    "                mask = train_input['attention_mask'].to(device)\n",
    "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "        # 通過模型得到輸出\n",
    "                output = model(input_id, mask)\n",
    "                # 計算損失\n",
    "                #\n",
    "                train_label = train_label.type(torch.LongTensor)\n",
    "                train_label = train_label.to(device)\n",
    "                #\n",
    "                batch_loss = criterion(output, train_label)\n",
    "                total_loss_train += batch_loss.item()\n",
    "                # 計算精度\n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "        # 模型更新\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            print(\n",
    "                f'''Epochs: {epoch_num + 1} \n",
    "              | Train Loss: {total_loss_train / len(train_data): .3f} \n",
    "              | Train Accuracy: {total_acc_train / len(train_data): .3f}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b68717ef-ba0e-471f-b856-44b49e62dfed",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 7435/7435 [12:14<00:00, 10.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 \n",
      "              | Train Loss:  0.223 \n",
      "              | Train Accuracy:  0.844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 7435/7435 [12:13<00:00, 10.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 \n",
      "              | Train Loss:  0.139 \n",
      "              | Train Accuracy:  0.913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 7435/7435 [12:09<00:00, 10.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 \n",
      "              | Train Loss:  0.116 \n",
      "              | Train Accuracy:  0.926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 7435/7435 [12:07<00:00, 10.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 \n",
      "              | Train Loss:  0.097 \n",
      "              | Train Accuracy:  0.937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 7435/7435 [12:09<00:00, 10.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 \n",
      "              | Train Loss:  0.078 \n",
      "              | Train Accuracy:  0.950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 7435/7435 [12:05<00:00, 10.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 6 \n",
      "              | Train Loss:  0.054 \n",
      "              | Train Accuracy:  0.964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 7435/7435 [12:07<00:00, 10.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 7 \n",
      "              | Train Loss:  0.031 \n",
      "              | Train Accuracy:  0.979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 7435/7435 [12:09<00:00, 10.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 8 \n",
      "              | Train Loss:  0.017 \n",
      "              | Train Accuracy:  0.991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 7435/7435 [12:16<00:00, 10.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 9 \n",
      "              | Train Loss:  0.011 \n",
      "              | Train Accuracy:  0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 7435/7435 [12:19<00:00, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10 \n",
      "              | Train Loss:  0.007 \n",
      "              | Train Accuracy:  0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "model = BertClassifier()\n",
    "LR = 1e-6\n",
    "trainmodel(model, train, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4797fcd0-01e0-4bb0-8136-1a46816a9b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 7435/7435 [12:09<00:00, 10.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 \n",
      "              | Train Loss:  0.228 \n",
      "              | Train Accuracy:  0.835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 7435/7435 [12:04<00:00, 10.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 \n",
      "              | Train Loss:  0.138 \n",
      "              | Train Accuracy:  0.911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 7435/7435 [12:01<00:00, 10.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 \n",
      "              | Train Loss:  0.112 \n",
      "              | Train Accuracy:  0.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 7435/7435 [12:01<00:00, 10.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 \n",
      "              | Train Loss:  0.091 \n",
      "              | Train Accuracy:  0.938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 7435/7435 [12:01<00:00, 10.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 \n",
      "              | Train Loss:  0.067 \n",
      "              | Train Accuracy:  0.953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 7435/7435 [12:01<00:00, 10.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 6 \n",
      "              | Train Loss:  0.044 \n",
      "              | Train Accuracy:  0.969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 7435/7435 [12:01<00:00, 10.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 7 \n",
      "              | Train Loss:  0.026 \n",
      "              | Train Accuracy:  0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 7435/7435 [12:01<00:00, 10.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 8 \n",
      "              | Train Loss:  0.016 \n",
      "              | Train Accuracy:  0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 7435/7435 [12:01<00:00, 10.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 9 \n",
      "              | Train Loss:  0.011 \n",
      "              | Train Accuracy:  0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 7435/7435 [12:01<00:00, 10.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10 \n",
      "              | Train Loss:  0.009 \n",
      "              | Train Accuracy:  0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 7435/7435 [12:01<00:00, 10.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 11 \n",
      "              | Train Loss:  0.008 \n",
      "              | Train Accuracy:  0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 7435/7435 [12:01<00:00, 10.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 12 \n",
      "              | Train Loss:  0.007 \n",
      "              | Train Accuracy:  0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#20\n",
    "EPOCHS = 12\n",
    "model = BertClassifier()\n",
    "LR = 1e-6\n",
    "trainmodel(model, train, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23120502-b712-496a-8ba7-155b2c674875",
   "metadata": {},
   "source": [
    "##### upload 7 setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6779fe91-acad-43a8-8be4-e8eed82a3923",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "def trainmodel(model, train_data, learning_rate, epochs):\n",
    "  # 通過Dataset類獲取訓練集\n",
    "    train = Dataset(train_data)\n",
    "    # DataLoader根據batch_size獲取數據，訓練時選擇打亂樣本\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=6, shuffle=True)\n",
    "  # 判斷是否使用GPU\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    # 定義損失函數和優化器\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "            model = model.cuda()\n",
    "            criterion = criterion.cuda()\n",
    "    # 開始進入訓練循環\n",
    "    for epoch_num in range(epochs):\n",
    "      # 定義兩個變量，用於存儲訓練集的準確率和損失\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "      # 進度條函數tqdm\n",
    "            for train_input, train_label in tqdm(train_dataloader):\n",
    "\n",
    "                train_label = train_label.to(device)\n",
    "                mask = train_input['attention_mask'].to(device)\n",
    "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "        # 通過模型得到輸出\n",
    "                output = model(input_id, mask)\n",
    "                # 計算損失\n",
    "                #\n",
    "                train_label = train_label.type(torch.LongTensor)\n",
    "                train_label = train_label.to(device)\n",
    "                #\n",
    "                batch_loss = criterion(output, train_label)\n",
    "                total_loss_train += batch_loss.item()\n",
    "                # 計算精度\n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "        # 模型更新\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            print(\n",
    "                f'''Epochs: {epoch_num + 1} \n",
    "              | Train Loss: {total_loss_train / len(train_data): .3f} \n",
    "              | Train Accuracy: {total_acc_train / len(train_data): .3f}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92a9ec77-4ce6-434b-b62e-51f614b66481",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3718/3718 [09:46<00:00,  6.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 \n",
      "              | Train Loss:  0.118 \n",
      "              | Train Accuracy:  0.836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3718/3718 [09:43<00:00,  6.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 \n",
      "              | Train Loss:  0.072 \n",
      "              | Train Accuracy:  0.910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3718/3718 [09:41<00:00,  6.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 \n",
      "              | Train Loss:  0.059 \n",
      "              | Train Accuracy:  0.921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3718/3718 [09:41<00:00,  6.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 \n",
      "              | Train Loss:  0.048 \n",
      "              | Train Accuracy:  0.933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3718/3718 [09:41<00:00,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 \n",
      "              | Train Loss:  0.038 \n",
      "              | Train Accuracy:  0.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "model = BertClassifier()\n",
    "LR = 1e-6\n",
    "trainmodel(model, train, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5478f3-8e53-43d3-9cb8-594db4866ad2",
   "metadata": {},
   "source": [
    "##### upload 8 setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56c00649-0e6a-4f23-b251-cf1e3b5f6c21",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3718/3718 [09:44<00:00,  6.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 \n",
      "              | Train Loss:  0.111 \n",
      "              | Train Accuracy:  0.857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3718/3718 [09:49<00:00,  6.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 \n",
      "              | Train Loss:  0.072 \n",
      "              | Train Accuracy:  0.911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 2\n",
    "model = BertClassifier()\n",
    "LR = 1e-6\n",
    "trainmodel(model, train, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f904a5-8871-4274-b826-c33cdc9af3c3",
   "metadata": {},
   "source": [
    "##### upload 9 setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18ef9271-7875-41ca-9675-4a8b3a36c556",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2479/2479 [09:08<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 \n",
      "              | Train Loss:  0.081 \n",
      "              | Train Accuracy:  0.832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2479/2479 [09:01<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 \n",
      "              | Train Loss:  0.047 \n",
      "              | Train Accuracy:  0.912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2479/2479 [09:08<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 \n",
      "              | Train Loss:  0.038 \n",
      "              | Train Accuracy:  0.924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2479/2479 [09:14<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 \n",
      "              | Train Loss:  0.032 \n",
      "              | Train Accuracy:  0.936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2479/2479 [09:09<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 \n",
      "              | Train Loss:  0.027 \n",
      "              | Train Accuracy:  0.947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2479/2479 [09:12<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 6 \n",
      "              | Train Loss:  0.022 \n",
      "              | Train Accuracy:  0.961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2479/2479 [09:02<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 7 \n",
      "              | Train Loss:  0.016 \n",
      "              | Train Accuracy:  0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2479/2479 [09:04<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 8 \n",
      "              | Train Loss:  0.011 \n",
      "              | Train Accuracy:  0.986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2479/2479 [09:06<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 9 \n",
      "              | Train Loss:  0.007 \n",
      "              | Train Accuracy:  0.991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2479/2479 [09:01<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10 \n",
      "              | Train Loss:  0.005 \n",
      "              | Train Accuracy:  0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2479/2479 [09:04<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 11 \n",
      "              | Train Loss:  0.004 \n",
      "              | Train Accuracy:  0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2479/2479 [09:03<00:00,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 12 \n",
      "              | Train Loss:  0.003 \n",
      "              | Train Accuracy:  0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 12\n",
    "model = BertClassifier()\n",
    "LR = 1e-6\n",
    "trainmodel(model, train, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cf8d090-8ae4-4d7d-b601-89f56934f14b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2479/2479 [09:06<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 \n",
      "              | Train Loss:  0.115 \n",
      "              | Train Accuracy:  0.771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2479/2479 [09:05<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 \n",
      "              | Train Loss:  0.114 \n",
      "              | Train Accuracy:  0.773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2479/2479 [09:01<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 \n",
      "              | Train Loss:  0.113 \n",
      "              | Train Accuracy:  0.773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2479/2479 [09:01<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 \n",
      "              | Train Loss:  0.112 \n",
      "              | Train Accuracy:  0.773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2479/2479 [09:01<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 \n",
      "              | Train Loss:  0.112 \n",
      "              | Train Accuracy:  0.773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2479/2479 [09:02<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 6 \n",
      "              | Train Loss:  0.112 \n",
      "              | Train Accuracy:  0.773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2479/2479 [09:06<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 7 \n",
      "              | Train Loss:  0.112 \n",
      "              | Train Accuracy:  0.773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2479/2479 [09:06<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 8 \n",
      "              | Train Loss:  0.111 \n",
      "              | Train Accuracy:  0.773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2479/2479 [09:03<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 9 \n",
      "              | Train Loss:  0.111 \n",
      "              | Train Accuracy:  0.773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2479/2479 [09:01<00:00,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10 \n",
      "              | Train Loss:  0.112 \n",
      "              | Train Accuracy:  0.773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "model = BertClassifier()\n",
    "LR = 0.0001\n",
    "trainmodel(model, train, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8306d04b-246c-4622-9310-725d4c2a4985",
   "metadata": {},
   "source": [
    "### model predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d826e1fb-6be0-4af9-8c80-eec1cfa62eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [0,1,2]\n",
    "prediction_list = []\n",
    "tweet = test['tweet'].tolist()\n",
    "# tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d3b55e0d-045c-4f10-9c9b-a1461ec54e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for i in tweet:\n",
    "    encoded_review = tokenizer.encode_plus(\n",
    "        i,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        add_special_tokens=True,\n",
    "        return_token_type_ids=False,\n",
    "        pad_to_max_length=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "    input_ids = encoded_review['input_ids'].to(device)\n",
    "    attention_mask = encoded_review['attention_mask'].to(device)\n",
    "    output = model(input_ids, attention_mask)\n",
    "    _, prediction = torch.max(output, dim=1)\n",
    "    prediction_list.append(class_names[prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec62f906-62e4-4451-84d3-4c0f787e05e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9909</th>\n",
       "      <td>9909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9910</th>\n",
       "      <td>9910</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9911</th>\n",
       "      <td>9911</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9912</th>\n",
       "      <td>9912</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9913</th>\n",
       "      <td>9913</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9914 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  class\n",
       "0        0      1\n",
       "1        1      0\n",
       "2        2      1\n",
       "3        3      1\n",
       "4        4      1\n",
       "...    ...    ...\n",
       "9909  9909      0\n",
       "9910  9910      2\n",
       "9911  9911      1\n",
       "9912  9912      1\n",
       "9913  9913      2\n",
       "\n",
       "[9914 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df = pd.DataFrame(prediction_list)\n",
    "id = pd.DataFrame([*range(0,9914)])\n",
    "upload = pd.concat([id, prediction_df], axis=1)\n",
    "upload.columns=['id','class']\n",
    "upload.to_csv('upload_20.csv')\n",
    "upload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85d5b41-486d-464c-8783-d7752a2b7388",
   "metadata": {
    "tags": []
   },
   "source": [
    "## No punctuation version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a52323aa-3453-49af-bb46-2971e8747c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danny\\AppData\\Local\\Temp\\ipykernel_23900\\2102231581.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_no_punc['tweet'] = train_no_punc['tweet'].str.replace(r'[^\\w\\s]+', '')\n",
      "C:\\Users\\danny\\AppData\\Local\\Temp\\ipykernel_23900\\2102231581.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test_no_punc['tweet'] = test_no_punc['tweet'].str.replace(r'[^\\w\\s]+', '')\n"
     ]
    }
   ],
   "source": [
    "train_no_punc = train.copy()\n",
    "test_no_punc = test.copy()\n",
    "train_no_punc['tweet'] = train_no_punc['tweet'].str.replace(r'[^\\w\\s]+', '')\n",
    "test_no_punc['tweet'] = test_no_punc['tweet'].str.replace(r'[^\\w\\s]+', '')\n",
    "train_no_punc\n",
    "# input為['tweet']\n",
    "train_inputs = train['tweet']\n",
    "test_inputs = test['tweet']\n",
    "# label為train資料的['class']\n",
    "train_labels = train['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110b085f-780f-4063-8d4e-c946d04a3c6e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dataset settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d0dc20d-3f03-4803-89c7-d481efef4a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "labels = {0:0,\n",
    "          1:1,\n",
    "          2:2 }\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.labels = [labels[label] for label in df['class']]\n",
    "        self.texts = [tokenizer(text, \n",
    "                                padding='max_length', \n",
    "                                max_length = 512, \n",
    "                                truncation=True,\n",
    "                                return_tensors=\"pt\") \n",
    "                      for text in df['tweet']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1261a133-b9ae-4f12-bb52-32e41a1676a4",
   "metadata": {},
   "source": [
    "### construct a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8fcf424c-7efa-4204-8fee-0921dcb9d3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11\n",
    "from transformers import BertModel\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, dropout=0.3):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 3)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c8967a-17fb-4d51-afba-42d9c10540fc",
   "metadata": {},
   "source": [
    "### training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0effd167-501f-43bc-a4ae-be384da0d2b4",
   "metadata": {},
   "source": [
    "##### upload 11 setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f661b06-12d0-49cc-a5bb-7a3ffdf55ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "def trainmodel(model, train_data, learning_rate, epochs):\n",
    "  # 通過Dataset類獲取訓練集\n",
    "    train = Dataset(train_data)\n",
    "    # DataLoader根據batch_size獲取數據，訓練時選擇打亂樣本\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=7, shuffle=True)\n",
    "  # 判斷是否使用GPU\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    # 定義損失函數和優化器\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "            model = model.cuda()\n",
    "            criterion = criterion.cuda()\n",
    "    # 開始進入訓練循環\n",
    "    for epoch_num in range(epochs):\n",
    "      # 定義兩個變量，用於存儲訓練集的準確率和損失\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "      # 進度條函數tqdm\n",
    "            for train_input, train_label in tqdm(train_dataloader):\n",
    "\n",
    "                train_label = train_label.to(device)\n",
    "                mask = train_input['attention_mask'].to(device)\n",
    "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "        # 通過模型得到輸出\n",
    "                output = model(input_id, mask)\n",
    "                # 計算損失\n",
    "                #\n",
    "                train_label = train_label.type(torch.LongTensor)\n",
    "                train_label = train_label.to(device)\n",
    "                #\n",
    "                batch_loss = criterion(output, train_label)\n",
    "                total_loss_train += batch_loss.item()\n",
    "                # 計算精度\n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "        # 模型更新\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            print(\n",
    "                f'''Epochs: {epoch_num + 1} \n",
    "              | Train Loss: {total_loss_train / len(train_data): .3f} \n",
    "              | Train Accuracy: {total_acc_train / len(train_data): .3f}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9424e82-d21e-442b-b1bf-72f39746b2b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2125/2125 [09:22<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 \n",
      "              | Train Loss:  0.128 \n",
      "              | Train Accuracy:  0.320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2125/2125 [09:25<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 \n",
      "              | Train Loss:  0.059 \n",
      "              | Train Accuracy:  0.767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2125/2125 [09:21<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 \n",
      "              | Train Loss:  0.055 \n",
      "              | Train Accuracy:  0.770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2125/2125 [09:19<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 \n",
      "              | Train Loss:  0.051 \n",
      "              | Train Accuracy:  0.777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2125/2125 [09:16<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 \n",
      "              | Train Loss:  0.042 \n",
      "              | Train Accuracy:  0.867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2125/2125 [09:15<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 6 \n",
      "              | Train Loss:  0.027 \n",
      "              | Train Accuracy:  0.942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2125/2125 [09:19<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 7 \n",
      "              | Train Loss:  0.020 \n",
      "              | Train Accuracy:  0.959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2125/2125 [09:15<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 8 \n",
      "              | Train Loss:  0.015 \n",
      "              | Train Accuracy:  0.970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2125/2125 [09:23<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 9 \n",
      "              | Train Loss:  0.011 \n",
      "              | Train Accuracy:  0.978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2125/2125 [09:20<00:00,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10 \n",
      "              | Train Loss:  0.008 \n",
      "              | Train Accuracy:  0.986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "model = BertClassifier()\n",
    "LR = 1e-6\n",
    "trainmodel(model, train, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5dbfd7-2936-4618-bb89-1e971eeb9d76",
   "metadata": {},
   "source": [
    "### model predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "08c33880-5d01-46e7-bfdd-ecc7cc60e841",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [0,1,2]\n",
    "prediction_list = []\n",
    "tweet = test['tweet'].tolist()\n",
    "# tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23bff9d0-d91b-4027-b02e-3177353845f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for i in tweet:\n",
    "    encoded_review = tokenizer.encode_plus(\n",
    "        i,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        add_special_tokens=True,\n",
    "        return_token_type_ids=False,\n",
    "        pad_to_max_length=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "    input_ids = encoded_review['input_ids'].to(device)\n",
    "    attention_mask = encoded_review['attention_mask'].to(device)\n",
    "    output = model(input_ids, attention_mask)\n",
    "    _, prediction = torch.max(output, dim=1)\n",
    "    prediction_list.append(class_names[prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "453157a3-17f3-4cea-bae2-223b16bdc0b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9909</th>\n",
       "      <td>9909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9910</th>\n",
       "      <td>9910</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9911</th>\n",
       "      <td>9911</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9912</th>\n",
       "      <td>9912</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9913</th>\n",
       "      <td>9913</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9914 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  class\n",
       "0        0      1\n",
       "1        1      0\n",
       "2        2      1\n",
       "3        3      1\n",
       "4        4      1\n",
       "...    ...    ...\n",
       "9909  9909      0\n",
       "9910  9910      2\n",
       "9911  9911      1\n",
       "9912  9912      1\n",
       "9913  9913      2\n",
       "\n",
       "[9914 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df = pd.DataFrame(prediction_list)\n",
    "id = pd.DataFrame([*range(0,9914)])\n",
    "upload = pd.concat([id, prediction_df], axis=1)\n",
    "upload.columns=['id','class']\n",
    "upload.to_csv('upload_11.csv')\n",
    "upload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d10492-6eaf-473e-b0a7-f47f6c2c01a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 清理乾淨版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec8d0eea-cf80-4fb4-9a9d-700ea1c6abec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub(r\"^(rt)\", \"\", text) #Removing RT in the beginning \n",
    "    \n",
    "    text = re.sub(r\"(@[a-zA-Z0-9_]*[:;, ])\", \"\", text) #Removing @user \n",
    "    \n",
    "    text = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", text) # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "\n",
    "    text = re.sub(r\"http\\S+\", \"\",text) #Removing URLs \n",
    "    #text = re.sub(r\"http\", \"\",text)\n",
    "    \n",
    "    html=re.compile(r'<.*?>') \n",
    "    \n",
    "    text = html.sub(r'',text) #Removing html tags\n",
    "    \n",
    "    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\" + '_'\n",
    "    for p in punctuations:\n",
    "        text = text.replace(p,'') #Removing punctuations\n",
    "    \n",
    "    text = \" \".join(text) #removing stopwords\n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text) #Removing emojis\n",
    "    \n",
    "    text = re.sub(r\"^(am)\", \"\",text)\n",
    "    text = re.sub(r\"^(pm)\", \"\",text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5d29834-921d-422f-8b76-318b05416345",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean = train.copy()\n",
    "test_clean = test.copy()\n",
    "train_clean['tweet'] = train_clean['tweet'].apply(lambda x: clean_text(x))\n",
    "test_clean['tweet'] = test_clean['tweet'].apply(lambda x: clean_text(x))\n",
    "# input為['tweet']\n",
    "train_inputs = train_clean['tweet']\n",
    "test_inputs = test_clean['tweet']\n",
    "# label為train資料的['class']\n",
    "train_labels = train_clean['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841929db-3f69-4cc0-9654-3c164f1dcffd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dataset settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7cad518-7a86-44e8-b9b1-272a2a81d85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "labels = {0:0,\n",
    "          1:1,\n",
    "          2:2 }\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.labels = [labels[label] for label in df['class']]\n",
    "        self.texts = [tokenizer(text, \n",
    "                                padding='max_length', \n",
    "                                max_length = 512, \n",
    "                                truncation=True,\n",
    "                                return_tensors=\"pt\") \n",
    "                      for text in df['tweet']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c91784-356a-4204-9c09-3b9a79d03c73",
   "metadata": {},
   "source": [
    "### construct a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c67cc9a4-f647-4943-9285-a1eb4e27e8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#17\n",
    "from transformers import BertModel\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, dropout=0.4):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 3)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47f80671-bbe1-4fc1-b81a-5b6f3013e5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#19\n",
    "from transformers import BertModel\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, dropout=0.45):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 3)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98107b08-08a4-4e29-a76c-07c426f1edc6",
   "metadata": {},
   "source": [
    "### training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0e5b49-ef02-4a43-b24d-20f397fa5bfd",
   "metadata": {},
   "source": [
    "##### upload 17 setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4343eb1e-6482-402d-98be-00b70844f48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "def trainmodel(model, train_data, learning_rate, epochs):\n",
    "  # 通過Dataset類獲取訓練集\n",
    "    train = Dataset(train_data)\n",
    "    # DataLoader根據batch_size獲取數據，訓練時選擇打亂樣本\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=6, shuffle=True)\n",
    "  # 判斷是否使用GPU\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    # 定義損失函數和優化器\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "            model = model.cuda()\n",
    "            criterion = criterion.cuda()\n",
    "    # 開始進入訓練循環\n",
    "    for epoch_num in range(epochs):\n",
    "      # 定義兩個變量，用於存儲訓練集的準確率和損失\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "      # 進度條函數tqdm\n",
    "            for train_input, train_label in tqdm(train_dataloader):\n",
    "\n",
    "                train_label = train_label.to(device)\n",
    "                mask = train_input['attention_mask'].to(device)\n",
    "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "        # 通過模型得到輸出\n",
    "                output = model(input_id, mask)\n",
    "                # 計算損失\n",
    "                #\n",
    "                train_label = train_label.type(torch.LongTensor)\n",
    "                train_label = train_label.to(device)\n",
    "                #\n",
    "                batch_loss = criterion(output, train_label)\n",
    "                total_loss_train += batch_loss.item()\n",
    "                # 計算精度\n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "        # 模型更新\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            print(\n",
    "                f'''Epochs: {epoch_num + 1} \n",
    "              | Train Loss: {total_loss_train / len(train_data): .3f} \n",
    "              | Train Accuracy: {total_acc_train / len(train_data): .3f}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5744f805-2eee-4b99-a11d-677888644d95",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2125/2125 [09:31<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 \n",
      "              | Train Loss:  0.081 \n",
      "              | Train Accuracy:  0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2125/2125 [09:25<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 \n",
      "              | Train Loss:  0.047 \n",
      "              | Train Accuracy:  0.900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2125/2125 [09:24<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 \n",
      "              | Train Loss:  0.040 \n",
      "              | Train Accuracy:  0.916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2125/2125 [09:22<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 \n",
      "              | Train Loss:  0.035 \n",
      "              | Train Accuracy:  0.924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2125/2125 [09:21<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 \n",
      "              | Train Loss:  0.030 \n",
      "              | Train Accuracy:  0.932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2125/2125 [09:19<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 6 \n",
      "              | Train Loss:  0.025 \n",
      "              | Train Accuracy:  0.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2125/2125 [09:19<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 7 \n",
      "              | Train Loss:  0.020 \n",
      "              | Train Accuracy:  0.955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2125/2125 [09:19<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 8 \n",
      "              | Train Loss:  0.016 \n",
      "              | Train Accuracy:  0.962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2125/2125 [09:19<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 9 \n",
      "              | Train Loss:  0.012 \n",
      "              | Train Accuracy:  0.971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2125/2125 [09:19<00:00,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10 \n",
      "              | Train Loss:  0.009 \n",
      "              | Train Accuracy:  0.979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "model = BertClassifier()\n",
    "LR = 1e-6\n",
    "trainmodel(model, train, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85f3676-76b2-4029-a9e4-403bdba87878",
   "metadata": {},
   "source": [
    "##### upload 19 setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7b12965-ef59-4a54-8b67-48c7f1a09bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2479/2479 [09:00<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 \n",
      "              | Train Loss:  0.057 \n",
      "              | Train Accuracy:  0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2479/2479 [09:06<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 \n",
      "              | Train Loss:  0.041 \n",
      "              | Train Accuracy:  0.916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2479/2479 [09:08<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 \n",
      "              | Train Loss:  0.029 \n",
      "              | Train Accuracy:  0.936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2479/2479 [09:02<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 \n",
      "              | Train Loss:  0.014 \n",
      "              | Train Accuracy:  0.969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2479/2479 [09:05<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 \n",
      "              | Train Loss:  0.006 \n",
      "              | Train Accuracy:  0.988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2479/2479 [09:08<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 6 \n",
      "              | Train Loss:  0.004 \n",
      "              | Train Accuracy:  0.993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2479/2479 [09:06<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 7 \n",
      "              | Train Loss:  0.003 \n",
      "              | Train Accuracy:  0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2479/2479 [09:00<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 8 \n",
      "              | Train Loss:  0.002 \n",
      "              | Train Accuracy:  0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2479/2479 [08:59<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 9 \n",
      "              | Train Loss:  0.002 \n",
      "              | Train Accuracy:  0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2479/2479 [08:58<00:00,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10 \n",
      "              | Train Loss:  0.001 \n",
      "              | Train Accuracy:  0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#19\n",
    "EPOCHS = 10\n",
    "model = BertClassifier()\n",
    "LR = 1e-5\n",
    "trainmodel(model, train, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435031ad-343f-4f0f-903b-89bdf079254b",
   "metadata": {},
   "source": [
    "### model predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "80b6b8b4-bf4f-4b8d-8589-20244ad7f668",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [0,1,2]\n",
    "prediction_list = []\n",
    "tweet = test['tweet'].tolist()\n",
    "# tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9ac5a69-39ea-45f4-be47-c5a3b5e49a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for i in tweet:\n",
    "    encoded_review = tokenizer.encode_plus(\n",
    "        i,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        add_special_tokens=True,\n",
    "        return_token_type_ids=False,\n",
    "        pad_to_max_length=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "    input_ids = encoded_review['input_ids'].to(device)\n",
    "    attention_mask = encoded_review['attention_mask'].to(device)\n",
    "    output = model(input_ids, attention_mask)\n",
    "    _, prediction = torch.max(output, dim=1)\n",
    "    prediction_list.append(class_names[prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "afbd57c4-3635-4a6b-93e9-c1f8d15af093",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9909</th>\n",
       "      <td>9909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9910</th>\n",
       "      <td>9910</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9911</th>\n",
       "      <td>9911</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9912</th>\n",
       "      <td>9912</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9913</th>\n",
       "      <td>9913</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9914 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  class\n",
       "0        0      1\n",
       "1        1      1\n",
       "2        2      1\n",
       "3        3      1\n",
       "4        4      1\n",
       "...    ...    ...\n",
       "9909  9909      0\n",
       "9910  9910      2\n",
       "9911  9911      1\n",
       "9912  9912      1\n",
       "9913  9913      2\n",
       "\n",
       "[9914 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df = pd.DataFrame(prediction_list)\n",
    "id = pd.DataFrame([*range(0,9914)])\n",
    "upload = pd.concat([id, prediction_df], axis=1)\n",
    "upload.columns=['id','class']\n",
    "upload.to_csv('upload_19.csv')\n",
    "upload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bdf6c4-0c28-40f7-8915-49f4b2d1b113",
   "metadata": {
    "tags": []
   },
   "source": [
    "## padding=256測試"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f65019-0198-46c3-852f-d9481e3456dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dataset settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32596d5a-f6f3-4fe5-9904-6f6d7ea41ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "labels = {0:0,\n",
    "          1:1,\n",
    "          2:2 }\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.labels = [labels[label] for label in df['class']]\n",
    "        self.texts = [tokenizer(text, \n",
    "                                padding='max_length', \n",
    "                                max_length = 256, \n",
    "                                truncation=True,\n",
    "                                return_tensors=\"pt\") \n",
    "                      for text in df['tweet']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ed0cc1-21b4-4fd2-932c-91b4d5541116",
   "metadata": {},
   "source": [
    "### construct a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9c68a0-7cb8-46bf-8b3d-f55b935871f5",
   "metadata": {},
   "source": [
    "##### upload 18 setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c0bd699-0898-40c8-937a-9eb35dae8884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 3)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c13653-fd2f-48c1-99d3-1536e1d859df",
   "metadata": {},
   "source": [
    "### training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "705a9152-f074-4474-ab0c-0ef70a5e0e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "def trainmodel(model, train_data, learning_rate, epochs):\n",
    "  # 通過Dataset類獲取訓練集\n",
    "    train = Dataset(train_data)\n",
    "    # DataLoader根據batch_size獲取數據，訓練時選擇打亂樣本\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "  # 判斷是否使用GPU\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    # 定義損失函數和優化器\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "            model = model.cuda()\n",
    "            criterion = criterion.cuda()\n",
    "    # 開始進入訓練循環\n",
    "    for epoch_num in range(epochs):\n",
    "      # 定義兩個變量，用於存儲訓練集的準確率和損失\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "      # 進度條函數tqdm\n",
    "            for train_input, train_label in tqdm(train_dataloader):\n",
    "\n",
    "                train_label = train_label.to(device)\n",
    "                mask = train_input['attention_mask'].to(device)\n",
    "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "        # 通過模型得到輸出\n",
    "                output = model(input_id, mask)\n",
    "                # 計算損失\n",
    "                #\n",
    "                train_label = train_label.type(torch.LongTensor)\n",
    "                train_label = train_label.to(device)\n",
    "                #\n",
    "                batch_loss = criterion(output, train_label)\n",
    "                total_loss_train += batch_loss.item()\n",
    "                # 計算精度\n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "        # 模型更新\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            print(\n",
    "                f'''Epochs: {epoch_num + 1} \n",
    "              | Train Loss: {total_loss_train / len(train_data): .3f} \n",
    "              | Train Accuracy: {total_acc_train / len(train_data): .3f}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3edbb6b3-e1e6-4f83-bcc2-f8797f0aaeaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1487/1487 [04:33<00:00,  5.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 \n",
      "              | Train Loss:  0.060 \n",
      "              | Train Accuracy:  0.763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1487/1487 [04:40<00:00,  5.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 \n",
      "              | Train Loss:  0.040 \n",
      "              | Train Accuracy:  0.836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1487/1487 [04:41<00:00,  5.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 \n",
      "              | Train Loss:  0.031 \n",
      "              | Train Accuracy:  0.904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1487/1487 [04:36<00:00,  5.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 \n",
      "              | Train Loss:  0.027 \n",
      "              | Train Accuracy:  0.915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1487/1487 [04:08<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 \n",
      "              | Train Loss:  0.024 \n",
      "              | Train Accuracy:  0.921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1487/1487 [04:18<00:00,  5.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 6 \n",
      "              | Train Loss:  0.021 \n",
      "              | Train Accuracy:  0.926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1487/1487 [04:23<00:00,  5.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 7 \n",
      "              | Train Loss:  0.018 \n",
      "              | Train Accuracy:  0.933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1487/1487 [04:23<00:00,  5.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 8 \n",
      "              | Train Loss:  0.015 \n",
      "              | Train Accuracy:  0.937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1487/1487 [04:24<00:00,  5.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 9 \n",
      "              | Train Loss:  0.013 \n",
      "              | Train Accuracy:  0.945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1487/1487 [04:22<00:00,  5.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10 \n",
      "              | Train Loss:  0.011 \n",
      "              | Train Accuracy:  0.953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "model = BertClassifier()\n",
    "LR = 1e-6\n",
    "trainmodel(model, train, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95449716-6c66-4a1a-add9-5736988ff959",
   "metadata": {},
   "source": [
    "### model predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5573d04d-e5f5-4156-997f-825051912831",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [0,1,2]\n",
    "prediction_list = []\n",
    "tweet = test['tweet'].tolist()\n",
    "# tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a4a5ecf-e374-40e0-af5c-440cf3a8695f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for i in tweet:\n",
    "    encoded_review = tokenizer.encode_plus(\n",
    "        i,\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        add_special_tokens=True,\n",
    "        return_token_type_ids=False,\n",
    "        pad_to_max_length=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "    input_ids = encoded_review['input_ids'].to(device)\n",
    "    attention_mask = encoded_review['attention_mask'].to(device)\n",
    "    output = model(input_ids, attention_mask)\n",
    "    _, prediction = torch.max(output, dim=1)\n",
    "    prediction_list.append(class_names[prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1ed67a3-9233-4ddc-959a-e76c88e4daa3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9909</th>\n",
       "      <td>9909</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9910</th>\n",
       "      <td>9910</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9911</th>\n",
       "      <td>9911</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9912</th>\n",
       "      <td>9912</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9913</th>\n",
       "      <td>9913</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9914 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  class\n",
       "0        0      1\n",
       "1        1      1\n",
       "2        2      1\n",
       "3        3      1\n",
       "4        4      1\n",
       "...    ...    ...\n",
       "9909  9909      1\n",
       "9910  9910      2\n",
       "9911  9911      1\n",
       "9912  9912      1\n",
       "9913  9913      2\n",
       "\n",
       "[9914 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df = pd.DataFrame(prediction_list)\n",
    "id = pd.DataFrame([*range(0,9914)])\n",
    "upload = pd.concat([id, prediction_df], axis=1)\n",
    "upload.columns=['id','class']\n",
    "upload.to_csv('upload_18.csv')\n",
    "upload"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
